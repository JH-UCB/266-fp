{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1-IAV1drb9MoaIxoT-KAu3_BQsW8Hm2jP","timestamp":1743979112517}],"gpuType":"A100","machine_shape":"hm","toc_visible":true,"collapsed_sections":["O_g9-bLdVBD_","214_LGGAzEWZ","H5PUNtHezMCd","i56uCOF7e6kH","28WBvMOQjM6t","ZISgVUwvmuOu"],"authorship_tag":"ABX9TyMQF/HNe2ASyWy0R+fNDRxA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"89b5b22e45fc4fcdb827c251ef6ae538":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_902172e8435243a69b964659df8a69d3","IPY_MODEL_438b0d8ad16241ca810451f52d2480ab","IPY_MODEL_1120e780f3c54d6f8d80df8fdb35d725"],"layout":"IPY_MODEL_d8a7693abbfd4fdf9936c37671650445"}},"902172e8435243a69b964659df8a69d3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a5c88356c2b7439e9fe82c19abfa9888","placeholder":"​","style":"IPY_MODEL_357864ce97944c189e4c0103409a7d7e","value":"config.json: 100%"}},"438b0d8ad16241ca810451f52d2480ab":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_11b95af2d36b4613a56c3c2c7b34bd11","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8e810591d51a4566b6576e80503906e6","value":570}},"1120e780f3c54d6f8d80df8fdb35d725":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e745d2e1abf64935b3e3237c23b17585","placeholder":"​","style":"IPY_MODEL_8991e20085e04385b7b77efedaf500e5","value":" 570/570 [00:00&lt;00:00, 68.3kB/s]"}},"d8a7693abbfd4fdf9936c37671650445":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5c88356c2b7439e9fe82c19abfa9888":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"357864ce97944c189e4c0103409a7d7e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"11b95af2d36b4613a56c3c2c7b34bd11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e810591d51a4566b6576e80503906e6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e745d2e1abf64935b3e3237c23b17585":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8991e20085e04385b7b77efedaf500e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b2d346b9f4ec425a89956af7bfbfb745":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f0403cecc95a416ab6907aef9879cae5","IPY_MODEL_2492ad52cf784c769efb2fa09ac4e1fe","IPY_MODEL_64cd24cec1ad476aa23ace815331bbe0"],"layout":"IPY_MODEL_e4509db5723c41a6b0a7afde1e1e9be8"}},"f0403cecc95a416ab6907aef9879cae5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d1ff2f3cc7c7488c903627adcfeec938","placeholder":"​","style":"IPY_MODEL_5bfebb34fe9b475fb9b086ac678ab8bd","value":"tokenizer_config.json: 100%"}},"2492ad52cf784c769efb2fa09ac4e1fe":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cac039b8d4374cacb9a191ef3d2e354d","max":49,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eab5e0f865b54e8db6b732b693b7ece8","value":49}},"64cd24cec1ad476aa23ace815331bbe0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_08da2a023b8a4a93a4629a56502c31fd","placeholder":"​","style":"IPY_MODEL_869426fb804749ca87a4d802fc622823","value":" 49.0/49.0 [00:00&lt;00:00, 5.99kB/s]"}},"e4509db5723c41a6b0a7afde1e1e9be8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1ff2f3cc7c7488c903627adcfeec938":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5bfebb34fe9b475fb9b086ac678ab8bd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cac039b8d4374cacb9a191ef3d2e354d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eab5e0f865b54e8db6b732b693b7ece8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"08da2a023b8a4a93a4629a56502c31fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"869426fb804749ca87a4d802fc622823":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fcf0211e35034e249fac7041dae128ca":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b596d06336ce480395cab08949f45247","IPY_MODEL_27c7c90fb9df4d0794fccda34934e972","IPY_MODEL_0c4a070a450344b5b12620f7d17badd6"],"layout":"IPY_MODEL_abc121c5e30c4c63a19a9215b5d0f7b7"}},"b596d06336ce480395cab08949f45247":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b1d0ab7282d469aba5ef2c9e81d16f4","placeholder":"​","style":"IPY_MODEL_bdac877573f6422f9ec1570c3da2c250","value":"vocab.txt: 100%"}},"27c7c90fb9df4d0794fccda34934e972":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6b914212d5b43a1a90ce1731251f44e","max":213450,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ebbba371ebb443bea1b01204a99142e0","value":213450}},"0c4a070a450344b5b12620f7d17badd6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_003e16b492f04f78aabe532787d24e0b","placeholder":"​","style":"IPY_MODEL_cf77fbc3636646ddb78c72cca9a8062c","value":" 213k/213k [00:00&lt;00:00, 5.18MB/s]"}},"abc121c5e30c4c63a19a9215b5d0f7b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b1d0ab7282d469aba5ef2c9e81d16f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bdac877573f6422f9ec1570c3da2c250":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c6b914212d5b43a1a90ce1731251f44e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ebbba371ebb443bea1b01204a99142e0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"003e16b492f04f78aabe532787d24e0b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf77fbc3636646ddb78c72cca9a8062c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"564c44ad45294e7d892324b5e50c9bbe":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5ae8e4175f594913b81dc59ed39a083c","IPY_MODEL_ceaf66a4eb0c45eca02829d740d01c82","IPY_MODEL_d21fb67486a34f27a5abc21246f214f0"],"layout":"IPY_MODEL_35d1f691a821445d84e09794d9acc969"}},"5ae8e4175f594913b81dc59ed39a083c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_da5ea127e58b41778171d4844a42a145","placeholder":"​","style":"IPY_MODEL_ce44ec47283d4dc6823a1ff5af608c80","value":"tokenizer.json: 100%"}},"ceaf66a4eb0c45eca02829d740d01c82":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1c2214b54e814b2789c54fadfee35388","max":435797,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8727bcb46ce24b77b50085788d7196b8","value":435797}},"d21fb67486a34f27a5abc21246f214f0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_82c5efebe1004e24a3f8aa28280cabde","placeholder":"​","style":"IPY_MODEL_5af40e84cf544abbb860ea6a00a99469","value":" 436k/436k [00:00&lt;00:00, 6.27MB/s]"}},"35d1f691a821445d84e09794d9acc969":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da5ea127e58b41778171d4844a42a145":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce44ec47283d4dc6823a1ff5af608c80":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1c2214b54e814b2789c54fadfee35388":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8727bcb46ce24b77b50085788d7196b8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"82c5efebe1004e24a3f8aa28280cabde":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5af40e84cf544abbb860ea6a00a99469":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0b2513e2ef094c568e06877dc403aa84":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5e173d6c05684dbf90f94d18cc5d3a2d","IPY_MODEL_dc86635f723b41c6b7177e878da6d3b9","IPY_MODEL_1d502d6910c5495faffa3a627317de31"],"layout":"IPY_MODEL_971e4d0414a846e99c9a4b488422eee9"}},"5e173d6c05684dbf90f94d18cc5d3a2d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_db45b09642d140c68fafdb7557f78ecc","placeholder":"​","style":"IPY_MODEL_7c3a0b4a1cde453db21a6eca177c904f","value":"model.safetensors: 100%"}},"dc86635f723b41c6b7177e878da6d3b9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_353abe1412704ea0a093eaa08c25a0cd","max":435755784,"min":0,"orientation":"horizontal","style":"IPY_MODEL_53d20cee7cba46269a563f970fd1ef1d","value":435755784}},"1d502d6910c5495faffa3a627317de31":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b98c70006c164a33a45c297349b0258c","placeholder":"​","style":"IPY_MODEL_1f321b0c340946d88561dfa2a0ab6ee4","value":" 436M/436M [00:02&lt;00:00, 341MB/s]"}},"971e4d0414a846e99c9a4b488422eee9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db45b09642d140c68fafdb7557f78ecc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c3a0b4a1cde453db21a6eca177c904f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"353abe1412704ea0a093eaa08c25a0cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53d20cee7cba46269a563f970fd1ef1d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b98c70006c164a33a45c297349b0258c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f321b0c340946d88561dfa2a0ab6ee4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fdfa0482758a49ee910449e2a669a68b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f8d33b4b60b74ae98075043f79398b5c","IPY_MODEL_b1aa88c0b866425d8aa65115770d7e73","IPY_MODEL_79aad39ded724731bc5ac5b043851b51"],"layout":"IPY_MODEL_8d81249603b543e09a69a7ff7dacf581"}},"f8d33b4b60b74ae98075043f79398b5c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_16510923ffe347f1881bdaa6e83799ef","placeholder":"​","style":"IPY_MODEL_0912b353df33468088adce074dbfefc7","value":"Map: 100%"}},"b1aa88c0b866425d8aa65115770d7e73":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_af7f7292d7614c82a6a1017337a68493","max":7662,"min":0,"orientation":"horizontal","style":"IPY_MODEL_28f943808db44d9b81cb96d6a84175ec","value":7662}},"79aad39ded724731bc5ac5b043851b51":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_00adfd48e0864d7194a9129b35beb119","placeholder":"​","style":"IPY_MODEL_7683aedd7bdb4b69923152c62956e20f","value":" 7662/7662 [00:01&lt;00:00, 6319.13 examples/s]"}},"8d81249603b543e09a69a7ff7dacf581":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16510923ffe347f1881bdaa6e83799ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0912b353df33468088adce074dbfefc7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"af7f7292d7614c82a6a1017337a68493":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28f943808db44d9b81cb96d6a84175ec":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"00adfd48e0864d7194a9129b35beb119":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7683aedd7bdb4b69923152c62956e20f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c6541cc4bb064efda85349ee17a8ac4b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a4547f4391344fd586a2b600793f3b9e","IPY_MODEL_d53d0fad3efe44bcb85a1173eb3cf702","IPY_MODEL_bcd761e95aed48939aff8255d2a1d550"],"layout":"IPY_MODEL_3883f3ef3f0948ee8226997637448022"}},"a4547f4391344fd586a2b600793f3b9e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_27321a93bb254f399f19bcc9d3ecd160","placeholder":"​","style":"IPY_MODEL_d8354d724ecf4a1595dd9e74e6ce928c","value":"Map: 100%"}},"d53d0fad3efe44bcb85a1173eb3cf702":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_83cde99485394f459d57396c0baf53be","max":421,"min":0,"orientation":"horizontal","style":"IPY_MODEL_06dc63594b3a46c4a15694c249a53fe4","value":421}},"bcd761e95aed48939aff8255d2a1d550":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bdb23d556b874d30880d411ed0d49c30","placeholder":"​","style":"IPY_MODEL_9eb857e339df462c9cd669b56cf3ef55","value":" 421/421 [00:00&lt;00:00, 5750.56 examples/s]"}},"3883f3ef3f0948ee8226997637448022":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27321a93bb254f399f19bcc9d3ecd160":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8354d724ecf4a1595dd9e74e6ce928c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"83cde99485394f459d57396c0baf53be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06dc63594b3a46c4a15694c249a53fe4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bdb23d556b874d30880d411ed0d49c30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9eb857e339df462c9cd669b56cf3ef55":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"88b013b29ced4b28a592ec5f891fd3a1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0b355f2978be475b8d439a037d5c4f88","IPY_MODEL_8315da9057c945f7a80479ffe4c16a45","IPY_MODEL_5c25303a90444250a9cf4659e2fffd4b"],"layout":"IPY_MODEL_0b9af45981e048beb39dcb5d380d1df5"}},"0b355f2978be475b8d439a037d5c4f88":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_00423dd5e9aa4636b319765a4af1703b","placeholder":"​","style":"IPY_MODEL_5aea9f54b38443939bcc812ffe9beb36","value":"Map: 100%"}},"8315da9057c945f7a80479ffe4c16a45":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d7f7ad43d4f40eea67667a3109ce3d9","max":917,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e64f0b3dec66442481df2509fce7e5d6","value":917}},"5c25303a90444250a9cf4659e2fffd4b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_60ecaa52be244295b6ffd38bc409fbf5","placeholder":"​","style":"IPY_MODEL_72fd7582e6ba43d48f8b63d7bfe2b7e1","value":" 917/917 [00:00&lt;00:00, 6586.72 examples/s]"}},"0b9af45981e048beb39dcb5d380d1df5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"00423dd5e9aa4636b319765a4af1703b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5aea9f54b38443939bcc812ffe9beb36":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3d7f7ad43d4f40eea67667a3109ce3d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e64f0b3dec66442481df2509fce7e5d6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"60ecaa52be244295b6ffd38bc409fbf5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72fd7582e6ba43d48f8b63d7bfe2b7e1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e8fdc51a5289454395102158c6696361":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7716f1ad936e440b978d1cac50219c20","IPY_MODEL_8f33632ec73443ba9a56fb77a05da7b4","IPY_MODEL_4f41754cde0e47f7b1135cc05fc199b5"],"layout":"IPY_MODEL_7e6ad6ad15aa4bf3b6c3fe7d62f09540"}},"7716f1ad936e440b978d1cac50219c20":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bcf6bddbacb44c27bbb714c2e1e35613","placeholder":"​","style":"IPY_MODEL_66b109759aac47e79385c1b45f00a8df","value":"Downloading builder script: 100%"}},"8f33632ec73443ba9a56fb77a05da7b4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_64421ad2f91445b89db3d01065e5f6c9","max":4203,"min":0,"orientation":"horizontal","style":"IPY_MODEL_59c4a04b0bfb4b3ea8843c94ff5e2da0","value":4203}},"4f41754cde0e47f7b1135cc05fc199b5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9857a079a3d4e208796e039e92feea5","placeholder":"​","style":"IPY_MODEL_a838bbc1df8941fe8f7794fdc6fedaba","value":" 4.20k/4.20k [00:00&lt;00:00, 510kB/s]"}},"7e6ad6ad15aa4bf3b6c3fe7d62f09540":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bcf6bddbacb44c27bbb714c2e1e35613":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66b109759aac47e79385c1b45f00a8df":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"64421ad2f91445b89db3d01065e5f6c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59c4a04b0bfb4b3ea8843c94ff5e2da0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b9857a079a3d4e208796e039e92feea5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a838bbc1df8941fe8f7794fdc6fedaba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c1eb0fe7ca949e6abe95b6bf93ba11f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2f1b9ec504154036b96af7cd4ca72870","IPY_MODEL_f8230fd400dd44a896324369e4e25cc0","IPY_MODEL_44be9aabbe444f01b2bdb436eecbe760"],"layout":"IPY_MODEL_9421d72252944ffdbbe56bbcddff8ac2"}},"2f1b9ec504154036b96af7cd4ca72870":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_54f5f5df7c074c4ba7fa30ba92380dd3","placeholder":"​","style":"IPY_MODEL_7b9a0192cd0d417fbbf0034358e1cb88","value":"Downloading builder script: 100%"}},"f8230fd400dd44a896324369e4e25cc0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a89d8eadf04649f5a69397aca75218b8","max":7560,"min":0,"orientation":"horizontal","style":"IPY_MODEL_21c49b327b6949d890b94b4e73decd54","value":7560}},"44be9aabbe444f01b2bdb436eecbe760":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_00ed43489376487e8026ab11d9aeea6e","placeholder":"​","style":"IPY_MODEL_9259f4a77fef42e480fd71541d92f454","value":" 7.56k/7.56k [00:00&lt;00:00, 931kB/s]"}},"9421d72252944ffdbbe56bbcddff8ac2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54f5f5df7c074c4ba7fa30ba92380dd3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b9a0192cd0d417fbbf0034358e1cb88":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a89d8eadf04649f5a69397aca75218b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21c49b327b6949d890b94b4e73decd54":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"00ed43489376487e8026ab11d9aeea6e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9259f4a77fef42e480fd71541d92f454":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6c8e59ae30824e8e9ca9328e9aa27711":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f36022111e9b43f0b8a76a127af601d8","IPY_MODEL_3053b04020594928aae8093b7e188afc","IPY_MODEL_ea4038bf79194a6d9b63fba05b180b4e"],"layout":"IPY_MODEL_916371cb4c2b4f5386a20641b48152dd"}},"f36022111e9b43f0b8a76a127af601d8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd86ec9b49374a15a9c5f1fad4329c93","placeholder":"​","style":"IPY_MODEL_3ecec126605a4832b0ab37a8fa3065cd","value":"Downloading builder script: 100%"}},"3053b04020594928aae8093b7e188afc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_93f9c0df08054fca82a0d523e395c7a8","max":7377,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f1dbac022c2e4374826e40453902cabc","value":7377}},"ea4038bf79194a6d9b63fba05b180b4e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd821eeee7c44ee19cbd00d40e3bd30e","placeholder":"​","style":"IPY_MODEL_7a693d5a44584d338d30c6bfb9b514ea","value":" 7.38k/7.38k [00:00&lt;00:00, 898kB/s]"}},"916371cb4c2b4f5386a20641b48152dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd86ec9b49374a15a9c5f1fad4329c93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ecec126605a4832b0ab37a8fa3065cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"93f9c0df08054fca82a0d523e395c7a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1dbac022c2e4374826e40453902cabc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bd821eeee7c44ee19cbd00d40e3bd30e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a693d5a44584d338d30c6bfb9b514ea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"82f3894f78e2479f9a86727e3d5ae9f5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_be202c87eae44c9aac5c15ba278d6dbb","IPY_MODEL_606d479257164f4e863cd705ceba74a6","IPY_MODEL_52cffb533c384380a25eb4d9a27574a0"],"layout":"IPY_MODEL_902bb1993ae4406c86a2d5d92b17f09e"}},"be202c87eae44c9aac5c15ba278d6dbb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e80c57c2542c4d14aed0fea47cca48ba","placeholder":"​","style":"IPY_MODEL_6128bba2283a4bc68c0055ec10b3ad55","value":"Downloading builder script: 100%"}},"606d479257164f4e863cd705ceba74a6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d43094c01bc43d59280674dc76c1b94","max":6785,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aea12a2ff7f3428f8700933cf83a7d66","value":6785}},"52cffb533c384380a25eb4d9a27574a0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b6a50bdcecb4077bfbd869aab6a7495","placeholder":"​","style":"IPY_MODEL_f46915056e8746cea132d4cc27beb5f1","value":" 6.79k/6.79k [00:00&lt;00:00, 820kB/s]"}},"902bb1993ae4406c86a2d5d92b17f09e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e80c57c2542c4d14aed0fea47cca48ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6128bba2283a4bc68c0055ec10b3ad55":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3d43094c01bc43d59280674dc76c1b94":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aea12a2ff7f3428f8700933cf83a7d66":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4b6a50bdcecb4077bfbd869aab6a7495":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f46915056e8746cea132d4cc27beb5f1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eb3922a3034147349f68550f5057541a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ace4573e7fe84d67b74b33e931ea7148","IPY_MODEL_4d9d8e7044884f6a842c7469b970a275","IPY_MODEL_58ef25ba5b614f4daf38d681bea605cc"],"layout":"IPY_MODEL_5f650ed21b7f472ca158bbf03edcc138"}},"ace4573e7fe84d67b74b33e931ea7148":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_59075e778cc34dfeb3dcdca029d6535b","placeholder":"​","style":"IPY_MODEL_09875a55e9a54956b8e412d3cdb879f2","value":"Map: 100%"}},"4d9d8e7044884f6a842c7469b970a275":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce775666726140f9b92625b19d0eb528","max":7662,"min":0,"orientation":"horizontal","style":"IPY_MODEL_090e5955a0074337a2a1297edf16304f","value":7662}},"58ef25ba5b614f4daf38d681bea605cc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc6bbf0181a94b5b8e03405fe287c70e","placeholder":"​","style":"IPY_MODEL_8200ed2077174641857fc87835d6360c","value":" 7662/7662 [00:01&lt;00:00, 5430.68 examples/s]"}},"5f650ed21b7f472ca158bbf03edcc138":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59075e778cc34dfeb3dcdca029d6535b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09875a55e9a54956b8e412d3cdb879f2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ce775666726140f9b92625b19d0eb528":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"090e5955a0074337a2a1297edf16304f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cc6bbf0181a94b5b8e03405fe287c70e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8200ed2077174641857fc87835d6360c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0fe184e349ba483d8b14b5a9dcd6c33c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_430b28f4a8a14e67b4eeb486f8aaf89b","IPY_MODEL_d841725c932d442fba363c8ddf8a20d7","IPY_MODEL_36ca68a9d0a146c8a5a76192b98f59dd"],"layout":"IPY_MODEL_ac2f817f64334e0685f6c4130055b40f"}},"430b28f4a8a14e67b4eeb486f8aaf89b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_34ea22d269aa490ca347dd9d8308ee78","placeholder":"​","style":"IPY_MODEL_42e51fad2995466b87a41625f0f663d9","value":"Map: 100%"}},"d841725c932d442fba363c8ddf8a20d7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_11d3e7cdd27c444381129cf6379ef4f3","max":421,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a6725d6785f14f66a29085ed8ebf086e","value":421}},"36ca68a9d0a146c8a5a76192b98f59dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a86124134314e4b8fb451bb502e7ff5","placeholder":"​","style":"IPY_MODEL_fd8721f62ec243979198177e560a3615","value":" 421/421 [00:00&lt;00:00, 4648.99 examples/s]"}},"ac2f817f64334e0685f6c4130055b40f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34ea22d269aa490ca347dd9d8308ee78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42e51fad2995466b87a41625f0f663d9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"11d3e7cdd27c444381129cf6379ef4f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6725d6785f14f66a29085ed8ebf086e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9a86124134314e4b8fb451bb502e7ff5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd8721f62ec243979198177e560a3615":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2884d40ef193407b8400ca701dc5f6ce":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9a06255df7b249e0a668d962ba88ee58","IPY_MODEL_aefe1a9b3ade45d39f84056638d1fa2e","IPY_MODEL_71e8ea5a6b074ef796eb3b29421ff862"],"layout":"IPY_MODEL_2f4a478dee294bd59c0e68aa8939a408"}},"9a06255df7b249e0a668d962ba88ee58":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_79a75b1984f948b1a2128e51653fdf54","placeholder":"​","style":"IPY_MODEL_a1222133c8664103ab664efea240537f","value":"Map: 100%"}},"aefe1a9b3ade45d39f84056638d1fa2e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9d8322653624713a0f6b75f678954b1","max":917,"min":0,"orientation":"horizontal","style":"IPY_MODEL_979ee16622bc42fa8b5183cfb3441e40","value":917}},"71e8ea5a6b074ef796eb3b29421ff862":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ab1cd70f97a479dae81cd90da8716f8","placeholder":"​","style":"IPY_MODEL_61c8c2da483340888eb15377023d20f4","value":" 917/917 [00:00&lt;00:00, 5460.00 examples/s]"}},"2f4a478dee294bd59c0e68aa8939a408":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79a75b1984f948b1a2128e51653fdf54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1222133c8664103ab664efea240537f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b9d8322653624713a0f6b75f678954b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"979ee16622bc42fa8b5183cfb3441e40":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2ab1cd70f97a479dae81cd90da8716f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61c8c2da483340888eb15377023d20f4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["## Packages, Library Imports, File Mounts, & Data Imports ** Run All **"],"metadata":{"id":"WQo77FO88zQV"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"XWeMhKnlvi9F","executionInfo":{"status":"ok","timestamp":1744253128234,"user_tz":420,"elapsed":23682,"user":{"displayName":"J H","userId":"12017482157397552319"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4ea58485-3dc8-478c-e9a7-2552aaee338c"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/491.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m368.6/491.2 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/183.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/143.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/194.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n","gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.3/118.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install -q transformers\n","!pip install -q torchinfo\n","!pip install -q datasets\n","!pip install -q evaluate\n","!pip install -q nltk\n","!pip install -q contractions\n","!pip install -q hf_xet\n","!pip install -q sentencepiece"]},{"cell_type":"code","source":["!sudo apt-get update\n","! sudo apt-get install tree"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rX3VqZu11-s_","executionInfo":{"status":"ok","timestamp":1744253136883,"user_tz":420,"elapsed":8639,"user":{"displayName":"J H","userId":"12017482157397552319"}},"outputId":"6e1bfdf9-b55c-4728-dd93-09f3742ca4bd"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n","\r0% [Connecting to security.ubuntu.com (185.125.190.82)] [Connected to cloud.r-p\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n","\r                                                                               \rGet:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n","Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n","Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n","Get:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n","Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,383 kB]\n","Get:9 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,688 kB]\n","Get:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n","Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,542 kB]\n","Hit:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,824 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,099 kB]\n","Hit:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Get:16 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,243 kB]\n","Get:17 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [34.3 kB]\n","Get:18 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,000 kB]\n","Get:19 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,788 kB]\n","Fetched 26.0 MB in 2s (12.3 MB/s)\n","Reading package lists... Done\n","W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following NEW packages will be installed:\n","  tree\n","0 upgraded, 1 newly installed, 0 to remove and 47 not upgraded.\n","Need to get 47.9 kB of archives.\n","After this operation, 116 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tree amd64 2.0.2-1 [47.9 kB]\n","Fetched 47.9 kB in 0s (360 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package tree.\n","(Reading database ... 126213 files and directories currently installed.)\n","Preparing to unpack .../tree_2.0.2-1_amd64.deb ...\n","Unpacking tree (2.0.2-1) ...\n","Setting up tree (2.0.2-1) ...\n","Processing triggers for man-db (2.10.2-1) ...\n"]}]},{"cell_type":"code","source":["#@title Imports\n","import nltk\n","from nltk.tokenize import RegexpTokenizer\n","import sentencepiece\n","import contractions\n","import spacy\n","\n","\n","import evaluate\n","from datasets import load_dataset, Dataset, DatasetDict\n","\n","import torch\n","import torch.nn as nn\n","from torchinfo import summary\n","\n","import transformers\n","from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification, TrainingArguments, Trainer, BertConfig, BertForSequenceClassification\n","\n","import os\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import sklearn\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import classification_report, precision_recall_fscore_support, accuracy_score\n","\n","import json\n","import datetime\n","import zoneinfo\n","from datetime import datetime"],"metadata":{"id":"3wEgNBR6zosA","executionInfo":{"status":"ok","timestamp":1744253159362,"user_tz":420,"elapsed":22472,"user":{"displayName":"J H","userId":"12017482157397552319"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# @title Mount Google Drive"],"metadata":{"id":"rSP7bIn12YU7","executionInfo":{"status":"ok","timestamp":1744253159376,"user_tz":420,"elapsed":2,"user":{"displayName":"J H","userId":"12017482157397552319"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oWKPq7h01cXk","executionInfo":{"status":"ok","timestamp":1744253182248,"user_tz":420,"elapsed":22871,"user":{"displayName":"J H","userId":"12017482157397552319"}},"outputId":"fadae07e-b733-4532-9bae-6420b3cfd737"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["dir_root = '/content/drive/MyDrive/266-final/'\n","# dir_data = '/content/drive/MyDrive/266-final/data/'\n","# dir_data = '/content/drive/MyDrive/266-final/data/se21-t1-comp-lex-master/'\n","dir_data = '/content/drive/MyDrive/266-final/data/266-comp-lex-master'\n","dir_models = '/content/drive/MyDrive/266-final/models/'\n","dir_results = '/content/drive/MyDrive/266-final/results/'\n","log_filename = \"experiment_runs.txt\"\n","log_filepath = os.path.join(dir_results, log_filename)"],"metadata":{"id":"I3Tfro3Zzop5","executionInfo":{"status":"ok","timestamp":1744253182256,"user_tz":420,"elapsed":10,"user":{"displayName":"J H","userId":"12017482157397552319"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["wandbai_api_key = \"\""],"metadata":{"id":"HjZtvw5ScRDp","executionInfo":{"status":"ok","timestamp":1744253182258,"user_tz":420,"elapsed":1,"user":{"displayName":"J H","userId":"12017482157397552319"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["!tree /content/drive/MyDrive/266-final/data/266-comp-lex-master/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qw9f1Hol2UhL","executionInfo":{"status":"ok","timestamp":1744253183022,"user_tz":420,"elapsed":764,"user":{"displayName":"J H","userId":"12017482157397552319"}},"outputId":"a190b14b-2f24-45c2-f43b-4678e847b090"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[01;34m/content/drive/MyDrive/266-final/data/266-comp-lex-master/\u001b[0m\n","├── \u001b[01;34mfe-test-labels\u001b[0m\n","│   ├── \u001b[00mtest_multi_df.csv\u001b[0m\n","│   └── \u001b[00mtest_single_df.csv\u001b[0m\n","├── \u001b[01;34mfe-train\u001b[0m\n","│   ├── \u001b[00mtrain_multi_df.csv\u001b[0m\n","│   └── \u001b[00mtrain_single_df.csv\u001b[0m\n","├── \u001b[01;34mfe-trial-val\u001b[0m\n","│   ├── \u001b[00mtrial_val_multi_df.csv\u001b[0m\n","│   └── \u001b[00mtrial_val_single_df.csv\u001b[0m\n","├── \u001b[01;34mtest-labels\u001b[0m\n","│   ├── \u001b[00mlcp_multi_test.tsv\u001b[0m\n","│   └── \u001b[00mlcp_single_test.tsv\u001b[0m\n","├── \u001b[01;34mtrain\u001b[0m\n","│   ├── \u001b[00mlcp_multi_train.tsv\u001b[0m\n","│   └── \u001b[00mlcp_single_train.tsv\u001b[0m\n","└── \u001b[01;34mtrial\u001b[0m\n","    ├── \u001b[00mlcp_multi_trial.tsv\u001b[0m\n","    └── \u001b[00mlcp_single_trial.tsv\u001b[0m\n","\n","6 directories, 12 files\n"]}]},{"cell_type":"code","source":["!ls -R /content/drive/MyDrive/266-final/data/266-comp-lex-master/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zgul33NlKkbV","executionInfo":{"status":"ok","timestamp":1744253183123,"user_tz":420,"elapsed":100,"user":{"displayName":"J H","userId":"12017482157397552319"}},"outputId":"28c2cdee-ffb2-430f-bba0-6e7377e49323"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/266-final/data/266-comp-lex-master/:\n","fe-test-labels\tfe-train  fe-trial-val\ttest-labels  train  trial\n","\n","/content/drive/MyDrive/266-final/data/266-comp-lex-master/fe-test-labels:\n","test_multi_df.csv  test_single_df.csv\n","\n","/content/drive/MyDrive/266-final/data/266-comp-lex-master/fe-train:\n","train_multi_df.csv  train_single_df.csv\n","\n","/content/drive/MyDrive/266-final/data/266-comp-lex-master/fe-trial-val:\n","trial_val_multi_df.csv\ttrial_val_single_df.csv\n","\n","/content/drive/MyDrive/266-final/data/266-comp-lex-master/test-labels:\n","lcp_multi_test.tsv  lcp_single_test.tsv\n","\n","/content/drive/MyDrive/266-final/data/266-comp-lex-master/train:\n","lcp_multi_train.tsv  lcp_single_train.tsv\n","\n","/content/drive/MyDrive/266-final/data/266-comp-lex-master/trial:\n","lcp_multi_trial.tsv  lcp_single_trial.tsv\n"]}]},{"cell_type":"code","source":["!tree /content/drive/MyDrive/266-final/data/266-comp-lex-master/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G9f8sPUBdbVr","executionInfo":{"status":"ok","timestamp":1744253183272,"user_tz":420,"elapsed":143,"user":{"displayName":"J H","userId":"12017482157397552319"}},"outputId":"7aa41ce2-d709-4075-ee0a-7652f385356a"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[01;34m/content/drive/MyDrive/266-final/data/266-comp-lex-master/\u001b[0m\n","├── \u001b[01;34mfe-test-labels\u001b[0m\n","│   ├── \u001b[00mtest_multi_df.csv\u001b[0m\n","│   └── \u001b[00mtest_single_df.csv\u001b[0m\n","├── \u001b[01;34mfe-train\u001b[0m\n","│   ├── \u001b[00mtrain_multi_df.csv\u001b[0m\n","│   └── \u001b[00mtrain_single_df.csv\u001b[0m\n","├── \u001b[01;34mfe-trial-val\u001b[0m\n","│   ├── \u001b[00mtrial_val_multi_df.csv\u001b[0m\n","│   └── \u001b[00mtrial_val_single_df.csv\u001b[0m\n","├── \u001b[01;34mtest-labels\u001b[0m\n","│   ├── \u001b[00mlcp_multi_test.tsv\u001b[0m\n","│   └── \u001b[00mlcp_single_test.tsv\u001b[0m\n","├── \u001b[01;34mtrain\u001b[0m\n","│   ├── \u001b[00mlcp_multi_train.tsv\u001b[0m\n","│   └── \u001b[00mlcp_single_train.tsv\u001b[0m\n","└── \u001b[01;34mtrial\u001b[0m\n","    ├── \u001b[00mlcp_multi_trial.tsv\u001b[0m\n","    └── \u001b[00mlcp_single_trial.tsv\u001b[0m\n","\n","6 directories, 12 files\n"]}]},{"cell_type":"code","source":["#@title Import Data"],"metadata":{"id":"oftTqvV8zojV","executionInfo":{"status":"ok","timestamp":1744253183274,"user_tz":420,"elapsed":1,"user":{"displayName":"J H","userId":"12017482157397552319"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["df_names = [\n","    \"train_single_df\",\n","    \"train_multi_df\",\n","    \"trial_val_single_df\",\n","    \"trial_val_multi_df\",\n","    \"test_single_df\",\n","    \"test_multi_df\"\n","]\n","\n","loaded_dataframes = {}\n","\n","for df_name in df_names:\n","    if \"train\" in df_name:\n","        subdir = \"fe-train\"\n","    elif \"trial_val\" in df_name:\n","        subdir = \"fe-trial-val\"\n","    elif \"test\" in df_name:\n","        subdir = \"fe-test-labels\"\n","    else:\n","        subdir = None\n","\n","    if subdir:\n","        read_path = os.path.join(dir_data, subdir, f\"{df_name}.csv\")\n","        loaded_df = pd.read_csv(read_path)\n","        loaded_dataframes[df_name] = loaded_df\n","        print(f\"Loaded {df_name} from {read_path}\")\n","\n","# for df_name, df in loaded_dataframes.items():\n","#     print(f\"\\n>>> {df_name} shape: {df.shape}\")\n","#     if 'binary_complexity' in df.columns:\n","#         print(df['binary_complexity'].value_counts())\n","#         print(df.info())\n","#         print(df.head())\n","\n","for df_name, df in loaded_dataframes.items():\n","    globals()[df_name] = df\n","    print(f\"{df_name} loaded into global namespace.\")"],"metadata":{"id":"73lV0P87eV-P","executionInfo":{"status":"ok","timestamp":1744253184895,"user_tz":420,"elapsed":1616,"user":{"displayName":"J H","userId":"12017482157397552319"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"76f8a17c-7562-4168-da8c-8c8b75f86707"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded train_single_df from /content/drive/MyDrive/266-final/data/266-comp-lex-master/fe-train/train_single_df.csv\n","Loaded train_multi_df from /content/drive/MyDrive/266-final/data/266-comp-lex-master/fe-train/train_multi_df.csv\n","Loaded trial_val_single_df from /content/drive/MyDrive/266-final/data/266-comp-lex-master/fe-trial-val/trial_val_single_df.csv\n","Loaded trial_val_multi_df from /content/drive/MyDrive/266-final/data/266-comp-lex-master/fe-trial-val/trial_val_multi_df.csv\n","Loaded test_single_df from /content/drive/MyDrive/266-final/data/266-comp-lex-master/fe-test-labels/test_single_df.csv\n","Loaded test_multi_df from /content/drive/MyDrive/266-final/data/266-comp-lex-master/fe-test-labels/test_multi_df.csv\n","train_single_df loaded into global namespace.\n","train_multi_df loaded into global namespace.\n","trial_val_single_df loaded into global namespace.\n","trial_val_multi_df loaded into global namespace.\n","test_single_df loaded into global namespace.\n","test_multi_df loaded into global namespace.\n"]}]},{"cell_type":"markdown","source":["- Functional tests pass, we can proceed with Baseline Modeling"],"metadata":{"id":"8VsgfL5ZhO4z"}},{"cell_type":"markdown","source":["## Experiments"],"metadata":{"id":"kxZvACQZQu61"}},{"cell_type":"markdown","source":["### Helper Functions ** Run **"],"metadata":{"id":"SdNRxC7h9EoU"}},{"cell_type":"code","source":["MODEL_LINEAGE = {}\n","\n","def get_model_and_tokenizer(\n","    remote_model_name: str = None,\n","    local_model_path: str = None,\n","    config=None\n","):\n","    \"\"\"\n","    Loads the model & tokenizer for classification.\n","    If 'local_model_path' is specified, load from that path.\n","    Otherwise, fall back to 'remote_model_name'.\n","\n","    Optional: 'config' can be a custom BertConfig/AutoConfig object\n","              to override certain configuration parameters.\n","\n","    Records complete traceable lineage in the global MODEL_LINEAGE.\n","    \"\"\"\n","    global MODEL_LINEAGE\n","\n","    if local_model_path:\n","        print(f\"Loading from local path: {local_model_path}\")\n","        tokenizer = AutoTokenizer.from_pretrained(local_model_path)\n","\n","        # If a config object is provided, we pass it to from_pretrained.\n","        # Otherwise, it just uses the config that is part of local_model_path.\n","        if config is not None:\n","            model = AutoModelForSequenceClassification.from_pretrained(\n","                local_model_path,\n","                config=config\n","            )\n","        else:\n","            model = AutoModelForSequenceClassification.from_pretrained(local_model_path)\n","\n","        MODEL_LINEAGE = {\n","            \"type\": \"offline_checkpoint\",\n","            \"path\": local_model_path,\n","            \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n","        }\n","    elif remote_model_name:\n","        print(f\"Loading from Hugging Face model: {remote_model_name}\")\n","        tokenizer = AutoTokenizer.from_pretrained(remote_model_name)\n","\n","        if config is not None:\n","            model = AutoModelForSequenceClassification.from_pretrained(\n","                remote_model_name,\n","                config=config\n","            )\n","        else:\n","            model = AutoModelForSequenceClassification.from_pretrained(remote_model_name)\n","\n","        MODEL_LINEAGE = {\n","            \"type\": \"huggingface_hub\",\n","            \"path\": remote_model_name,\n","            \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n","        }\n","    else:\n","        raise ValueError(\"You must provide either a remote_model_name or a local_model_path!\")\n","\n","    return model, tokenizer\n"],"metadata":{"id":"qZEZHMAojXuc","executionInfo":{"status":"ok","timestamp":1744253184897,"user_tz":420,"elapsed":0,"user":{"displayName":"J H","userId":"12017482157397552319"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["def freeze_unfreeze_layers(model, layers_to_unfreeze=None):\n","    \"\"\"\n","    Toggles requires_grad = False for all parameters\n","    except for those whose names contain any string in layers_to_unfreeze.\n","    By default, always unfreeze classifier/heads.\n","    \"\"\"\n","    if layers_to_unfreeze is None:\n","        layers_to_unfreeze = [\"classifier.\", \"pooler.\"]\n","\n","    for name, param in model.named_parameters():\n","        if any(substring in name for substring in layers_to_unfreeze):\n","            param.requires_grad = True\n","        else:\n","            param.requires_grad = False"],"metadata":{"id":"a7OVfxB__e3S","executionInfo":{"status":"ok","timestamp":1744253184928,"user_tz":420,"elapsed":24,"user":{"displayName":"J H","userId":"12017482157397552319"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def encode_examples(examples, tokenizer, text_col, max_length=256):\n","    \"\"\"\n","    Tokenizes a batch of texts from 'examples[text_col]' using the given tokenizer.\n","    Returns a dict with 'input_ids', 'attention_mask', etc.\n","    \"\"\"\n","    texts = examples[text_col]\n","    encoded = tokenizer(\n","        texts,\n","        truncation=True,\n","        padding='max_length',\n","        max_length=max_length\n","    )\n","    return encoded"],"metadata":{"id":"BtVWXxqb_e0r","executionInfo":{"status":"ok","timestamp":1744253184931,"user_tz":420,"elapsed":1,"user":{"displayName":"J H","userId":"12017482157397552319"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def prepare_dataset(df, tokenizer, text_col, label_col, max_length=256):\n","    \"\"\"\n","    Converts a Pandas DataFrame to a Hugging Face Dataset,\n","    then applies 'encode_examples' to tokenize.\n","    \"\"\"\n","    dataset = Dataset.from_pandas(df)\n","\n","    dataset = dataset.map(\n","        lambda batch: encode_examples(batch, tokenizer, text_col, max_length),\n","        batched=True\n","    )\n","\n","    dataset = dataset.rename_column(label_col, \"labels\")\n","    dataset.set_format(type='torch',\n","                       columns=['input_ids', 'attention_mask', 'labels'])\n","    return dataset"],"metadata":{"id":"YmynPX-5i5HL","executionInfo":{"status":"ok","timestamp":1744253184931,"user_tz":420,"elapsed":0,"user":{"displayName":"J H","userId":"12017482157397552319"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def compute_metrics(eval_pred):\n","    \"\"\"\n","    Computes classification metrics, including accuracy, precision, recall, and F1.\n","    \"\"\"\n","    logits, labels = eval_pred\n","    preds = np.argmax(logits, axis=1)\n","\n","    metric_accuracy  = evaluate.load(\"accuracy\")\n","    metric_precision = evaluate.load(\"precision\")\n","    metric_recall    = evaluate.load(\"recall\")\n","    metric_f1        = evaluate.load(\"f1\")\n","\n","    accuracy_result  = metric_accuracy.compute(predictions=preds, references=labels)\n","    precision_result = metric_precision.compute(predictions=preds, references=labels, average=\"binary\")\n","    recall_result    = metric_recall.compute(predictions=preds, references=labels, average=\"binary\")\n","    f1_result        = metric_f1.compute(predictions=preds, references=labels, average=\"binary\")\n","\n","    return {\n","        \"accuracy\"       : accuracy_result[\"accuracy\"],\n","        \"precision\": precision_result[\"precision\"],\n","        \"recall\"   : recall_result[\"recall\"],\n","        \"f1\"       : f1_result[\"f1\"]\n","    }"],"metadata":{"id":"ze7GiYRP_ewQ","executionInfo":{"status":"ok","timestamp":1744253184932,"user_tz":420,"elapsed":0,"user":{"displayName":"J H","userId":"12017482157397552319"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["def gather_config_details(model):\n","    \"\"\"\n","    Enumerates every attribute in model.config\n","    \"\"\"\n","    config_items = {}\n","    for attr_name, attr_value in vars(model.config).items():\n","        config_items[attr_name] = attr_value\n","    return config_items\n","\n","def gather_model_details(model):\n","    \"\"\"\n","    Extracts total layers, total params, trainable params, and activation function\n","    from a Transformers model. Adjust logic as needed for different architectures.\n","    \"\"\"\n","    details = {}\n","\n","    try:\n","        total_params = model.num_parameters()\n","        trainable_params = model.num_parameters(only_trainable=True)\n","    except AttributeError:\n","        all_params = list(model.parameters())\n","        total_params = sum(p.numel() for p in all_params)\n","        trainable_params = sum(p.numel() for p in all_params if p.requires_grad)\n","\n","    details[\"model_total_params\"] = total_params\n","    details[\"model_trainable_params\"] = trainable_params\n","\n","    if hasattr(model, \"bert\") and hasattr(model.bert, \"pooler\"):\n","        act_obj = getattr(model.bert.pooler, \"activation\", None)\n","        details[\"pooler_activation_function\"] = act_obj.__class__.__name__ if act_obj else \"N/A\"\n","    else:\n","        details[\"pooler_activation_function\"] = \"N/A\"\n","\n","    details[\"config_attributes\"] = gather_config_details(model)\n","    return details\n","\n","def gather_all_run_metrics(trainer, train_dataset=None, val_dataset=None, test_dataset=None):\n","    \"\"\"\n","    Gathers final training metrics, final validation metrics, final test metrics.\n","    Instead of only parsing the final train_loss from the log, we also do a full\n","    trainer.evaluate(train_dataset) to get the same set of metrics that val/test have.\n","    \"\"\"\n","    results = {}\n","\n","    if train_dataset is not None:\n","        train_metrics = trainer.evaluate(train_dataset)\n","        for k, v in train_metrics.items():\n","            results[f\"train_{k}\"] = v\n","    else:\n","        results[\"train_metrics\"] = \"No train dataset provided\"\n","\n","    if val_dataset is not None:\n","        val_metrics = trainer.evaluate(val_dataset)\n","        for k, v in val_metrics.items():\n","            results[f\"val_{k}\"] = v\n","    else:\n","        results[\"val_metrics\"] = \"No val dataset provided\"\n","\n","    if test_dataset is not None:\n","        test_metrics = trainer.evaluate(test_dataset)\n","        for k, v in test_metrics.items():\n","            results[f\"test_{k}\"] = v\n","    else:\n","        results[\"test_metrics\"] = \"No test dataset provided\"\n","\n","    return results\n","\n","# def log_experiment_results_json(experiment_meta, model_details, run_metrics, log_file):\n","#     \"\"\"\n","#     Logs experiment metadata, model details, and metrics to a JSON lines file.\n","#     Automatically concatenates the 'checkpoint_path' to the 'model_lineage'.\n","#     \"\"\"\n","#     checkpoint_path = model_details.get(\"checkpoint_path\")\n","#     if checkpoint_path:\n","#         if \"model_lineage\" not in model_details:\n","#             model_details[\"model_lineage\"] = \"\"\n","#         if model_details[\"model_lineage\"]:\n","#             model_details[\"model_lineage\"] += \" -> \"\n","#         model_details[\"model_lineage\"] += checkpoint_path\n","\n","#     record = {\n","#         \"timestamp\": str(datetime.datetime.now()),\n","#         \"experiment_meta\": experiment_meta,\n","#         \"model_details\": model_details,\n","#         \"run_metrics\": run_metrics\n","#     }\n","\n","#     with open(log_file, \"a\", encoding=\"utf-8\") as f:\n","#         json.dump(record, f)\n","#         f.write(\"\\n\")\n","\n","def log_experiment_results_json(experiment_meta, model_details, run_metrics, log_file):\n","    \"\"\"\n","    Logs experiment metadata, model details, and metrics to a JSON lines file.\n","    Automatically concatenates the 'checkpoint_path' to the 'model_lineage'\n","    and uses Pacific time for the timestamp.\n","    \"\"\"\n","    checkpoint_path = model_details.get(\"checkpoint_path\")\n","    if checkpoint_path:\n","        if \"model_lineage\" not in model_details:\n","            model_details[\"model_lineage\"] = \"\"\n","        if model_details[\"model_lineage\"]:\n","            model_details[\"model_lineage\"] += \" -> \"\n","        model_details[\"model_lineage\"] += checkpoint_path\n","\n","    pacific_time = datetime.now(zoneinfo.ZoneInfo(\"America/Los_Angeles\")) # update to support pacific time\n","    timestamp_str = pacific_time.isoformat()\n","\n","    record = {\n","        \"timestamp\": timestamp_str,\n","        \"experiment_meta\": experiment_meta,\n","        \"model_details\": model_details,\n","        \"run_metrics\": run_metrics\n","    }\n","\n","    with open(log_file, \"a\", encoding=\"utf-8\") as f:\n","        json.dump(record, f)\n","        f.write(\"\\n\")"],"metadata":{"id":"yHdeDiKF5FZb","executionInfo":{"status":"ok","timestamp":1744253184933,"user_tz":420,"elapsed":0,"user":{"displayName":"J H","userId":"12017482157397552319"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["### Experiment Cohort Design"],"metadata":{"id":"5w231tlmrh_3"}},{"cell_type":"code","source":["# Define Experiment Parameters\n","\n","named_model = \"bert-base-cased\"\n","# named_model = \"roberta-base\"\n","# named_model = \"bert-large\"\n","# named_model = \"roberta-large\"\n","# named_model = \"\" # modern bert\n","\n","# learning_rate = 1e-3\n","# learning_rate = 1e-4\n","learning_rate = 1e-5\n","# learning_rate = 5e-6\n","# learning_rate = 5e-7\n","# learning_rate = 5e-8\n","\n","# num_epochs = 1\n","# num_epochs = 3\n","# num_epochs = 5\n","num_epochs = 25\n","# num_epochs = 15\n","# num_epochs = 20\n","\n","# length_max = 128\n","length_max = 256\n","# length_max = 348\n","# length_max = 512\n","\n","# size_batch = 1\n","# size_batch = 4\n","# size_batch = 8\n","size_batch = 16\n","# size_batch = 24\n","# size_batch = 32\n","# size_batch = 64\n","# size_batch = 128\n","\n","# regularization_weight_decay = 0\n","regularization_weight_decay = 0.1\n","# regularization_weight_decay = 0.5\n","\n","y_col = \"binary_complexity\"\n","# y_col = \"complexity\"\n","\n","x_task = \"single\"\n","# x_task = \"multi\"\n","\n","# x_col = \"sentence\"\n","x_col = \"sentence_no_contractions\"\n","# x_col = \"pos_sequence\"\n","# x_col = \"dep_sequence\"\n","# x_col = \"morph_sequence\"\n","\n","if x_task == \"single\":\n","    df_train = train_single_df\n","    df_val   = trial_val_single_df\n","    df_test  = test_single_df\n","else:\n","    df_train = train_multi_df\n","    df_val   = trial_val_multi_df\n","    df_test  = test_multi_df\n","\n","custom_config = BertConfig.from_pretrained(\"bert-base-cased\")\n","\n","custom_config.hidden_dropout_prob = 0.1\n","# custom_config.intermediate_size = 3072\n","# custom_config.intermediate_size = 6144\n","# custom_config.num_attention_heads = 12\n","# custom_config.num_hidden_layers = 12\n","custom_config.gradient_checkpointing = False\n","custom_config.attention_probs_dropout_prob = 0.1\n","# custom_config.max_position_embeddings = 512\n","# custom_config.type_vocab_size = 2\n","custom_config.hidden_act = \"gelu\"  # alts: \"relu\" \"silu\"\n","# custom_config.vocab_size = 28996  # must match\n","\n","# model.bert.pooler.activation = nn.ReLU() # Tanh() replaced as the pooler layer activation function in side-by-side with 1.1\n"],"metadata":{"id":"PjPcND4vrgOm","executionInfo":{"status":"ok","timestamp":1744253195153,"user_tz":420,"elapsed":10219,"user":{"displayName":"J H","userId":"12017482157397552319"}},"colab":{"base_uri":"https://localhost:8080/","height":188,"referenced_widgets":["89b5b22e45fc4fcdb827c251ef6ae538","902172e8435243a69b964659df8a69d3","438b0d8ad16241ca810451f52d2480ab","1120e780f3c54d6f8d80df8fdb35d725","d8a7693abbfd4fdf9936c37671650445","a5c88356c2b7439e9fe82c19abfa9888","357864ce97944c189e4c0103409a7d7e","11b95af2d36b4613a56c3c2c7b34bd11","8e810591d51a4566b6576e80503906e6","e745d2e1abf64935b3e3237c23b17585","8991e20085e04385b7b77efedaf500e5"]},"outputId":"52ee6db0-f74e-4464-9c82-d24cab861ad1"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n","Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n","You are not authenticated with the Hugging Face Hub in this notebook.\n","If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89b5b22e45fc4fcdb827c251ef6ae538"}},"metadata":{}}]},{"cell_type":"code","source":["def train_transformer_model(\n","    model,\n","    tokenizer,\n","    train_dataset,\n","    val_dataset,\n","    output_dir=dir_results,\n","    num_epochs=num_epochs,\n","    batch_size=size_batch,\n","    lr=learning_rate,\n","    weight_decay=regularization_weight_decay\n","):\n","    \"\"\"\n","    Sets up a Trainer and trains the model for 'num_epochs' using the given dataset.\n","    Returns the trained model and the Trainer object for possible re-use or analysis.\n","    \"\"\"\n","\n","    training_args = TrainingArguments(\n","        output_dir=output_dir,\n","        num_train_epochs=num_epochs,\n","        per_device_train_batch_size=batch_size,\n","        per_device_eval_batch_size=batch_size,\n","        evaluation_strategy=\"epoch\",\n","        save_strategy=\"no\",\n","        logging_strategy=\"epoch\",\n","        learning_rate=lr,\n","        weight_decay=weight_decay,\n","        report_to=[\"none\"],  # or \"wandb\"\n","        warmup_steps=100\n","    )\n","\n","    trainer = Trainer(\n","        model=model,\n","        args=training_args,\n","        train_dataset=train_dataset,\n","        eval_dataset=val_dataset,\n","        tokenizer=tokenizer,  # optional\n","        compute_metrics=compute_metrics\n","    )\n","\n","    trainer.train()\n","    return model, trainer"],"metadata":{"id":"b-kyadzyrgHT","executionInfo":{"status":"ok","timestamp":1744253195157,"user_tz":420,"elapsed":3,"user":{"displayName":"J H","userId":"12017482157397552319"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["----------------------------------------------------------------\n","****************************************************************"],"metadata":{"id":"-xComu7azRHr"}},{"cell_type":"markdown","source":["#### Model Inspection ** Run **"],"metadata":{"id":"UWNP_mfRZFJd"}},{"cell_type":"code","source":["print(\"model checkpoints:\", dir_models)\n","!ls /content/drive/MyDrive/266-final/models/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s5raqYA8p8zQ","executionInfo":{"status":"ok","timestamp":1744253195222,"user_tz":420,"elapsed":60,"user":{"displayName":"J H","userId":"12017482157397552319"}},"outputId":"39dbd4d3-31a0-48aa-93ff-0f0cd219ae39"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["model checkpoints: /content/drive/MyDrive/266-final/models/\n","multi_bert-base-cased_binary_complexity_20250408_143322\n","multi_bert-base-cased_binary_complexity_20250409_175804\n","multi_bert-base-cased_binary_complexity_20250409_175954\n","multi_bert-base-cased_binary_complexity_20250409_180139\n","multi_bert-base-cased_binary_complexity_20250409_185057\n","multi_bert-base-cased_binary_complexity_20250409_185213\n","multi_bert-base-cased_binary_complexity_20250409_185333\n","multi_bert-base-cased_binary_complexity_20250409_234934\n","multi_bert-base-cased_binary_complexity_20250410_001637\n","multi_bert-base-cased_binary_complexity_20250410_003117\n","multi_bert-base-cased_binary_complexity_20250410_004527\n","single_bert-base-cased_binary_complexity_20250408_043117\n","single_bert-base-cased_binary_complexity_20250408_043334\n","single_bert-base-cased_binary_complexity_20250408_043750\n","single_bert-base-cased_binary_complexity_20250409_175702\n","single_bert-base-cased_binary_complexity_20250409_175900\n","single_bert-base-cased_binary_complexity_20250409_180045\n","single_bert-base-cased_binary_complexity_20250409_185027\n","single_bert-base-cased_binary_complexity_20250409_185141\n","single_bert-base-cased_binary_complexity_20250409_185303\n","single_bert-base-cased_binary_complexity_20250409_234236\n","single_bert-base-cased_binary_complexity_20250410_000508\n","single_bert-base-cased_binary_complexity_20250410_002813\n","single_bert-base-cased_binary_complexity_20250410_004230\n"]}]},{"cell_type":"code","source":["# Load Model & Tokenizer\n","# model, tokenizer = get_model_and_tokenizer(named_model) # deprecated argument structure\n","# model, tokenizer = get_model_and_tokenizer(\"/content/drive/MyDrive/266-final/models/....\") # proposed argument usage for checkpointed models\n","\n","# for name, param in model.named_parameters():\n","#     print(name)\n","\n","model, tokenizer = get_model_and_tokenizer(\n","    remote_model_name=\"bert-base-cased\",\n","    local_model_path=None,\n","    config=custom_config\n",")\n","\n","# model, tokenizer = get_model_and_tokenizer(\n","#     local_model_path=\"my_local_bert_path\",\n","#     config=custom_config\n","# )\n","\n","print(\"=============\")\n","print(named_model, \":\")\n","print(\"=============\")\n","# print(model)\n","print(\"=============\")\n","print(model.config)\n","print(\"=============\")\n","print(\"num_parameters:\", model.num_parameters())\n","print(\"=============\")\n","print(\"num_trainable_parameters:\", model.num_parameters(only_trainable=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":965,"referenced_widgets":["b2d346b9f4ec425a89956af7bfbfb745","f0403cecc95a416ab6907aef9879cae5","2492ad52cf784c769efb2fa09ac4e1fe","64cd24cec1ad476aa23ace815331bbe0","e4509db5723c41a6b0a7afde1e1e9be8","d1ff2f3cc7c7488c903627adcfeec938","5bfebb34fe9b475fb9b086ac678ab8bd","cac039b8d4374cacb9a191ef3d2e354d","eab5e0f865b54e8db6b732b693b7ece8","08da2a023b8a4a93a4629a56502c31fd","869426fb804749ca87a4d802fc622823","fcf0211e35034e249fac7041dae128ca","b596d06336ce480395cab08949f45247","27c7c90fb9df4d0794fccda34934e972","0c4a070a450344b5b12620f7d17badd6","abc121c5e30c4c63a19a9215b5d0f7b7","5b1d0ab7282d469aba5ef2c9e81d16f4","bdac877573f6422f9ec1570c3da2c250","c6b914212d5b43a1a90ce1731251f44e","ebbba371ebb443bea1b01204a99142e0","003e16b492f04f78aabe532787d24e0b","cf77fbc3636646ddb78c72cca9a8062c","564c44ad45294e7d892324b5e50c9bbe","5ae8e4175f594913b81dc59ed39a083c","ceaf66a4eb0c45eca02829d740d01c82","d21fb67486a34f27a5abc21246f214f0","35d1f691a821445d84e09794d9acc969","da5ea127e58b41778171d4844a42a145","ce44ec47283d4dc6823a1ff5af608c80","1c2214b54e814b2789c54fadfee35388","8727bcb46ce24b77b50085788d7196b8","82c5efebe1004e24a3f8aa28280cabde","5af40e84cf544abbb860ea6a00a99469","0b2513e2ef094c568e06877dc403aa84","5e173d6c05684dbf90f94d18cc5d3a2d","dc86635f723b41c6b7177e878da6d3b9","1d502d6910c5495faffa3a627317de31","971e4d0414a846e99c9a4b488422eee9","db45b09642d140c68fafdb7557f78ecc","7c3a0b4a1cde453db21a6eca177c904f","353abe1412704ea0a093eaa08c25a0cd","53d20cee7cba46269a563f970fd1ef1d","b98c70006c164a33a45c297349b0258c","1f321b0c340946d88561dfa2a0ab6ee4"]},"id":"dVZ8rPGOVT5X","executionInfo":{"status":"ok","timestamp":1744253199365,"user_tz":420,"elapsed":4142,"user":{"displayName":"J H","userId":"12017482157397552319"}},"outputId":"c2948659-f301-4e5c-afea-39499ab80e59"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading from Hugging Face model: bert-base-cased\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2d346b9f4ec425a89956af7bfbfb745"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fcf0211e35034e249fac7041dae128ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"564c44ad45294e7d892324b5e50c9bbe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b2513e2ef094c568e06877dc403aa84"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["=============\n","bert-base-cased :\n","=============\n","=============\n","BertConfig {\n","  \"_attn_implementation_autoset\": true,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.50.3\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","=============\n","num_parameters: 108311810\n","=============\n","num_trainable_parameters: 108311810\n"]}]},{"cell_type":"markdown","source":["\n","#### Layer Configuration ** Run **"],"metadata":{"id":"9xKfKrycZH8l"}},{"cell_type":"code","source":["# Freeze/Unfreeze Layers & Additional Activation Function Configuration\n","\n","layers_to_unfreeze = [\n","    \"bert.embeddings.\",\n","    \"bert.encoder.layer.0.\",\n","    # \"bert.encoder.layer.1.\",\n","    \"bert.encoder.layer.8.\",\n","    \"bert.encoder.layer.9.\",\n","    \"bert.encoder.layer.10.\",\n","    \"bert.encoder.layer.11.\",\n","    \"bert.pooler.\",\n","    \"classifier.\",\n","]\n","\n","freeze_unfreeze_layers(model, layers_to_unfreeze=layers_to_unfreeze)\n","\n","for name, param in model.named_parameters():\n","    print(name, \"requires_grad=\", param.requires_grad)\n","\n","print(\"\\nLayers that are 'True' are trainable. 'False' are frozen.\")\n","\n","print(\"=============\")\n","print(named_model, \":\")\n","print(\"=============\")\n","# print(model)\n","print(\"=============\")\n","print(model.config)\n","print(\"=============\")\n","print(\"num_parameters:\", model.num_parameters())\n","print(\"=============\")\n","print(\"num_trainable_parameters:\", model.num_parameters(only_trainable=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UTv7BTh5VXQv","executionInfo":{"status":"ok","timestamp":1744253199387,"user_tz":420,"elapsed":16,"user":{"displayName":"J H","userId":"12017482157397552319"}},"outputId":"a38e2457-29a8-44b1-9c23-01f318705730"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["bert.embeddings.word_embeddings.weight requires_grad= True\n","bert.embeddings.position_embeddings.weight requires_grad= True\n","bert.embeddings.token_type_embeddings.weight requires_grad= True\n","bert.embeddings.LayerNorm.weight requires_grad= True\n","bert.embeddings.LayerNorm.bias requires_grad= True\n","bert.encoder.layer.0.attention.self.query.weight requires_grad= True\n","bert.encoder.layer.0.attention.self.query.bias requires_grad= True\n","bert.encoder.layer.0.attention.self.key.weight requires_grad= True\n","bert.encoder.layer.0.attention.self.key.bias requires_grad= True\n","bert.encoder.layer.0.attention.self.value.weight requires_grad= True\n","bert.encoder.layer.0.attention.self.value.bias requires_grad= True\n","bert.encoder.layer.0.attention.output.dense.weight requires_grad= True\n","bert.encoder.layer.0.attention.output.dense.bias requires_grad= True\n","bert.encoder.layer.0.attention.output.LayerNorm.weight requires_grad= True\n","bert.encoder.layer.0.attention.output.LayerNorm.bias requires_grad= True\n","bert.encoder.layer.0.intermediate.dense.weight requires_grad= True\n","bert.encoder.layer.0.intermediate.dense.bias requires_grad= True\n","bert.encoder.layer.0.output.dense.weight requires_grad= True\n","bert.encoder.layer.0.output.dense.bias requires_grad= True\n","bert.encoder.layer.0.output.LayerNorm.weight requires_grad= True\n","bert.encoder.layer.0.output.LayerNorm.bias requires_grad= True\n","bert.encoder.layer.1.attention.self.query.weight requires_grad= False\n","bert.encoder.layer.1.attention.self.query.bias requires_grad= False\n","bert.encoder.layer.1.attention.self.key.weight requires_grad= False\n","bert.encoder.layer.1.attention.self.key.bias requires_grad= False\n","bert.encoder.layer.1.attention.self.value.weight requires_grad= False\n","bert.encoder.layer.1.attention.self.value.bias requires_grad= False\n","bert.encoder.layer.1.attention.output.dense.weight requires_grad= False\n","bert.encoder.layer.1.attention.output.dense.bias requires_grad= False\n","bert.encoder.layer.1.attention.output.LayerNorm.weight requires_grad= False\n","bert.encoder.layer.1.attention.output.LayerNorm.bias requires_grad= False\n","bert.encoder.layer.1.intermediate.dense.weight requires_grad= False\n","bert.encoder.layer.1.intermediate.dense.bias requires_grad= False\n","bert.encoder.layer.1.output.dense.weight requires_grad= False\n","bert.encoder.layer.1.output.dense.bias requires_grad= False\n","bert.encoder.layer.1.output.LayerNorm.weight requires_grad= False\n","bert.encoder.layer.1.output.LayerNorm.bias requires_grad= False\n","bert.encoder.layer.2.attention.self.query.weight requires_grad= False\n","bert.encoder.layer.2.attention.self.query.bias requires_grad= False\n","bert.encoder.layer.2.attention.self.key.weight requires_grad= False\n","bert.encoder.layer.2.attention.self.key.bias requires_grad= False\n","bert.encoder.layer.2.attention.self.value.weight requires_grad= False\n","bert.encoder.layer.2.attention.self.value.bias requires_grad= False\n","bert.encoder.layer.2.attention.output.dense.weight requires_grad= False\n","bert.encoder.layer.2.attention.output.dense.bias requires_grad= False\n","bert.encoder.layer.2.attention.output.LayerNorm.weight requires_grad= False\n","bert.encoder.layer.2.attention.output.LayerNorm.bias requires_grad= False\n","bert.encoder.layer.2.intermediate.dense.weight requires_grad= False\n","bert.encoder.layer.2.intermediate.dense.bias requires_grad= False\n","bert.encoder.layer.2.output.dense.weight requires_grad= False\n","bert.encoder.layer.2.output.dense.bias requires_grad= False\n","bert.encoder.layer.2.output.LayerNorm.weight requires_grad= False\n","bert.encoder.layer.2.output.LayerNorm.bias requires_grad= False\n","bert.encoder.layer.3.attention.self.query.weight requires_grad= False\n","bert.encoder.layer.3.attention.self.query.bias requires_grad= False\n","bert.encoder.layer.3.attention.self.key.weight requires_grad= False\n","bert.encoder.layer.3.attention.self.key.bias requires_grad= False\n","bert.encoder.layer.3.attention.self.value.weight requires_grad= False\n","bert.encoder.layer.3.attention.self.value.bias requires_grad= False\n","bert.encoder.layer.3.attention.output.dense.weight requires_grad= False\n","bert.encoder.layer.3.attention.output.dense.bias requires_grad= False\n","bert.encoder.layer.3.attention.output.LayerNorm.weight requires_grad= False\n","bert.encoder.layer.3.attention.output.LayerNorm.bias requires_grad= False\n","bert.encoder.layer.3.intermediate.dense.weight requires_grad= False\n","bert.encoder.layer.3.intermediate.dense.bias requires_grad= False\n","bert.encoder.layer.3.output.dense.weight requires_grad= False\n","bert.encoder.layer.3.output.dense.bias requires_grad= False\n","bert.encoder.layer.3.output.LayerNorm.weight requires_grad= False\n","bert.encoder.layer.3.output.LayerNorm.bias requires_grad= False\n","bert.encoder.layer.4.attention.self.query.weight requires_grad= False\n","bert.encoder.layer.4.attention.self.query.bias requires_grad= False\n","bert.encoder.layer.4.attention.self.key.weight requires_grad= False\n","bert.encoder.layer.4.attention.self.key.bias requires_grad= False\n","bert.encoder.layer.4.attention.self.value.weight requires_grad= False\n","bert.encoder.layer.4.attention.self.value.bias requires_grad= False\n","bert.encoder.layer.4.attention.output.dense.weight requires_grad= False\n","bert.encoder.layer.4.attention.output.dense.bias requires_grad= False\n","bert.encoder.layer.4.attention.output.LayerNorm.weight requires_grad= False\n","bert.encoder.layer.4.attention.output.LayerNorm.bias requires_grad= False\n","bert.encoder.layer.4.intermediate.dense.weight requires_grad= False\n","bert.encoder.layer.4.intermediate.dense.bias requires_grad= False\n","bert.encoder.layer.4.output.dense.weight requires_grad= False\n","bert.encoder.layer.4.output.dense.bias requires_grad= False\n","bert.encoder.layer.4.output.LayerNorm.weight requires_grad= False\n","bert.encoder.layer.4.output.LayerNorm.bias requires_grad= False\n","bert.encoder.layer.5.attention.self.query.weight requires_grad= False\n","bert.encoder.layer.5.attention.self.query.bias requires_grad= False\n","bert.encoder.layer.5.attention.self.key.weight requires_grad= False\n","bert.encoder.layer.5.attention.self.key.bias requires_grad= False\n","bert.encoder.layer.5.attention.self.value.weight requires_grad= False\n","bert.encoder.layer.5.attention.self.value.bias requires_grad= False\n","bert.encoder.layer.5.attention.output.dense.weight requires_grad= False\n","bert.encoder.layer.5.attention.output.dense.bias requires_grad= False\n","bert.encoder.layer.5.attention.output.LayerNorm.weight requires_grad= False\n","bert.encoder.layer.5.attention.output.LayerNorm.bias requires_grad= False\n","bert.encoder.layer.5.intermediate.dense.weight requires_grad= False\n","bert.encoder.layer.5.intermediate.dense.bias requires_grad= False\n","bert.encoder.layer.5.output.dense.weight requires_grad= False\n","bert.encoder.layer.5.output.dense.bias requires_grad= False\n","bert.encoder.layer.5.output.LayerNorm.weight requires_grad= False\n","bert.encoder.layer.5.output.LayerNorm.bias requires_grad= False\n","bert.encoder.layer.6.attention.self.query.weight requires_grad= False\n","bert.encoder.layer.6.attention.self.query.bias requires_grad= False\n","bert.encoder.layer.6.attention.self.key.weight requires_grad= False\n","bert.encoder.layer.6.attention.self.key.bias requires_grad= False\n","bert.encoder.layer.6.attention.self.value.weight requires_grad= False\n","bert.encoder.layer.6.attention.self.value.bias requires_grad= False\n","bert.encoder.layer.6.attention.output.dense.weight requires_grad= False\n","bert.encoder.layer.6.attention.output.dense.bias requires_grad= False\n","bert.encoder.layer.6.attention.output.LayerNorm.weight requires_grad= False\n","bert.encoder.layer.6.attention.output.LayerNorm.bias requires_grad= False\n","bert.encoder.layer.6.intermediate.dense.weight requires_grad= False\n","bert.encoder.layer.6.intermediate.dense.bias requires_grad= False\n","bert.encoder.layer.6.output.dense.weight requires_grad= False\n","bert.encoder.layer.6.output.dense.bias requires_grad= False\n","bert.encoder.layer.6.output.LayerNorm.weight requires_grad= False\n","bert.encoder.layer.6.output.LayerNorm.bias requires_grad= False\n","bert.encoder.layer.7.attention.self.query.weight requires_grad= False\n","bert.encoder.layer.7.attention.self.query.bias requires_grad= False\n","bert.encoder.layer.7.attention.self.key.weight requires_grad= False\n","bert.encoder.layer.7.attention.self.key.bias requires_grad= False\n","bert.encoder.layer.7.attention.self.value.weight requires_grad= False\n","bert.encoder.layer.7.attention.self.value.bias requires_grad= False\n","bert.encoder.layer.7.attention.output.dense.weight requires_grad= False\n","bert.encoder.layer.7.attention.output.dense.bias requires_grad= False\n","bert.encoder.layer.7.attention.output.LayerNorm.weight requires_grad= False\n","bert.encoder.layer.7.attention.output.LayerNorm.bias requires_grad= False\n","bert.encoder.layer.7.intermediate.dense.weight requires_grad= False\n","bert.encoder.layer.7.intermediate.dense.bias requires_grad= False\n","bert.encoder.layer.7.output.dense.weight requires_grad= False\n","bert.encoder.layer.7.output.dense.bias requires_grad= False\n","bert.encoder.layer.7.output.LayerNorm.weight requires_grad= False\n","bert.encoder.layer.7.output.LayerNorm.bias requires_grad= False\n","bert.encoder.layer.8.attention.self.query.weight requires_grad= True\n","bert.encoder.layer.8.attention.self.query.bias requires_grad= True\n","bert.encoder.layer.8.attention.self.key.weight requires_grad= True\n","bert.encoder.layer.8.attention.self.key.bias requires_grad= True\n","bert.encoder.layer.8.attention.self.value.weight requires_grad= True\n","bert.encoder.layer.8.attention.self.value.bias requires_grad= True\n","bert.encoder.layer.8.attention.output.dense.weight requires_grad= True\n","bert.encoder.layer.8.attention.output.dense.bias requires_grad= True\n","bert.encoder.layer.8.attention.output.LayerNorm.weight requires_grad= True\n","bert.encoder.layer.8.attention.output.LayerNorm.bias requires_grad= True\n","bert.encoder.layer.8.intermediate.dense.weight requires_grad= True\n","bert.encoder.layer.8.intermediate.dense.bias requires_grad= True\n","bert.encoder.layer.8.output.dense.weight requires_grad= True\n","bert.encoder.layer.8.output.dense.bias requires_grad= True\n","bert.encoder.layer.8.output.LayerNorm.weight requires_grad= True\n","bert.encoder.layer.8.output.LayerNorm.bias requires_grad= True\n","bert.encoder.layer.9.attention.self.query.weight requires_grad= True\n","bert.encoder.layer.9.attention.self.query.bias requires_grad= True\n","bert.encoder.layer.9.attention.self.key.weight requires_grad= True\n","bert.encoder.layer.9.attention.self.key.bias requires_grad= True\n","bert.encoder.layer.9.attention.self.value.weight requires_grad= True\n","bert.encoder.layer.9.attention.self.value.bias requires_grad= True\n","bert.encoder.layer.9.attention.output.dense.weight requires_grad= True\n","bert.encoder.layer.9.attention.output.dense.bias requires_grad= True\n","bert.encoder.layer.9.attention.output.LayerNorm.weight requires_grad= True\n","bert.encoder.layer.9.attention.output.LayerNorm.bias requires_grad= True\n","bert.encoder.layer.9.intermediate.dense.weight requires_grad= True\n","bert.encoder.layer.9.intermediate.dense.bias requires_grad= True\n","bert.encoder.layer.9.output.dense.weight requires_grad= True\n","bert.encoder.layer.9.output.dense.bias requires_grad= True\n","bert.encoder.layer.9.output.LayerNorm.weight requires_grad= True\n","bert.encoder.layer.9.output.LayerNorm.bias requires_grad= True\n","bert.encoder.layer.10.attention.self.query.weight requires_grad= True\n","bert.encoder.layer.10.attention.self.query.bias requires_grad= True\n","bert.encoder.layer.10.attention.self.key.weight requires_grad= True\n","bert.encoder.layer.10.attention.self.key.bias requires_grad= True\n","bert.encoder.layer.10.attention.self.value.weight requires_grad= True\n","bert.encoder.layer.10.attention.self.value.bias requires_grad= True\n","bert.encoder.layer.10.attention.output.dense.weight requires_grad= True\n","bert.encoder.layer.10.attention.output.dense.bias requires_grad= True\n","bert.encoder.layer.10.attention.output.LayerNorm.weight requires_grad= True\n","bert.encoder.layer.10.attention.output.LayerNorm.bias requires_grad= True\n","bert.encoder.layer.10.intermediate.dense.weight requires_grad= True\n","bert.encoder.layer.10.intermediate.dense.bias requires_grad= True\n","bert.encoder.layer.10.output.dense.weight requires_grad= True\n","bert.encoder.layer.10.output.dense.bias requires_grad= True\n","bert.encoder.layer.10.output.LayerNorm.weight requires_grad= True\n","bert.encoder.layer.10.output.LayerNorm.bias requires_grad= True\n","bert.encoder.layer.11.attention.self.query.weight requires_grad= True\n","bert.encoder.layer.11.attention.self.query.bias requires_grad= True\n","bert.encoder.layer.11.attention.self.key.weight requires_grad= True\n","bert.encoder.layer.11.attention.self.key.bias requires_grad= True\n","bert.encoder.layer.11.attention.self.value.weight requires_grad= True\n","bert.encoder.layer.11.attention.self.value.bias requires_grad= True\n","bert.encoder.layer.11.attention.output.dense.weight requires_grad= True\n","bert.encoder.layer.11.attention.output.dense.bias requires_grad= True\n","bert.encoder.layer.11.attention.output.LayerNorm.weight requires_grad= True\n","bert.encoder.layer.11.attention.output.LayerNorm.bias requires_grad= True\n","bert.encoder.layer.11.intermediate.dense.weight requires_grad= True\n","bert.encoder.layer.11.intermediate.dense.bias requires_grad= True\n","bert.encoder.layer.11.output.dense.weight requires_grad= True\n","bert.encoder.layer.11.output.dense.bias requires_grad= True\n","bert.encoder.layer.11.output.LayerNorm.weight requires_grad= True\n","bert.encoder.layer.11.output.LayerNorm.bias requires_grad= True\n","bert.pooler.dense.weight requires_grad= True\n","bert.pooler.dense.bias requires_grad= True\n","classifier.weight requires_grad= True\n","classifier.bias requires_grad= True\n","\n","Layers that are 'True' are trainable. 'False' are frozen.\n","=============\n","bert-base-cased :\n","=============\n","=============\n","BertConfig {\n","  \"_attn_implementation_autoset\": true,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.50.3\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","=============\n","num_parameters: 108311810\n","=============\n","num_trainable_parameters: 58696706\n"]}]},{"cell_type":"markdown","source":["#### Dataset Preparation ** Run **"],"metadata":{"id":"s0vgf-iJZQzv"}},{"cell_type":"code","source":["# Tokenize & Prepare Datasets\n","\n","train_data_hf = prepare_dataset(\n","    df_train,\n","    tokenizer,\n","    text_col=x_col,\n","    label_col=y_col,\n","    max_length=length_max\n",")\n","\n","val_data_hf = prepare_dataset(\n","    df_val,\n","    tokenizer,\n","    text_col=x_col,\n","    label_col=y_col,\n","    max_length=length_max\n",")\n","\n","test_data_hf = prepare_dataset(\n","    df_test,\n","    tokenizer,\n","    text_col=x_col,\n","    label_col=y_col,\n","    max_length=length_max\n","\n",")\n","\n","print(\"Datasets prepared. Sample from train_data_hf:\\n\", train_data_hf[10])\n","# print(\"Datasets prepared. Sample from train_data_hf:\\n\", val_data_hf[10])\n","# print(\"Datasets prepared. Sample from train_data_hf:\\n\", test_data_hf[10])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":887,"referenced_widgets":["fdfa0482758a49ee910449e2a669a68b","f8d33b4b60b74ae98075043f79398b5c","b1aa88c0b866425d8aa65115770d7e73","79aad39ded724731bc5ac5b043851b51","8d81249603b543e09a69a7ff7dacf581","16510923ffe347f1881bdaa6e83799ef","0912b353df33468088adce074dbfefc7","af7f7292d7614c82a6a1017337a68493","28f943808db44d9b81cb96d6a84175ec","00adfd48e0864d7194a9129b35beb119","7683aedd7bdb4b69923152c62956e20f","c6541cc4bb064efda85349ee17a8ac4b","a4547f4391344fd586a2b600793f3b9e","d53d0fad3efe44bcb85a1173eb3cf702","bcd761e95aed48939aff8255d2a1d550","3883f3ef3f0948ee8226997637448022","27321a93bb254f399f19bcc9d3ecd160","d8354d724ecf4a1595dd9e74e6ce928c","83cde99485394f459d57396c0baf53be","06dc63594b3a46c4a15694c249a53fe4","bdb23d556b874d30880d411ed0d49c30","9eb857e339df462c9cd669b56cf3ef55","88b013b29ced4b28a592ec5f891fd3a1","0b355f2978be475b8d439a037d5c4f88","8315da9057c945f7a80479ffe4c16a45","5c25303a90444250a9cf4659e2fffd4b","0b9af45981e048beb39dcb5d380d1df5","00423dd5e9aa4636b319765a4af1703b","5aea9f54b38443939bcc812ffe9beb36","3d7f7ad43d4f40eea67667a3109ce3d9","e64f0b3dec66442481df2509fce7e5d6","60ecaa52be244295b6ffd38bc409fbf5","72fd7582e6ba43d48f8b63d7bfe2b7e1"]},"id":"bMQMoy5rcdLv","executionInfo":{"status":"ok","timestamp":1744253201161,"user_tz":420,"elapsed":1759,"user":{"displayName":"J H","userId":"12017482157397552319"}},"outputId":"26c2e139-c4c9-410c-dc02-f83a6b5023b7"},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/7662 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdfa0482758a49ee910449e2a669a68b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/421 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6541cc4bb064efda85349ee17a8ac4b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/917 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88b013b29ced4b28a592ec5f891fd3a1"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Datasets prepared. Sample from train_data_hf:\n"," {'labels': tensor(0), 'input_ids': tensor([  101,  1252,  1106,  1103,  3824,  1104, 19892, 11220,  1324,  1119,\n","         1522,  3839,   117,  1272,  1103,  1555,  1104,  1103, 11563,  5609,\n","         1106,  1172,   132,  1152,  2446,  1122,  1113,  1147,  3221,   119,\n","          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}\n"]}]},{"cell_type":"markdown","source":["### 3.1.1 from pretrained bert-base-cased Y: single task 1 & X: sentence_no_contractions — Y"],"metadata":{"id":"O_g9-bLdVBD_"}},{"cell_type":"code","source":["print(\"Experiment configuration used with this experiment:\")\n","print(\"model used:\", named_model)\n","print(\"learning rate used:\", learning_rate)\n","print(\"number of epochs:\", num_epochs)\n","print(\"maximum sequence length:\", length_max)\n","print(\"batch size used:\", size_batch)\n","print(\"regularization value:\", regularization_weight_decay)\n","print(\"outcome variable:\", y_col)\n","print(\"task:\", x_task)\n","print(\"input column:\", x_col)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x8hht2anjdDJ","executionInfo":{"status":"ok","timestamp":1744253201206,"user_tz":420,"elapsed":3,"user":{"displayName":"J H","userId":"12017482157397552319"}},"outputId":"91fd16a4-64a2-4356-8fcf-568a00a67ea9"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Experiment configuration used with this experiment:\n","model used: bert-base-cased\n","learning rate used: 1e-05\n","number of epochs: 25\n","maximum sequence length: 256\n","batch size used: 16\n","regularization value: 0.1\n","outcome variable: binary_complexity\n","task: single\n","input column: sentence_no_contractions\n"]}]},{"cell_type":"code","source":["# Train & Evaluate\n","\n","trained_model, trainer_obj = train_transformer_model(\n","    model=model,\n","    tokenizer=tokenizer,\n","    train_dataset=train_data_hf,\n","    val_dataset=val_data_hf,\n","    output_dir=dir_results,\n","    num_epochs=num_epochs,\n","    batch_size=size_batch,\n","    lr=learning_rate,\n","    weight_decay=regularization_weight_decay\n",")\n","\n","metrics = trainer_obj.evaluate()\n","print(\"Validation metrics:\", metrics)\n","\n","test_metrics = trainer_obj.evaluate(test_data_hf) if test_data_hf else None\n","print(\"Test metrics:\", test_metrics)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["e8fdc51a5289454395102158c6696361","7716f1ad936e440b978d1cac50219c20","8f33632ec73443ba9a56fb77a05da7b4","4f41754cde0e47f7b1135cc05fc199b5","7e6ad6ad15aa4bf3b6c3fe7d62f09540","bcf6bddbacb44c27bbb714c2e1e35613","66b109759aac47e79385c1b45f00a8df","64421ad2f91445b89db3d01065e5f6c9","59c4a04b0bfb4b3ea8843c94ff5e2da0","b9857a079a3d4e208796e039e92feea5","a838bbc1df8941fe8f7794fdc6fedaba","8c1eb0fe7ca949e6abe95b6bf93ba11f","2f1b9ec504154036b96af7cd4ca72870","f8230fd400dd44a896324369e4e25cc0","44be9aabbe444f01b2bdb436eecbe760","9421d72252944ffdbbe56bbcddff8ac2","54f5f5df7c074c4ba7fa30ba92380dd3","7b9a0192cd0d417fbbf0034358e1cb88","a89d8eadf04649f5a69397aca75218b8","21c49b327b6949d890b94b4e73decd54","00ed43489376487e8026ab11d9aeea6e","9259f4a77fef42e480fd71541d92f454","6c8e59ae30824e8e9ca9328e9aa27711","f36022111e9b43f0b8a76a127af601d8","3053b04020594928aae8093b7e188afc","ea4038bf79194a6d9b63fba05b180b4e","916371cb4c2b4f5386a20641b48152dd","fd86ec9b49374a15a9c5f1fad4329c93","3ecec126605a4832b0ab37a8fa3065cd","93f9c0df08054fca82a0d523e395c7a8","f1dbac022c2e4374826e40453902cabc","bd821eeee7c44ee19cbd00d40e3bd30e","7a693d5a44584d338d30c6bfb9b514ea","82f3894f78e2479f9a86727e3d5ae9f5","be202c87eae44c9aac5c15ba278d6dbb","606d479257164f4e863cd705ceba74a6","52cffb533c384380a25eb4d9a27574a0","902bb1993ae4406c86a2d5d92b17f09e","e80c57c2542c4d14aed0fea47cca48ba","6128bba2283a4bc68c0055ec10b3ad55","3d43094c01bc43d59280674dc76c1b94","aea12a2ff7f3428f8700933cf83a7d66","4b6a50bdcecb4077bfbd869aab6a7495","f46915056e8746cea132d4cc27beb5f1"]},"id":"-entrH9lieD0","executionInfo":{"status":"ok","timestamp":1744254844889,"user_tz":420,"elapsed":1643678,"user":{"displayName":"J H","userId":"12017482157397552319"}},"outputId":"c327faca-3fe5-4b08-994c-73f5efda1a0d"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","<ipython-input-20-c2ee9f934517>:31: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='11975' max='11975' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [11975/11975 27:14, Epoch 25/25]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.691400</td>\n","      <td>0.674979</td>\n","      <td>0.603325</td>\n","      <td>0.585034</td>\n","      <td>0.447917</td>\n","      <td>0.507375</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.668900</td>\n","      <td>0.672660</td>\n","      <td>0.581948</td>\n","      <td>0.595238</td>\n","      <td>0.260417</td>\n","      <td>0.362319</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.622800</td>\n","      <td>0.661327</td>\n","      <td>0.629454</td>\n","      <td>0.586538</td>\n","      <td>0.635417</td>\n","      <td>0.610000</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.563400</td>\n","      <td>0.671554</td>\n","      <td>0.638955</td>\n","      <td>0.603093</td>\n","      <td>0.609375</td>\n","      <td>0.606218</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.497800</td>\n","      <td>0.730583</td>\n","      <td>0.624703</td>\n","      <td>0.618056</td>\n","      <td>0.463542</td>\n","      <td>0.529762</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.435500</td>\n","      <td>0.802946</td>\n","      <td>0.610451</td>\n","      <td>0.581395</td>\n","      <td>0.520833</td>\n","      <td>0.549451</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.375700</td>\n","      <td>0.883296</td>\n","      <td>0.629454</td>\n","      <td>0.601124</td>\n","      <td>0.557292</td>\n","      <td>0.578378</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.339800</td>\n","      <td>0.985840</td>\n","      <td>0.610451</td>\n","      <td>0.574468</td>\n","      <td>0.562500</td>\n","      <td>0.568421</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.299200</td>\n","      <td>1.054664</td>\n","      <td>0.617577</td>\n","      <td>0.584699</td>\n","      <td>0.557292</td>\n","      <td>0.570667</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.265600</td>\n","      <td>1.173299</td>\n","      <td>0.605701</td>\n","      <td>0.601562</td>\n","      <td>0.401042</td>\n","      <td>0.481250</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.242400</td>\n","      <td>1.212402</td>\n","      <td>0.617577</td>\n","      <td>0.582888</td>\n","      <td>0.567708</td>\n","      <td>0.575198</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.229500</td>\n","      <td>1.283133</td>\n","      <td>0.596200</td>\n","      <td>0.566265</td>\n","      <td>0.489583</td>\n","      <td>0.525140</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.213600</td>\n","      <td>1.417778</td>\n","      <td>0.584323</td>\n","      <td>0.550898</td>\n","      <td>0.479167</td>\n","      <td>0.512535</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.208600</td>\n","      <td>1.435689</td>\n","      <td>0.593824</td>\n","      <td>0.562130</td>\n","      <td>0.494792</td>\n","      <td>0.526316</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.197200</td>\n","      <td>1.550017</td>\n","      <td>0.605701</td>\n","      <td>0.573864</td>\n","      <td>0.526042</td>\n","      <td>0.548913</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.189800</td>\n","      <td>1.586166</td>\n","      <td>0.589074</td>\n","      <td>0.559006</td>\n","      <td>0.468750</td>\n","      <td>0.509915</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>0.177400</td>\n","      <td>1.597647</td>\n","      <td>0.605701</td>\n","      <td>0.570652</td>\n","      <td>0.546875</td>\n","      <td>0.558511</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>0.173200</td>\n","      <td>1.702955</td>\n","      <td>0.600950</td>\n","      <td>0.562500</td>\n","      <td>0.562500</td>\n","      <td>0.562500</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>0.169300</td>\n","      <td>1.686311</td>\n","      <td>0.612827</td>\n","      <td>0.580110</td>\n","      <td>0.546875</td>\n","      <td>0.563003</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.161200</td>\n","      <td>1.748729</td>\n","      <td>0.600950</td>\n","      <td>0.568966</td>\n","      <td>0.515625</td>\n","      <td>0.540984</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>0.165200</td>\n","      <td>1.757036</td>\n","      <td>0.622328</td>\n","      <td>0.590164</td>\n","      <td>0.562500</td>\n","      <td>0.576000</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>0.156000</td>\n","      <td>1.807272</td>\n","      <td>0.615202</td>\n","      <td>0.581522</td>\n","      <td>0.557292</td>\n","      <td>0.569149</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>0.150100</td>\n","      <td>1.843412</td>\n","      <td>0.598575</td>\n","      <td>0.564972</td>\n","      <td>0.520833</td>\n","      <td>0.542005</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>0.140800</td>\n","      <td>1.860659</td>\n","      <td>0.605701</td>\n","      <td>0.570652</td>\n","      <td>0.546875</td>\n","      <td>0.558511</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>0.137700</td>\n","      <td>1.872748</td>\n","      <td>0.608076</td>\n","      <td>0.578035</td>\n","      <td>0.520833</td>\n","      <td>0.547945</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8fdc51a5289454395102158c6696361"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/7.56k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c1eb0fe7ca949e6abe95b6bf93ba11f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/7.38k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c8e59ae30824e8e9ca9328e9aa27711"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/6.79k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82f3894f78e2479f9a86727e3d5ae9f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='85' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [27/27 00:05]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Validation metrics: {'eval_loss': 1.8727476596832275, 'eval_accuracy': 0.6080760095011877, 'eval_precision': 0.5780346820809249, 'eval_recall': 0.5208333333333334, 'eval_f1': 0.547945205479452, 'eval_runtime': 2.6804, 'eval_samples_per_second': 157.064, 'eval_steps_per_second': 10.073, 'epoch': 25.0}\n","Test metrics: {'eval_loss': 1.9690210819244385, 'eval_accuracy': 0.5561613958560524, 'eval_precision': 0.5435897435897435, 'eval_recall': 0.48072562358276644, 'eval_f1': 0.5102286401925391, 'eval_runtime': 4.0332, 'eval_samples_per_second': 227.36, 'eval_steps_per_second': 14.38, 'epoch': 25.0}\n"]}]},{"cell_type":"code","source":["# save model checkpoint\n","\n","timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","model_save_path = os.path.join(dir_models, f\"{x_task}_{named_model}_{y_col}_{timestamp}\")\n","\n","trainer_obj.save_model(model_save_path)\n","print(f\"Model checkpoint saved to: {model_save_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dSTfG1W6lM9Q","executionInfo":{"status":"ok","timestamp":1744254846113,"user_tz":420,"elapsed":1222,"user":{"displayName":"J H","userId":"12017482157397552319"}},"outputId":"27133e46-c3b8-4caf-e8cb-e46db0c219f5"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Model checkpoint saved to: /content/drive/MyDrive/266-final/models/single_bert-base-cased_binary_complexity_20250410_031404\n"]}]},{"cell_type":"code","source":["experiment_info = {\n","    \"model_name\": named_model,\n","    \"learning_rate\": learning_rate,\n","    \"epochs\": num_epochs,\n","    \"batch_size\": size_batch,\n","    \"weight_decay\": regularization_weight_decay,\n","    \"x_task\": x_task,\n","    \"x_col\": x_col,\n","    \"y_col\": y_col,\n","    \"layers_to_unfreeze\": layers_to_unfreeze\n","}\n","\n","model_info = gather_model_details(trained_model)\n","\n","all_run_metrics = gather_all_run_metrics(\n","    trainer=trainer_obj,\n","    train_dataset=train_data_hf,\n","    val_dataset=val_data_hf,\n","    test_dataset=test_data_hf\n",")\n","\n","log_experiment_results_json(\n","    experiment_meta=experiment_info,\n","    model_details=model_info,\n","    run_metrics=all_run_metrics,\n","    log_file=log_filepath\n",")\n","\n","print(f\"EXPERIMENT LOGGED TO: {log_filepath}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":55},"id":"f5LV6aOj7dOj","executionInfo":{"status":"ok","timestamp":1744254879913,"user_tz":420,"elapsed":33786,"user":{"displayName":"J H","userId":"12017482157397552319"}},"outputId":"656b6176-4da3-4f9f-d0da-3864f0591900"},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='649' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [27/27 00:40]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["EXPERIMENT LOGGED TO: /content/drive/MyDrive/266-final/results/experiment_runs.txt\n"]}]},{"cell_type":"markdown","source":["### 3.1.2: from pretrained bert-base-cased Y: multi task 2 & X: sentence_no_contractions — Y"],"metadata":{"id":"214_LGGAzEWZ"}},{"cell_type":"code","source":["# Define Experiment Parameters\n","\n","named_model = \"bert-base-cased\"\n","# named_model = \"roberta-base\"\n","# named_model = \"bert-large\"\n","# named_model = \"roberta-large\"\n","# named_model = \"\" # modern bert\n","\n","# learning_rate = 1e-3\n","# learning_rate = 1e-4\n","learning_rate = 1e-5\n","# learning_rate = 5e-6\n","# learning_rate = 5e-7\n","# learning_rate = 5e-8\n","\n","# num_epochs = 1\n","# num_epochs = 3\n","# num_epochs = 5\n","num_epochs = 25\n","# num_epochs = 15\n","# num_epochs = 20\n","\n","# length_max = 128\n","length_max = 256\n","# length_max = 348\n","# length_max = 512\n","\n","# size_batch = 1\n","# size_batch = 4\n","# size_batch = 8\n","size_batch = 16\n","# size_batch = 24\n","# size_batch = 32\n","# size_batch = 64\n","# size_batch = 128\n","\n","# regularization_weight_decay = 0\n","regularization_weight_decay = 0.1\n","# regularization_weight_decay = 0.5\n","\n","y_col = \"binary_complexity\"\n","# y_col = \"complexity\"\n","\n","# x_task = \"single\"\n","x_task = \"multi\"\n","\n","# x_col = \"sentence\"\n","x_col = \"sentence_no_contractions\"\n","# x_col = \"pos_sequence\"\n","# x_col = \"dep_sequence\"\n","# x_col = \"morph_sequence\"\n","\n","if x_task == \"single\":\n","    df_train = train_single_df\n","    df_val   = trial_val_single_df\n","    df_test  = test_single_df\n","else:\n","    df_train = train_multi_df\n","    df_val   = trial_val_multi_df\n","    df_test  = test_multi_df\n","\n","custom_config = BertConfig.from_pretrained(\"bert-base-cased\")\n","\n","custom_config.hidden_dropout_prob = 0.1\n","# custom_config.intermediate_size = 3072\n","# custom_config.intermediate_size = 6144\n","# custom_config.num_attention_heads = 12\n","# custom_config.num_hidden_layers = 12\n","custom_config.gradient_checkpointing = False\n","custom_config.attention_probs_dropout_prob = 0.1\n","# custom_config.max_position_embeddings = 512\n","# custom_config.type_vocab_size = 2\n","custom_config.hidden_act = \"gelu\"  # alts: \"relu\" \"silu\"\n","# custom_config.vocab_size = 28996  # must match\n","\n","# model.bert.pooler.activation = nn.ReLU() # Tanh() replaced as the pooler layer activation function in side-by-side with 1.1\n"],"metadata":{"id":"_tqrSUw_zYLu","executionInfo":{"status":"ok","timestamp":1744254879989,"user_tz":420,"elapsed":70,"user":{"displayName":"J H","userId":"12017482157397552319"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["print(\"model checkpoints:\", dir_models)\n","!ls /content/drive/MyDrive/266-final/models/"],"metadata":{"id":"UtkPOzC0zYK-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1744254880097,"user_tz":420,"elapsed":106,"user":{"displayName":"J H","userId":"12017482157397552319"}},"outputId":"b74be15a-e4c6-4680-db32-d00f23fa6c4f"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["model checkpoints: /content/drive/MyDrive/266-final/models/\n","multi_bert-base-cased_binary_complexity_20250408_143322\n","multi_bert-base-cased_binary_complexity_20250409_175804\n","multi_bert-base-cased_binary_complexity_20250409_175954\n","multi_bert-base-cased_binary_complexity_20250409_180139\n","multi_bert-base-cased_binary_complexity_20250409_185057\n","multi_bert-base-cased_binary_complexity_20250409_185213\n","multi_bert-base-cased_binary_complexity_20250409_185333\n","multi_bert-base-cased_binary_complexity_20250409_234934\n","multi_bert-base-cased_binary_complexity_20250410_001637\n","multi_bert-base-cased_binary_complexity_20250410_003117\n","multi_bert-base-cased_binary_complexity_20250410_004527\n","single_bert-base-cased_binary_complexity_20250408_043117\n","single_bert-base-cased_binary_complexity_20250408_043334\n","single_bert-base-cased_binary_complexity_20250408_043750\n","single_bert-base-cased_binary_complexity_20250409_175702\n","single_bert-base-cased_binary_complexity_20250409_175900\n","single_bert-base-cased_binary_complexity_20250409_180045\n","single_bert-base-cased_binary_complexity_20250409_185027\n","single_bert-base-cased_binary_complexity_20250409_185141\n","single_bert-base-cased_binary_complexity_20250409_185303\n","single_bert-base-cased_binary_complexity_20250409_234236\n","single_bert-base-cased_binary_complexity_20250410_000508\n","single_bert-base-cased_binary_complexity_20250410_002813\n","single_bert-base-cased_binary_complexity_20250410_004230\n","single_bert-base-cased_binary_complexity_20250410_031404\n"]}]},{"cell_type":"code","source":["# Load Model & Tokenizer\n","# model, tokenizer = get_model_and_tokenizer(named_model) # deprecated argument structure\n","# model, tokenizer = get_model_and_tokenizer(\"/content/drive/MyDrive/266-final/models/....\") # proposed argument usage for checkpointed models\n","\n","# for name, param in model.named_parameters():\n","#     print(name)\n","\n","model, tokenizer = get_model_and_tokenizer(\n","    remote_model_name=\"bert-base-cased\",\n","    local_model_path=None,\n","    config=custom_config\n",")\n","\n","# model, tokenizer = get_model_and_tokenizer(\n","#     local_model_path=\"my_local_bert_path\",\n","#     config=custom_config\n","# )\n","\n","print(\"=============\")\n","print(named_model, \":\")\n","print(\"=============\")\n","# print(model)\n","print(\"=============\")\n","print(model.config)\n","print(\"=============\")\n","print(\"num_parameters:\", model.num_parameters())\n","print(\"=============\")\n","print(\"num_trainable_parameters:\", model.num_parameters(only_trainable=True))"],"metadata":{"id":"ApJjvZKmzYKT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1744254880561,"user_tz":420,"elapsed":462,"user":{"displayName":"J H","userId":"12017482157397552319"}},"outputId":"1fb8f166-799c-4f0a-af8a-32fd64a8750b"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading from Hugging Face model: bert-base-cased\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["=============\n","bert-base-cased :\n","=============\n","=============\n","BertConfig {\n","  \"_attn_implementation_autoset\": true,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.50.3\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","=============\n","num_parameters: 108311810\n","=============\n","num_trainable_parameters: 108311810\n"]}]},{"cell_type":"code","source":["# Freeze/Unfreeze Layers & Additional Activation Function Configuration\n","layers_to_unfreeze = [\n","    \"bert.embeddings.\",\n","    \"bert.encoder.layer.0.\",\n","    # \"bert.encoder.layer.1.\",\n","    \"bert.encoder.layer.8.\",\n","    \"bert.encoder.layer.9.\",\n","    \"bert.encoder.layer.10.\",\n","    \"bert.encoder.layer.11.\",\n","    \"bert.pooler.\",\n","    \"classifier.\",\n","]\n","\n","freeze_unfreeze_layers(model, layers_to_unfreeze=layers_to_unfreeze)\n","\n","for name, param in model.named_parameters():\n","    print(name, \"requires_grad=\", param.requires_grad)\n","\n","print(\"\\nLayers that are 'True' are trainable. 'False' are frozen.\")\n","\n","print(\"=============\")\n","print(named_model, \":\")\n","print(\"=============\")\n","# print(model)\n","print(\"=============\")\n","print(model.config)\n","print(\"=============\")\n","print(\"num_parameters:\", model.num_parameters())\n","print(\"=============\")\n","print(\"num_trainable_parameters:\", model.num_parameters(only_trainable=True))"],"metadata":{"id":"tX01cTvJzYJi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1744254880596,"user_tz":420,"elapsed":34,"user":{"displayName":"J H","userId":"12017482157397552319"}},"outputId":"486d85e9-f7b5-4e92-dd68-7f9d1dff2e4a"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["bert.embeddings.word_embeddings.weight requires_grad= True\n","bert.embeddings.position_embeddings.weight requires_grad= True\n","bert.embeddings.token_type_embeddings.weight requires_grad= True\n","bert.embeddings.LayerNorm.weight requires_grad= True\n","bert.embeddings.LayerNorm.bias requires_grad= True\n","bert.encoder.layer.0.attention.self.query.weight requires_grad= True\n","bert.encoder.layer.0.attention.self.query.bias requires_grad= True\n","bert.encoder.layer.0.attention.self.key.weight requires_grad= True\n","bert.encoder.layer.0.attention.self.key.bias requires_grad= True\n","bert.encoder.layer.0.attention.self.value.weight requires_grad= True\n","bert.encoder.layer.0.attention.self.value.bias requires_grad= True\n","bert.encoder.layer.0.attention.output.dense.weight requires_grad= True\n","bert.encoder.layer.0.attention.output.dense.bias requires_grad= True\n","bert.encoder.layer.0.attention.output.LayerNorm.weight requires_grad= True\n","bert.encoder.layer.0.attention.output.LayerNorm.bias requires_grad= True\n","bert.encoder.layer.0.intermediate.dense.weight requires_grad= True\n","bert.encoder.layer.0.intermediate.dense.bias requires_grad= True\n","bert.encoder.layer.0.output.dense.weight requires_grad= True\n","bert.encoder.layer.0.output.dense.bias requires_grad= True\n","bert.encoder.layer.0.output.LayerNorm.weight requires_grad= True\n","bert.encoder.layer.0.output.LayerNorm.bias requires_grad= True\n","bert.encoder.layer.1.attention.self.query.weight requires_grad= False\n","bert.encoder.layer.1.attention.self.query.bias requires_grad= False\n","bert.encoder.layer.1.attention.self.key.weight requires_grad= False\n","bert.encoder.layer.1.attention.self.key.bias requires_grad= False\n","bert.encoder.layer.1.attention.self.value.weight requires_grad= False\n","bert.encoder.layer.1.attention.self.value.bias requires_grad= False\n","bert.encoder.layer.1.attention.output.dense.weight requires_grad= False\n","bert.encoder.layer.1.attention.output.dense.bias requires_grad= False\n","bert.encoder.layer.1.attention.output.LayerNorm.weight requires_grad= False\n","bert.encoder.layer.1.attention.output.LayerNorm.bias requires_grad= False\n","bert.encoder.layer.1.intermediate.dense.weight requires_grad= False\n","bert.encoder.layer.1.intermediate.dense.bias requires_grad= False\n","bert.encoder.layer.1.output.dense.weight requires_grad= False\n","bert.encoder.layer.1.output.dense.bias requires_grad= False\n","bert.encoder.layer.1.output.LayerNorm.weight requires_grad= False\n","bert.encoder.layer.1.output.LayerNorm.bias requires_grad= False\n","bert.encoder.layer.2.attention.self.query.weight requires_grad= False\n","bert.encoder.layer.2.attention.self.query.bias requires_grad= False\n","bert.encoder.layer.2.attention.self.key.weight requires_grad= False\n","bert.encoder.layer.2.attention.self.key.bias requires_grad= False\n","bert.encoder.layer.2.attention.self.value.weight requires_grad= False\n","bert.encoder.layer.2.attention.self.value.bias requires_grad= False\n","bert.encoder.layer.2.attention.output.dense.weight requires_grad= False\n","bert.encoder.layer.2.attention.output.dense.bias requires_grad= False\n","bert.encoder.layer.2.attention.output.LayerNorm.weight requires_grad= False\n","bert.encoder.layer.2.attention.output.LayerNorm.bias requires_grad= False\n","bert.encoder.layer.2.intermediate.dense.weight requires_grad= False\n","bert.encoder.layer.2.intermediate.dense.bias requires_grad= False\n","bert.encoder.layer.2.output.dense.weight requires_grad= False\n","bert.encoder.layer.2.output.dense.bias requires_grad= False\n","bert.encoder.layer.2.output.LayerNorm.weight requires_grad= False\n","bert.encoder.layer.2.output.LayerNorm.bias requires_grad= False\n","bert.encoder.layer.3.attention.self.query.weight requires_grad= False\n","bert.encoder.layer.3.attention.self.query.bias requires_grad= False\n","bert.encoder.layer.3.attention.self.key.weight requires_grad= False\n","bert.encoder.layer.3.attention.self.key.bias requires_grad= False\n","bert.encoder.layer.3.attention.self.value.weight requires_grad= False\n","bert.encoder.layer.3.attention.self.value.bias requires_grad= False\n","bert.encoder.layer.3.attention.output.dense.weight requires_grad= False\n","bert.encoder.layer.3.attention.output.dense.bias requires_grad= False\n","bert.encoder.layer.3.attention.output.LayerNorm.weight requires_grad= False\n","bert.encoder.layer.3.attention.output.LayerNorm.bias requires_grad= False\n","bert.encoder.layer.3.intermediate.dense.weight requires_grad= False\n","bert.encoder.layer.3.intermediate.dense.bias requires_grad= False\n","bert.encoder.layer.3.output.dense.weight requires_grad= False\n","bert.encoder.layer.3.output.dense.bias requires_grad= False\n","bert.encoder.layer.3.output.LayerNorm.weight requires_grad= False\n","bert.encoder.layer.3.output.LayerNorm.bias requires_grad= False\n","bert.encoder.layer.4.attention.self.query.weight requires_grad= False\n","bert.encoder.layer.4.attention.self.query.bias requires_grad= False\n","bert.encoder.layer.4.attention.self.key.weight requires_grad= False\n","bert.encoder.layer.4.attention.self.key.bias requires_grad= False\n","bert.encoder.layer.4.attention.self.value.weight requires_grad= False\n","bert.encoder.layer.4.attention.self.value.bias requires_grad= False\n","bert.encoder.layer.4.attention.output.dense.weight requires_grad= False\n","bert.encoder.layer.4.attention.output.dense.bias requires_grad= False\n","bert.encoder.layer.4.attention.output.LayerNorm.weight requires_grad= False\n","bert.encoder.layer.4.attention.output.LayerNorm.bias requires_grad= False\n","bert.encoder.layer.4.intermediate.dense.weight requires_grad= False\n","bert.encoder.layer.4.intermediate.dense.bias requires_grad= False\n","bert.encoder.layer.4.output.dense.weight requires_grad= False\n","bert.encoder.layer.4.output.dense.bias requires_grad= False\n","bert.encoder.layer.4.output.LayerNorm.weight requires_grad= False\n","bert.encoder.layer.4.output.LayerNorm.bias requires_grad= False\n","bert.encoder.layer.5.attention.self.query.weight requires_grad= False\n","bert.encoder.layer.5.attention.self.query.bias requires_grad= False\n","bert.encoder.layer.5.attention.self.key.weight requires_grad= False\n","bert.encoder.layer.5.attention.self.key.bias requires_grad= False\n","bert.encoder.layer.5.attention.self.value.weight requires_grad= False\n","bert.encoder.layer.5.attention.self.value.bias requires_grad= False\n","bert.encoder.layer.5.attention.output.dense.weight requires_grad= False\n","bert.encoder.layer.5.attention.output.dense.bias requires_grad= False\n","bert.encoder.layer.5.attention.output.LayerNorm.weight requires_grad= False\n","bert.encoder.layer.5.attention.output.LayerNorm.bias requires_grad= False\n","bert.encoder.layer.5.intermediate.dense.weight requires_grad= False\n","bert.encoder.layer.5.intermediate.dense.bias requires_grad= False\n","bert.encoder.layer.5.output.dense.weight requires_grad= False\n","bert.encoder.layer.5.output.dense.bias requires_grad= False\n","bert.encoder.layer.5.output.LayerNorm.weight requires_grad= False\n","bert.encoder.layer.5.output.LayerNorm.bias requires_grad= False\n","bert.encoder.layer.6.attention.self.query.weight requires_grad= False\n","bert.encoder.layer.6.attention.self.query.bias requires_grad= False\n","bert.encoder.layer.6.attention.self.key.weight requires_grad= False\n","bert.encoder.layer.6.attention.self.key.bias requires_grad= False\n","bert.encoder.layer.6.attention.self.value.weight requires_grad= False\n","bert.encoder.layer.6.attention.self.value.bias requires_grad= False\n","bert.encoder.layer.6.attention.output.dense.weight requires_grad= False\n","bert.encoder.layer.6.attention.output.dense.bias requires_grad= False\n","bert.encoder.layer.6.attention.output.LayerNorm.weight requires_grad= False\n","bert.encoder.layer.6.attention.output.LayerNorm.bias requires_grad= False\n","bert.encoder.layer.6.intermediate.dense.weight requires_grad= False\n","bert.encoder.layer.6.intermediate.dense.bias requires_grad= False\n","bert.encoder.layer.6.output.dense.weight requires_grad= False\n","bert.encoder.layer.6.output.dense.bias requires_grad= False\n","bert.encoder.layer.6.output.LayerNorm.weight requires_grad= False\n","bert.encoder.layer.6.output.LayerNorm.bias requires_grad= False\n","bert.encoder.layer.7.attention.self.query.weight requires_grad= False\n","bert.encoder.layer.7.attention.self.query.bias requires_grad= False\n","bert.encoder.layer.7.attention.self.key.weight requires_grad= False\n","bert.encoder.layer.7.attention.self.key.bias requires_grad= False\n","bert.encoder.layer.7.attention.self.value.weight requires_grad= False\n","bert.encoder.layer.7.attention.self.value.bias requires_grad= False\n","bert.encoder.layer.7.attention.output.dense.weight requires_grad= False\n","bert.encoder.layer.7.attention.output.dense.bias requires_grad= False\n","bert.encoder.layer.7.attention.output.LayerNorm.weight requires_grad= False\n","bert.encoder.layer.7.attention.output.LayerNorm.bias requires_grad= False\n","bert.encoder.layer.7.intermediate.dense.weight requires_grad= False\n","bert.encoder.layer.7.intermediate.dense.bias requires_grad= False\n","bert.encoder.layer.7.output.dense.weight requires_grad= False\n","bert.encoder.layer.7.output.dense.bias requires_grad= False\n","bert.encoder.layer.7.output.LayerNorm.weight requires_grad= False\n","bert.encoder.layer.7.output.LayerNorm.bias requires_grad= False\n","bert.encoder.layer.8.attention.self.query.weight requires_grad= True\n","bert.encoder.layer.8.attention.self.query.bias requires_grad= True\n","bert.encoder.layer.8.attention.self.key.weight requires_grad= True\n","bert.encoder.layer.8.attention.self.key.bias requires_grad= True\n","bert.encoder.layer.8.attention.self.value.weight requires_grad= True\n","bert.encoder.layer.8.attention.self.value.bias requires_grad= True\n","bert.encoder.layer.8.attention.output.dense.weight requires_grad= True\n","bert.encoder.layer.8.attention.output.dense.bias requires_grad= True\n","bert.encoder.layer.8.attention.output.LayerNorm.weight requires_grad= True\n","bert.encoder.layer.8.attention.output.LayerNorm.bias requires_grad= True\n","bert.encoder.layer.8.intermediate.dense.weight requires_grad= True\n","bert.encoder.layer.8.intermediate.dense.bias requires_grad= True\n","bert.encoder.layer.8.output.dense.weight requires_grad= True\n","bert.encoder.layer.8.output.dense.bias requires_grad= True\n","bert.encoder.layer.8.output.LayerNorm.weight requires_grad= True\n","bert.encoder.layer.8.output.LayerNorm.bias requires_grad= True\n","bert.encoder.layer.9.attention.self.query.weight requires_grad= True\n","bert.encoder.layer.9.attention.self.query.bias requires_grad= True\n","bert.encoder.layer.9.attention.self.key.weight requires_grad= True\n","bert.encoder.layer.9.attention.self.key.bias requires_grad= True\n","bert.encoder.layer.9.attention.self.value.weight requires_grad= True\n","bert.encoder.layer.9.attention.self.value.bias requires_grad= True\n","bert.encoder.layer.9.attention.output.dense.weight requires_grad= True\n","bert.encoder.layer.9.attention.output.dense.bias requires_grad= True\n","bert.encoder.layer.9.attention.output.LayerNorm.weight requires_grad= True\n","bert.encoder.layer.9.attention.output.LayerNorm.bias requires_grad= True\n","bert.encoder.layer.9.intermediate.dense.weight requires_grad= True\n","bert.encoder.layer.9.intermediate.dense.bias requires_grad= True\n","bert.encoder.layer.9.output.dense.weight requires_grad= True\n","bert.encoder.layer.9.output.dense.bias requires_grad= True\n","bert.encoder.layer.9.output.LayerNorm.weight requires_grad= True\n","bert.encoder.layer.9.output.LayerNorm.bias requires_grad= True\n","bert.encoder.layer.10.attention.self.query.weight requires_grad= True\n","bert.encoder.layer.10.attention.self.query.bias requires_grad= True\n","bert.encoder.layer.10.attention.self.key.weight requires_grad= True\n","bert.encoder.layer.10.attention.self.key.bias requires_grad= True\n","bert.encoder.layer.10.attention.self.value.weight requires_grad= True\n","bert.encoder.layer.10.attention.self.value.bias requires_grad= True\n","bert.encoder.layer.10.attention.output.dense.weight requires_grad= True\n","bert.encoder.layer.10.attention.output.dense.bias requires_grad= True\n","bert.encoder.layer.10.attention.output.LayerNorm.weight requires_grad= True\n","bert.encoder.layer.10.attention.output.LayerNorm.bias requires_grad= True\n","bert.encoder.layer.10.intermediate.dense.weight requires_grad= True\n","bert.encoder.layer.10.intermediate.dense.bias requires_grad= True\n","bert.encoder.layer.10.output.dense.weight requires_grad= True\n","bert.encoder.layer.10.output.dense.bias requires_grad= True\n","bert.encoder.layer.10.output.LayerNorm.weight requires_grad= True\n","bert.encoder.layer.10.output.LayerNorm.bias requires_grad= True\n","bert.encoder.layer.11.attention.self.query.weight requires_grad= True\n","bert.encoder.layer.11.attention.self.query.bias requires_grad= True\n","bert.encoder.layer.11.attention.self.key.weight requires_grad= True\n","bert.encoder.layer.11.attention.self.key.bias requires_grad= True\n","bert.encoder.layer.11.attention.self.value.weight requires_grad= True\n","bert.encoder.layer.11.attention.self.value.bias requires_grad= True\n","bert.encoder.layer.11.attention.output.dense.weight requires_grad= True\n","bert.encoder.layer.11.attention.output.dense.bias requires_grad= True\n","bert.encoder.layer.11.attention.output.LayerNorm.weight requires_grad= True\n","bert.encoder.layer.11.attention.output.LayerNorm.bias requires_grad= True\n","bert.encoder.layer.11.intermediate.dense.weight requires_grad= True\n","bert.encoder.layer.11.intermediate.dense.bias requires_grad= True\n","bert.encoder.layer.11.output.dense.weight requires_grad= True\n","bert.encoder.layer.11.output.dense.bias requires_grad= True\n","bert.encoder.layer.11.output.LayerNorm.weight requires_grad= True\n","bert.encoder.layer.11.output.LayerNorm.bias requires_grad= True\n","bert.pooler.dense.weight requires_grad= True\n","bert.pooler.dense.bias requires_grad= True\n","classifier.weight requires_grad= True\n","classifier.bias requires_grad= True\n","\n","Layers that are 'True' are trainable. 'False' are frozen.\n","=============\n","bert-base-cased :\n","=============\n","=============\n","BertConfig {\n","  \"_attn_implementation_autoset\": true,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.50.3\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","=============\n","num_parameters: 108311810\n","=============\n","num_trainable_parameters: 58696706\n"]}]},{"cell_type":"code","source":["print(\"Experiment configuration used with this experiment:\")\n","print(\"model used:\", named_model)\n","print(\"learning rate used:\", learning_rate)\n","print(\"number of epochs:\", num_epochs)\n","print(\"maximum sequence length:\", length_max)\n","print(\"batch size used:\", size_batch)\n","print(\"regularization value:\", regularization_weight_decay)\n","print(\"outcome variable:\", y_col)\n","print(\"task:\", x_task)\n","print(\"input column:\", x_col)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jQAeXhzvyjVL","executionInfo":{"status":"ok","timestamp":1744254880600,"user_tz":420,"elapsed":5,"user":{"displayName":"J H","userId":"12017482157397552319"}},"outputId":"112650a3-6740-4e84-c9e2-23a1ac635d44"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Experiment configuration used with this experiment:\n","model used: bert-base-cased\n","learning rate used: 1e-05\n","number of epochs: 25\n","maximum sequence length: 256\n","batch size used: 16\n","regularization value: 0.1\n","outcome variable: binary_complexity\n","task: multi\n","input column: sentence_no_contractions\n"]}]},{"cell_type":"code","source":["def validate_dataframe(df, df_name):\n","    \"\"\"\n","    Performs basic functional tests on a pandas DataFrame\n","    to ensure it matches expected structure and content.\n","    \"\"\"\n","    print(f\"\\n[VALIDATION] Checking {df_name}...\")\n","\n","    # 1) Check shape\n","    print(f\" - Shape: {df.shape}\")\n","\n","    # 2) Check columns\n","    print(f\" - Columns: {list(df.columns)}\")\n","\n","    # 3) Check label distribution (assuming 'binary_complexity' is the label)\n","    if \"binary_complexity\" in df.columns:\n","        label_counts = df[\"binary_complexity\"].value_counts(dropna=False)\n","        print(f\" - Label distribution:\\n{label_counts}\")\n","    else:\n","        print(\" - WARNING: 'binary_complexity' column not found!\")\n","\n","    # 4) Peek at top few rows\n","    print(\" - Sample rows:\\n\", df.head(3))\n","\n","validate_dataframe(train_multi_df, \"train_multi_df\")\n","validate_dataframe(trial_val_multi_df, \"trial_val_multi_df\")\n","validate_dataframe(test_multi_df, \"test_multi_df\")"],"metadata":{"id":"YgSb20u10VcA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1744254880604,"user_tz":420,"elapsed":3,"user":{"displayName":"J H","userId":"12017482157397552319"}},"outputId":"aa2dce26-8410-4f38-a8ff-f2731a0e6546"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","[VALIDATION] Checking train_multi_df...\n"," - Shape: (1517, 12)\n"," - Columns: ['id', 'corpus', 'sentence', 'token', 'complexity', 'sentence_no_contractions', 'contraction_expanded', 'pos_sequence', 'dep_sequence', 'morph_sequence', 'morph_complexity', 'binary_complexity']\n"," - Label distribution:\n","binary_complexity\n","0    759\n","1    758\n","Name: count, dtype: int64\n"," - Sample rows:\n","                                id corpus  \\\n","0  3S37Y8CWI80N8KVM53U4E6JKCDC4WE  bible   \n","1  3WGCNLZJKF877FYC1Q6COKNWTDWD11  bible   \n","2  3UOMW19E6D6WQ5TH2HDD74IVKTP5CB  bible   \n","\n","                                            sentence            token  \\\n","0  but the seventh day is a Sabbath to Yahweh you...      seventh day   \n","1  But let each man test his own work, and then h...         own work   \n","2  To him who by understanding made the heavens; ...  loving kindness   \n","\n","   complexity                           sentence_no_contractions  \\\n","0    0.027778  but the seventh day is a Sabbath to Yahweh you...   \n","1    0.050000  But let each man test his own work, and then h...   \n","2    0.050000  To him who by understanding made the heavens; ...   \n","\n","   contraction_expanded                                       pos_sequence  \\\n","0                 False  ['CCONJ', 'DET', 'ADJ', 'NOUN', 'AUX', 'DET', ...   \n","1                 False  ['CCONJ', 'VERB', 'DET', 'NOUN', 'VERB', 'PRON...   \n","2                 False  ['ADP', 'PRON', 'PRON', 'ADP', 'VERB', 'VERB',...   \n","\n","                                        dep_sequence  \\\n","0  ['cc', 'det', 'amod', 'nsubj', 'ccomp', 'det',...   \n","1  ['cc', 'ROOT', 'det', 'nsubj', 'ccomp', 'poss'...   \n","2  ['prep', 'pobj', 'nsubj', 'prep', 'pcomp', 'ad...   \n","\n","                                      morph_sequence  morph_complexity  \\\n","0  [ConjType=Cmp, Definite=Def|PronType=Art, Degr...          1.341772   \n","1  [ConjType=Cmp, VerbForm=Inf, , Number=Sing, Ve...          1.608696   \n","2  [, Case=Acc|Gender=Masc|Number=Sing|Person=3|P...          1.562500   \n","\n","   binary_complexity  \n","0                  0  \n","1                  0  \n","2                  0  \n","\n","[VALIDATION] Checking trial_val_multi_df...\n"," - Shape: (99, 12)\n"," - Columns: ['id', 'corpus', 'sentence', 'token', 'complexity', 'sentence_no_contractions', 'contraction_expanded', 'pos_sequence', 'dep_sequence', 'morph_sequence', 'morph_complexity', 'binary_complexity']\n"," - Label distribution:\n","binary_complexity\n","1    51\n","0    48\n","Name: count, dtype: int64\n"," - Sample rows:\n","                                id corpus  \\\n","0  31HLTCK4BLVQ5BO1AUR91TX9V9IVGH  bible   \n","1  389A2A304OIXVY7G5B71Q9M43LE0CL  bible   \n","2  31N9JPQXIPIRX2A3S9N0CCFXO6TNHR  bible   \n","\n","                                            sentence          token  \\\n","0  The name of one son was Gershom, for Moses sai...   foreign land   \n","1  unleavened bread, unleavened cakes mixed with ...    wheat flour   \n","2  However the high places were not taken away; t...  burnt incense   \n","\n","   complexity                           sentence_no_contractions  \\\n","0    0.000000  The name of one son was Gershom, for Moses sai...   \n","1    0.157895  unleavened bread, unleavened cakes mixed with ...   \n","2    0.200000  However the high places were not taken away; t...   \n","\n","   contraction_expanded                                       pos_sequence  \\\n","0                 False  ['DET', 'NOUN', 'ADP', 'NUM', 'NOUN', 'AUX', '...   \n","1                 False  ['ADJ', 'NOUN', 'PUNCT', 'ADJ', 'NOUN', 'VERB'...   \n","2                 False  ['ADV', 'DET', 'ADJ', 'NOUN', 'AUX', 'PART', '...   \n","\n","                                        dep_sequence  \\\n","0  ['det', 'nsubj', 'prep', 'nummod', 'pobj', 'RO...   \n","1  ['amod', 'dep', 'punct', 'amod', 'appos', 'acl...   \n","2  ['advmod', 'det', 'amod', 'nsubjpass', 'auxpas...   \n","\n","                                      morph_sequence  morph_complexity  \\\n","0  [Definite=Def|PronType=Art, Number=Sing, , Num...          1.520000   \n","1  [Degree=Pos, Number=Sing, PunctType=Comm, Degr...          1.200000   \n","2  [, Definite=Def|PronType=Art, Degree=Pos, Numb...          1.190476   \n","\n","   binary_complexity  \n","0                  0  \n","1                  0  \n","2                  0  \n","\n","[VALIDATION] Checking test_multi_df...\n"," - Shape: (184, 12)\n"," - Columns: ['id', 'corpus', 'sentence', 'token', 'complexity', 'sentence_no_contractions', 'contraction_expanded', 'pos_sequence', 'dep_sequence', 'morph_sequence', 'morph_complexity', 'binary_complexity']\n"," - Label distribution:\n","binary_complexity\n","1    99\n","0    85\n","Name: count, dtype: int64\n"," - Sample rows:\n","                                id corpus  \\\n","0  3UXQ63NLAAMRIP4WG4XPD98AOYOBLX  bible   \n","1  3FJ2RVH25Z62TA3R8E1O77EBUYU92W  bible   \n","2  3YO4AH2FPDK1PZHZAT8WAEBL70EQ0F  bible   \n","\n","                                            sentence          token  \\\n","0  for he had an only daughter, about twelve year...  only daughter   \n","1  All these were cities fortified with high wall...     high walls   \n","2  In the morning, 'It will be foul weather today...  weather today   \n","\n","   complexity                           sentence_no_contractions  \\\n","0       0.025  for he had an only daughter, about twelve year...   \n","1       0.100  All these were cities fortified with high wall...   \n","2       0.125  In the morning, 'It will be foul weather today...   \n","\n","   contraction_expanded                                       pos_sequence  \\\n","0                 False  ['SCONJ', 'PRON', 'VERB', 'DET', 'ADJ', 'NOUN'...   \n","1                 False  ['DET', 'PRON', 'AUX', 'NOUN', 'VERB', 'ADP', ...   \n","2                 False  ['ADP', 'DET', 'NOUN', 'PUNCT', 'PUNCT', 'PRON...   \n","\n","                                        dep_sequence  \\\n","0  ['mark', 'nsubj', 'ROOT', 'det', 'amod', 'dobj...   \n","1  ['predet', 'nsubj', 'ROOT', 'attr', 'acl', 'pr...   \n","2  ['prep', 'det', 'pobj', 'punct', 'punct', 'nsu...   \n","\n","                                      morph_sequence  morph_complexity  \\\n","0  [, Case=Nom|Gender=Masc|Number=Sing|Person=3|P...          1.722222   \n","1  [, Number=Plur|PronType=Dem, Mood=Ind|Tense=Pa...          1.136364   \n","2  [, Definite=Def|PronType=Art, Number=Sing, Pun...          1.476190   \n","\n","   binary_complexity  \n","0                  0  \n","1                  0  \n","2                  0  \n"]}]},{"cell_type":"code","source":["# Train & Evaluate\n","\n","trained_model, trainer_obj = train_transformer_model(\n","    model = model,\n","    tokenizer = tokenizer,\n","    train_dataset = train_data_hf,\n","    val_dataset = val_data_hf,\n","    output_dir = dir_results,\n","    num_epochs = num_epochs,\n","    batch_size = size_batch,\n","    lr = learning_rate,\n","    weight_decay = regularization_weight_decay\n",")\n","\n","metrics = trainer_obj.evaluate()\n","print(\"Validation metrics:\", metrics)\n","\n","test_metrics = trainer_obj.evaluate(test_data_hf) if test_data_hf else None\n","print(\"Test metrics:\", test_metrics)"],"metadata":{"id":"5a08UyPTzXxM","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1744256523186,"user_tz":420,"elapsed":1642582,"user":{"displayName":"J H","userId":"12017482157397552319"}},"outputId":"fc2b0805-857b-47f6-fc14-dda259115d76"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","<ipython-input-20-c2ee9f934517>:31: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='11975' max='11975' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [11975/11975 27:15, Epoch 25/25]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.691800</td>\n","      <td>0.667800</td>\n","      <td>0.605701</td>\n","      <td>0.594203</td>\n","      <td>0.427083</td>\n","      <td>0.496970</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.665200</td>\n","      <td>0.665261</td>\n","      <td>0.570071</td>\n","      <td>0.541985</td>\n","      <td>0.369792</td>\n","      <td>0.439628</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.612300</td>\n","      <td>0.666243</td>\n","      <td>0.629454</td>\n","      <td>0.566667</td>\n","      <td>0.796875</td>\n","      <td>0.662338</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.557100</td>\n","      <td>0.666386</td>\n","      <td>0.646081</td>\n","      <td>0.592275</td>\n","      <td>0.718750</td>\n","      <td>0.649412</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.490800</td>\n","      <td>0.728687</td>\n","      <td>0.648456</td>\n","      <td>0.599099</td>\n","      <td>0.692708</td>\n","      <td>0.642512</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.430700</td>\n","      <td>0.809132</td>\n","      <td>0.627078</td>\n","      <td>0.580645</td>\n","      <td>0.656250</td>\n","      <td>0.616137</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.377100</td>\n","      <td>0.881357</td>\n","      <td>0.636580</td>\n","      <td>0.589041</td>\n","      <td>0.671875</td>\n","      <td>0.627737</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.336500</td>\n","      <td>0.957735</td>\n","      <td>0.619952</td>\n","      <td>0.576190</td>\n","      <td>0.630208</td>\n","      <td>0.601990</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.303000</td>\n","      <td>1.046776</td>\n","      <td>0.610451</td>\n","      <td>0.564220</td>\n","      <td>0.640625</td>\n","      <td>0.600000</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.263400</td>\n","      <td>1.083331</td>\n","      <td>0.624703</td>\n","      <td>0.591398</td>\n","      <td>0.572917</td>\n","      <td>0.582011</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.243100</td>\n","      <td>1.162388</td>\n","      <td>0.627078</td>\n","      <td>0.586207</td>\n","      <td>0.619792</td>\n","      <td>0.602532</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.232800</td>\n","      <td>1.227434</td>\n","      <td>0.638955</td>\n","      <td>0.604167</td>\n","      <td>0.604167</td>\n","      <td>0.604167</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.219300</td>\n","      <td>1.348338</td>\n","      <td>0.600950</td>\n","      <td>0.558824</td>\n","      <td>0.593750</td>\n","      <td>0.575758</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.215900</td>\n","      <td>1.351660</td>\n","      <td>0.615202</td>\n","      <td>0.575000</td>\n","      <td>0.598958</td>\n","      <td>0.586735</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.195700</td>\n","      <td>1.483722</td>\n","      <td>0.622328</td>\n","      <td>0.580488</td>\n","      <td>0.619792</td>\n","      <td>0.599496</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.194400</td>\n","      <td>1.519741</td>\n","      <td>0.603325</td>\n","      <td>0.565445</td>\n","      <td>0.562500</td>\n","      <td>0.563969</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>0.184000</td>\n","      <td>1.566552</td>\n","      <td>0.605701</td>\n","      <td>0.560748</td>\n","      <td>0.625000</td>\n","      <td>0.591133</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>0.172500</td>\n","      <td>1.659054</td>\n","      <td>0.605701</td>\n","      <td>0.567010</td>\n","      <td>0.572917</td>\n","      <td>0.569948</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>0.171900</td>\n","      <td>1.659035</td>\n","      <td>0.608076</td>\n","      <td>0.563380</td>\n","      <td>0.625000</td>\n","      <td>0.592593</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.169300</td>\n","      <td>1.685900</td>\n","      <td>0.603325</td>\n","      <td>0.562814</td>\n","      <td>0.583333</td>\n","      <td>0.572890</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>0.169600</td>\n","      <td>1.717856</td>\n","      <td>0.608076</td>\n","      <td>0.562212</td>\n","      <td>0.635417</td>\n","      <td>0.596577</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>0.166700</td>\n","      <td>1.715503</td>\n","      <td>0.622328</td>\n","      <td>0.577465</td>\n","      <td>0.640625</td>\n","      <td>0.607407</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>0.155300</td>\n","      <td>1.730771</td>\n","      <td>0.605701</td>\n","      <td>0.563725</td>\n","      <td>0.598958</td>\n","      <td>0.580808</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>0.153800</td>\n","      <td>1.737607</td>\n","      <td>0.617577</td>\n","      <td>0.577114</td>\n","      <td>0.604167</td>\n","      <td>0.590331</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>0.150500</td>\n","      <td>1.752788</td>\n","      <td>0.615202</td>\n","      <td>0.577320</td>\n","      <td>0.583333</td>\n","      <td>0.580311</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='85' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [27/27 00:05]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Validation metrics: {'eval_loss': 1.7527879476547241, 'eval_accuracy': 0.6152019002375297, 'eval_precision': 0.5773195876288659, 'eval_recall': 0.5833333333333334, 'eval_f1': 0.5803108808290155, 'eval_runtime': 2.4004, 'eval_samples_per_second': 175.389, 'eval_steps_per_second': 11.248, 'epoch': 25.0}\n","Test metrics: {'eval_loss': 1.9492871761322021, 'eval_accuracy': 0.5561613958560524, 'eval_precision': 0.5425, 'eval_recall': 0.49206349206349204, 'eval_f1': 0.5160523186682521, 'eval_runtime': 4.1347, 'eval_samples_per_second': 221.781, 'eval_steps_per_second': 14.028, 'epoch': 25.0}\n"]}]},{"cell_type":"code","source":["# save model checkpoint\n","\n","timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","model_save_path = os.path.join(dir_models, f\"{x_task}_{named_model}_{y_col}_{timestamp}\")\n","\n","trainer_obj.save_model(model_save_path)\n","print(f\"Model checkpoint saved to: {model_save_path}\")"],"metadata":{"id":"YralHU70zqbP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1744256524304,"user_tz":420,"elapsed":1116,"user":{"displayName":"J H","userId":"12017482157397552319"}},"outputId":"0e086030-3916-472b-f1c7-08ce112d5646"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Model checkpoint saved to: /content/drive/MyDrive/266-final/models/multi_bert-base-cased_binary_complexity_20250410_034203\n"]}]},{"cell_type":"code","source":["experiment_info = {\n","    \"model_name\": named_model,\n","    \"learning_rate\": learning_rate,\n","    \"epochs\": num_epochs,\n","    \"batch_size\": size_batch,\n","    \"weight_decay\": regularization_weight_decay,\n","    \"x_task\": x_task,\n","    \"x_col\": x_col,\n","    \"y_col\": y_col,\n","    \"layers_to_unfreeze\": layers_to_unfreeze\n","}\n","\n","model_info = gather_model_details(trained_model)\n","\n","all_run_metrics = gather_all_run_metrics(\n","    trainer=trainer_obj,\n","    train_dataset=train_data_hf,\n","    val_dataset=val_data_hf,\n","    test_dataset=test_data_hf\n",")\n","\n","log_experiment_results_json(\n","    experiment_meta=experiment_info,\n","    model_details=model_info,\n","    run_metrics=all_run_metrics,\n","    log_file=log_filepath\n",")\n","\n","print(f\"EXPERIMENT LOGGED TO: {log_filepath}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":55},"id":"EtBs8K_57ncw","executionInfo":{"status":"ok","timestamp":1744256559433,"user_tz":420,"elapsed":35126,"user":{"displayName":"J H","userId":"12017482157397552319"}},"outputId":"c2236268-6622-4d34-aeca-96e43b0f6d2d"},"execution_count":37,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='649' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [27/27 00:41]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["EXPERIMENT LOGGED TO: /content/drive/MyDrive/266-final/results/experiment_runs.txt\n"]}]},{"cell_type":"markdown","source":["### 3.1.3 from pretrained bert-base-cased Y: single task 1 & X: pos_sequence —"],"metadata":{"id":"H5PUNtHezMCd"}},{"cell_type":"code","source":["# Define Experiment Parameters\n","named_model = \"bert-base-cased\"\n","# named_model = \"roberta-base\"\n","# named_model = \"bert-large\"\n","# named_model = \"roberta-large\"\n","# named_model = \"\" # modern bert\n","############\n","regularization_weight_decay = 0.1\n","learning_rate = 1e-5\n","size_batch = 16\n","length_max = 256\n","num_epochs = 25\n","##########################################\n","# x_col = \"sentence\"\n","# x_col = \"sentence_no_contractions\"\n","x_col = \"pos_sequence\"\n","# x_col = \"dep_sequence\"\n","# x_col = \"morph_sequence\"\n","############\n","y_col = \"binary_complexity\"\n","# y_col = \"complexity\"\n","############\n","x_task = \"single\"\n","# x_task = \"multi\"\n","if x_task == \"single\":\n","    df_train = train_single_df\n","    df_val   = trial_val_single_df\n","    df_test  = test_single_df\n","else:\n","    df_train = train_multi_df\n","    df_val   = trial_val_multi_df\n","    df_test  = test_multi_df\n","##########################################\n","# Tokenize & Prepare Datasets\n","train_data_hf = prepare_dataset(\n","    df_train,\n","    tokenizer,\n","    text_col=x_col,\n","    label_col=y_col,\n","    max_length=length_max)\n","val_data_hf = prepare_dataset(\n","    df_val,\n","    tokenizer,\n","    text_col=x_col,\n","    label_col=y_col,\n","    max_length=length_max)\n","test_data_hf = prepare_dataset(\n","    df_test,\n","    tokenizer,\n","    text_col=x_col,\n","    label_col=y_col,\n","    max_length=length_max)\n","print(\"Datasets prepared. Sample from train_data_hf:\\n\", train_data_hf[10])\n","# print(\"Datasets prepared. Sample from train_data_hf:\\n\", val_data_hf[10])\n","# print(\"Datasets prepared. Sample from train_data_hf:\\n\", test_data_hf[10])\n","##########################################\n","custom_config = BertConfig.from_pretrained(\"bert-base-cased\")\n","custom_config.hidden_act = \"gelu\"  # alts: \"relu\" \"silu\"\n","custom_config.attention_probs_dropout_prob = 0.1\n","custom_config.hidden_dropout_prob = 0.1\n","custom_config.gradient_checkpointing = False\n","##########################################\n","model, tokenizer = get_model_and_tokenizer(\n","    remote_model_name=\"bert-base-cased\",\n","    local_model_path=None,\n","    config=custom_config)\n","############\n","# model, tokenizer = get_model_and_tokenizer(\n","#     remote_model_name=None\n","#     local_model_path=\"...CONFIGURE_PATH...\",\n","#     config=custom_config)\n","print(\"=============\")\n","print(named_model, \":\")\n","print(\"=============\")\n","print(\"num_parameters:\", model.num_parameters())\n","print(\"num_trainable_parameters at load:\", model.num_parameters(only_trainable=True))\n","print(\"=============\")\n","print(\"model lineage:\", MODEL_LINEAGE)\n","print(\"=============\")\n","##########################################\n","layers_to_unfreeze = [\n","    \"bert.embeddings.\",\n","    \"bert.encoder.layer.0.\",\n","    # \"bert.encoder.layer.1.\",\n","    \"bert.encoder.layer.8.\",\n","    \"bert.encoder.layer.9.\",\n","    \"bert.encoder.layer.10.\",\n","    \"bert.encoder.layer.11.\",\n","    \"bert.pooler.\",\n","    \"classifier.\",\n","]\n","freeze_unfreeze_layers(model, layers_to_unfreeze=layers_to_unfreeze)\n","print(model.config)\n","print(\"=============\")\n","print(\"num_parameters:\", model.num_parameters())\n","print(\"num_trainable_parameters:\", model.num_parameters(only_trainable=True))\n","print(\"=============\")\n","##########################################\n","print(\"Experiment configuration used with this experiment:\")\n","print(\"model used:\", named_model)\n","print(\"learning rate used:\", learning_rate)\n","print(\"number of epochs:\", num_epochs)\n","print(\"maximum sequence length:\", length_max)\n","print(\"batch size used:\", size_batch)\n","print(\"regularization value:\", regularization_weight_decay)\n","print(\"outcome variable:\", y_col)\n","print(\"task:\", x_task)\n","print(\"input column:\", x_col)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["eb3922a3034147349f68550f5057541a","ace4573e7fe84d67b74b33e931ea7148","4d9d8e7044884f6a842c7469b970a275","58ef25ba5b614f4daf38d681bea605cc","5f650ed21b7f472ca158bbf03edcc138","59075e778cc34dfeb3dcdca029d6535b","09875a55e9a54956b8e412d3cdb879f2","ce775666726140f9b92625b19d0eb528","090e5955a0074337a2a1297edf16304f","cc6bbf0181a94b5b8e03405fe287c70e","8200ed2077174641857fc87835d6360c","0fe184e349ba483d8b14b5a9dcd6c33c","430b28f4a8a14e67b4eeb486f8aaf89b","d841725c932d442fba363c8ddf8a20d7","36ca68a9d0a146c8a5a76192b98f59dd","ac2f817f64334e0685f6c4130055b40f","34ea22d269aa490ca347dd9d8308ee78","42e51fad2995466b87a41625f0f663d9","11d3e7cdd27c444381129cf6379ef4f3","a6725d6785f14f66a29085ed8ebf086e","9a86124134314e4b8fb451bb502e7ff5","fd8721f62ec243979198177e560a3615","2884d40ef193407b8400ca701dc5f6ce","9a06255df7b249e0a668d962ba88ee58","aefe1a9b3ade45d39f84056638d1fa2e","71e8ea5a6b074ef796eb3b29421ff862","2f4a478dee294bd59c0e68aa8939a408","79a75b1984f948b1a2128e51653fdf54","a1222133c8664103ab664efea240537f","b9d8322653624713a0f6b75f678954b1","979ee16622bc42fa8b5183cfb3441e40","2ab1cd70f97a479dae81cd90da8716f8","61c8c2da483340888eb15377023d20f4"]},"id":"MMUOl-m2izJt","executionInfo":{"status":"ok","timestamp":1744256561456,"user_tz":420,"elapsed":2019,"user":{"displayName":"J H","userId":"12017482157397552319"}},"outputId":"e8153a12-4c97-4883-eff1-d92c5264ebde"},"execution_count":38,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/7662 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb3922a3034147349f68550f5057541a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/421 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fe184e349ba483d8b14b5a9dcd6c33c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/917 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2884d40ef193407b8400ca701dc5f6ce"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Datasets prepared. Sample from train_data_hf:\n"," {'labels': tensor(0), 'input_ids': tensor([  101,   164,   112, 21362, 11414,  4538,   112,   117,   112,  5844,\n","         2101,   112,   117,   112, 18581,  1942,   112,   117,   112, 24819,\n","        27370,   112,   117,   112,  5844,  2101,   112,   117,   112, 11629,\n","        17195,  2249,   112,   117,   112, 11629, 11414,   112,   117,   112,\n","          159,  9637,  2064,   112,   117,   112, 24819, 27370,   112,   117,\n","          112,   153, 27370, 16647,   112,   117,   112,  9314, 11414,  4538,\n","          112,   117,   112, 18581,  1942,   112,   117,   112, 24819, 27370,\n","          112,   117,   112,  5844,  2101,   112,   117,   112, 18581,  1942,\n","          112,   117,   112, 24819, 27370,   112,   117,   112,   159,  9637,\n","         2064,   112,   117,   112,  5844,  2101,   112,   117,   112, 11629,\n","        11414,   112,   117,   112,   153, 27370, 16647,   112,   117,   112,\n","        11629, 11414,   112,   117,   112,   159,  9637,  2064,   112,   117,\n","          112, 11629, 11414,   112,   117,   112,  5844,  2101,   112,   117,\n","          112, 11629, 11414,   112,   117,   112, 24819, 27370,   112,   117,\n","          112,   153, 27370, 16647,   112,   166,   102,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}\n","Loading from Hugging Face model: bert-base-cased\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["=============\n","bert-base-cased :\n","=============\n","num_parameters: 108311810\n","num_trainable_parameters at load: 108311810\n","=============\n","model lineage: {'type': 'huggingface_hub', 'path': 'bert-base-cased', 'timestamp': '2025-04-10 03:42:41'}\n","=============\n","BertConfig {\n","  \"_attn_implementation_autoset\": true,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.50.3\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","=============\n","num_parameters: 108311810\n","num_trainable_parameters: 58696706\n","=============\n","Experiment configuration used with this experiment:\n","model used: bert-base-cased\n","learning rate used: 1e-05\n","number of epochs: 25\n","maximum sequence length: 256\n","batch size used: 16\n","regularization value: 0.1\n","outcome variable: binary_complexity\n","task: single\n","input column: pos_sequence\n"]}]},{"cell_type":"code","source":["# Train & Evaluate\n","trained_model, trainer_obj = train_transformer_model(\n","    model = model,\n","    tokenizer = tokenizer,\n","    train_dataset = train_data_hf,\n","    val_dataset = val_data_hf,\n","    output_dir = dir_results,\n","    num_epochs = num_epochs,\n","    batch_size = size_batch,\n","    lr = learning_rate,\n","    weight_decay = regularization_weight_decay)\n","metrics = trainer_obj.evaluate()\n","print(\"Validation metrics:\", metrics)\n","test_metrics = trainer_obj.evaluate(test_data_hf) if test_data_hf else None\n","print(\"Test metrics:\", test_metrics)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":601},"id":"bbvM3T_9izE_","outputId":"7ec5c61b-b3b5-4a95-8e68-2031d39292d6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","<ipython-input-20-c2ee9f934517>:31: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='6228' max='11975' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 6228/11975 14:09 < 13:04, 7.33 it/s, Epoch 13/25]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.700000</td>\n","      <td>0.690257</td>\n","      <td>0.543943</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.699100</td>\n","      <td>0.688805</td>\n","      <td>0.543943</td>\n","      <td>0.500000</td>\n","      <td>0.156250</td>\n","      <td>0.238095</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.695700</td>\n","      <td>0.692800</td>\n","      <td>0.522565</td>\n","      <td>0.485149</td>\n","      <td>0.765625</td>\n","      <td>0.593939</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.694000</td>\n","      <td>0.681160</td>\n","      <td>0.572447</td>\n","      <td>0.537500</td>\n","      <td>0.447917</td>\n","      <td>0.488636</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.693600</td>\n","      <td>0.686775</td>\n","      <td>0.527316</td>\n","      <td>0.486275</td>\n","      <td>0.645833</td>\n","      <td>0.554810</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.692600</td>\n","      <td>0.682323</td>\n","      <td>0.546318</td>\n","      <td>0.502326</td>\n","      <td>0.562500</td>\n","      <td>0.530713</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.687000</td>\n","      <td>0.688000</td>\n","      <td>0.536817</td>\n","      <td>0.493878</td>\n","      <td>0.630208</td>\n","      <td>0.553776</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.688100</td>\n","      <td>0.678277</td>\n","      <td>0.560570</td>\n","      <td>0.529412</td>\n","      <td>0.328125</td>\n","      <td>0.405145</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.681200</td>\n","      <td>0.698864</td>\n","      <td>0.529691</td>\n","      <td>0.487903</td>\n","      <td>0.630208</td>\n","      <td>0.550000</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.680100</td>\n","      <td>0.693433</td>\n","      <td>0.546318</td>\n","      <td>0.503356</td>\n","      <td>0.390625</td>\n","      <td>0.439883</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.676600</td>\n","      <td>0.692917</td>\n","      <td>0.543943</td>\n","      <td>0.500000</td>\n","      <td>0.432292</td>\n","      <td>0.463687</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.675700</td>\n","      <td>0.708669</td>\n","      <td>0.529691</td>\n","      <td>0.483696</td>\n","      <td>0.463542</td>\n","      <td>0.473404</td>\n","    </tr>\n","  </tbody>\n","</table><p>\n","    <div>\n","      \n","      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [27/27 00:01]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}]},{"cell_type":"code","source":["# save model checkpoint\n","timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","model_save_path = os.path.join(dir_models, f\"{x_task}_{named_model}_{y_col}_{timestamp}\")\n","trainer_obj.save_model(model_save_path)\n","print(f\"Model checkpoint saved to: {model_save_path}\")\n","# log experiment results\n","experiment_info = {\n","    \"model_name\": named_model,\n","    \"learning_rate\": learning_rate,\n","    \"epochs\": num_epochs,\n","    \"batch_size\": size_batch,\n","    \"weight_decay\": regularization_weight_decay,\n","    \"x_task\": x_task,\n","    \"x_col\": x_col,\n","    \"y_col\": y_col,\n","    \"layers_to_unfreeze\": layers_to_unfreeze}\n","model_info = gather_model_details(trained_model)\n","all_run_metrics = gather_all_run_metrics(\n","    trainer=trainer_obj,\n","    train_dataset=train_data_hf,\n","    val_dataset=val_data_hf,\n","    test_dataset=test_data_hf)\n","log_experiment_results_json(\n","    experiment_meta=experiment_info,\n","    model_details=model_info,\n","    run_metrics=all_run_metrics,\n","    log_file=log_filepath)\n","print(f\"EXPERIMENT LOGGED TO: {log_filepath}\")"],"metadata":{"id":"BmQh38K3izAz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3.1.4 from pretrained bert-base-cased Y: multi task 2 & X: pos_sequence —"],"metadata":{"id":"i56uCOF7e6kH"}},{"cell_type":"code","source":["# Define Experiment Parameters\n","named_model = \"bert-base-cased\"\n","# named_model = \"roberta-base\"\n","# named_model = \"bert-large\"\n","# named_model = \"roberta-large\"\n","# named_model = \"\" # modern bert\n","############\n","regularization_weight_decay = 0.1\n","learning_rate = 1e-5\n","size_batch = 16\n","length_max = 256\n","num_epochs = 25\n","##########################################\n","# x_col = \"sentence\"\n","# x_col = \"sentence_no_contractions\"\n","x_col = \"pos_sequence\"\n","# x_col = \"dep_sequence\"\n","# x_col = \"morph_sequence\"\n","############\n","y_col = \"binary_complexity\"\n","# y_col = \"complexity\"\n","############\n","# x_task = \"single\"\n","x_task = \"multi\"\n","if x_task == \"single\":\n","    df_train = train_single_df\n","    df_val   = trial_val_single_df\n","    df_test  = test_single_df\n","else:\n","    df_train = train_multi_df\n","    df_val   = trial_val_multi_df\n","    df_test  = test_multi_df\n","##########################################\n","# Tokenize & Prepare Datasets\n","train_data_hf = prepare_dataset(\n","    df_train,\n","    tokenizer,\n","    text_col=x_col,\n","    label_col=y_col,\n","    max_length=length_max)\n","val_data_hf = prepare_dataset(\n","    df_val,\n","    tokenizer,\n","    text_col=x_col,\n","    label_col=y_col,\n","    max_length=length_max)\n","test_data_hf = prepare_dataset(\n","    df_test,\n","    tokenizer,\n","    text_col=x_col,\n","    label_col=y_col,\n","    max_length=length_max)\n","print(\"Datasets prepared. Sample from train_data_hf:\\n\", train_data_hf[10])\n","# print(\"Datasets prepared. Sample from train_data_hf:\\n\", val_data_hf[10])\n","# print(\"Datasets prepared. Sample from train_data_hf:\\n\", test_data_hf[10])\n","##########################################\n","custom_config = BertConfig.from_pretrained(\"bert-base-cased\")\n","custom_config.hidden_act = \"gelu\"  # alts: \"relu\" \"silu\"\n","custom_config.attention_probs_dropout_prob = 0.1\n","custom_config.hidden_dropout_prob = 0.1\n","custom_config.gradient_checkpointing = False\n","##########################################\n","model, tokenizer = get_model_and_tokenizer(\n","    remote_model_name=\"bert-base-cased\",\n","    local_model_path=None,\n","    config=custom_config)\n","############\n","# model, tokenizer = get_model_and_tokenizer(\n","#     remote_model_name=None\n","#     local_model_path=\"...CONFIGURE_PATH...\",\n","#     config=custom_config)\n","print(\"=============\")\n","print(named_model, \":\")\n","print(\"=============\")\n","print(\"num_parameters:\", model.num_parameters())\n","print(\"num_trainable_parameters at load:\", model.num_parameters(only_trainable=True))\n","print(\"=============\")\n","print(\"model lineage:\", MODEL_LINEAGE)\n","print(\"=============\")\n","##########################################\n","layers_to_unfreeze = [\n","    \"bert.embeddings.\",\n","    \"bert.encoder.layer.0.\",\n","    # \"bert.encoder.layer.1.\",\n","    \"bert.encoder.layer.8.\",\n","    \"bert.encoder.layer.9.\",\n","    \"bert.encoder.layer.10.\",\n","    \"bert.encoder.layer.11.\",\n","    \"bert.pooler.\",\n","    \"classifier.\",\n","]\n","freeze_unfreeze_layers(model, layers_to_unfreeze=layers_to_unfreeze)\n","print(model.config)\n","print(\"=============\")\n","print(\"num_parameters:\", model.num_parameters())\n","print(\"num_trainable_parameters:\", model.num_parameters(only_trainable=True))\n","print(\"=============\")\n","##########################################\n","print(\"Experiment configuration used with this experiment:\")\n","print(\"model used:\", named_model)\n","print(\"learning rate used:\", learning_rate)\n","print(\"number of epochs:\", num_epochs)\n","print(\"maximum sequence length:\", length_max)\n","print(\"batch size used:\", size_batch)\n","print(\"regularization value:\", regularization_weight_decay)\n","print(\"outcome variable:\", y_col)\n","print(\"task:\", x_task)\n","print(\"input column:\", x_col)"],"metadata":{"id":"wTYJpChLfDxz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# #QA\n","\n","# def validate_dataframe(df, df_name):\n","#     \"\"\"\n","#     Performs basic functional tests on a pandas DataFrame\n","#     to ensure it matches expected structure and content.\n","#     \"\"\"\n","#     print(f\"\\n[VALIDATION] Checking {df_name}...\")\n","\n","#     # 1) Check shape\n","#     print(f\" - Shape: {df.shape}\")\n","\n","#     # 2) Check columns\n","#     print(f\" - Columns: {list(df.columns)}\")\n","\n","#     # 3) Check label distribution (assuming 'binary_complexity' is the label)\n","#     if \"binary_complexity\" in df.columns:\n","#         label_counts = df[\"binary_complexity\"].value_counts(dropna=False)\n","#         print(f\" - Label distribution:\\n{label_counts}\")\n","#     else:\n","#         print(\" - WARNING: 'binary_complexity' column not found!\")\n","\n","#     # 4) Peek at top few rows\n","#     print(\" - Sample rows:\\n\", df.head(3))\n","\n","\n","# # Example usage for multi data:\n","# validate_dataframe(train_multi_df, \"train_multi_df\")\n","# validate_dataframe(trial_val_multi_df, \"trial_val_multi_df\")\n","# validate_dataframe(test_multi_df, \"test_multi_df\")\n"],"metadata":{"id":"QT3tVZx801oF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def check_dataframe_invariants(df, df_name, expected_shape, expected_columns):\n","    \"\"\"\n","    Ensures that df has the exact shape and columns expected.\n","    Raises AssertionError if not.\n","    \"\"\"\n","    print(f\"\\n[CHECK] {df_name}\")\n","\n","    actual_shape = df.shape\n","    actual_columns = set(df.columns)\n","\n","    # 1) Check shape\n","    assert actual_shape == expected_shape, (\n","        f\"[ERROR] {df_name} shape mismatch. \"\n","        f\"Expected {expected_shape}, got {actual_shape}.\"\n","    )\n","\n","    # 2) Check columns\n","    assert actual_columns == set(expected_columns), (\n","        f\"[ERROR] {df_name} columns mismatch. \"\n","        f\"Expected {set(expected_columns)}, got {actual_columns}.\"\n","    )\n","\n","    print(\" - PASS: shape and columns match expectations\")\n","\n","# Suppose the actual columns are exactly:\n","my_expected_cols = [\n","    \"id\", \"sentence\", \"sentence_no_contractions\", \"token\",\n","    \"contraction_expanded\", \"pos_sequence\", \"morph_sequence\",\n","    \"dep_sequence\", \"morph_complexity\", \"complexity\",\n","    \"binary_complexity\", \"corpus\"\n","]\n","\n","check_dataframe_invariants(\n","    train_multi_df,\n","    \"train_multi_df\",\n","    expected_shape=(1517, 12),  # example only\n","    expected_columns=my_expected_cols\n",")\n"],"metadata":{"id":"ajFm4gu107kd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train & Evaluate\n","trained_model, trainer_obj = train_transformer_model(\n","    model = model,\n","    tokenizer = tokenizer,\n","    train_dataset = train_data_hf,\n","    val_dataset = val_data_hf,\n","    output_dir = dir_results,\n","    num_epochs = num_epochs,\n","    batch_size = size_batch,\n","    lr = learning_rate,\n","    weight_decay = regularization_weight_decay)\n","metrics = trainer_obj.evaluate()\n","print(\"Validation metrics:\", metrics)\n","test_metrics = trainer_obj.evaluate(test_data_hf) if test_data_hf else None\n","print(\"Test metrics:\", test_metrics)"],"metadata":{"id":"VSil7RA9gCWl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# save model checkpoint\n","timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","model_save_path = os.path.join(dir_models, f\"{x_task}_{named_model}_{y_col}_{timestamp}\")\n","trainer_obj.save_model(model_save_path)\n","print(f\"Model checkpoint saved to: {model_save_path}\")\n","# log experiment results\n","experiment_info = {\n","    \"model_name\": named_model,\n","    \"learning_rate\": learning_rate,\n","    \"epochs\": num_epochs,\n","    \"batch_size\": size_batch,\n","    \"weight_decay\": regularization_weight_decay,\n","    \"x_task\": x_task,\n","    \"x_col\": x_col,\n","    \"y_col\": y_col,\n","    \"layers_to_unfreeze\": layers_to_unfreeze}\n","model_info = gather_model_details(trained_model)\n","all_run_metrics = gather_all_run_metrics(\n","    trainer=trainer_obj,\n","    train_dataset=train_data_hf,\n","    val_dataset=val_data_hf,\n","    test_dataset=test_data_hf)\n","log_experiment_results_json(\n","    experiment_meta=experiment_info,\n","    model_details=model_info,\n","    run_metrics=all_run_metrics,\n","    log_file=log_filepath)\n","print(f\"EXPERIMENT LOGGED TO: {log_filepath}\")"],"metadata":{"id":"T3LQYTumgCTJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3.1.5 from pretrained bert-base-cased Y: single task 1 & X: morph_sequence"],"metadata":{"id":"28WBvMOQjM6t"}},{"cell_type":"code","source":["# Define Experiment Parameters\n","named_model = \"bert-base-cased\"\n","# named_model = \"roberta-base\"\n","# named_model = \"bert-large\"\n","# named_model = \"roberta-large\"\n","# named_model = \"\" # modern bert\n","############\n","regularization_weight_decay = 0.1\n","learning_rate = 1e-5\n","size_batch = 16\n","length_max = 256\n","num_epochs = 25\n","##########################################\n","# x_col = \"sentence\"\n","# x_col = \"sentence_no_contractions\"\n","# x_col = \"pos_sequence\"\n","# x_col = \"dep_sequence\"\n","x_col = \"morph_sequence\"\n","############\n","y_col = \"binary_complexity\"\n","# y_col = \"complexity\"\n","############\n","x_task = \"single\"\n","# x_task = \"multi\"\n","if x_task == \"single\":\n","    df_train = train_single_df\n","    df_val   = trial_val_single_df\n","    df_test  = test_single_df\n","else:\n","    df_train = train_multi_df\n","    df_val   = trial_val_multi_df\n","    df_test  = test_multi_df\n","##########################################\n","# Tokenize & Prepare Datasets\n","train_data_hf = prepare_dataset(\n","    df_train,\n","    tokenizer,\n","    text_col=x_col,\n","    label_col=y_col,\n","    max_length=length_max)\n","val_data_hf = prepare_dataset(\n","    df_val,\n","    tokenizer,\n","    text_col=x_col,\n","    label_col=y_col,\n","    max_length=length_max)\n","test_data_hf = prepare_dataset(\n","    df_test,\n","    tokenizer,\n","    text_col=x_col,\n","    label_col=y_col,\n","    max_length=length_max)\n","print(\"Datasets prepared. Sample from train_data_hf:\\n\", train_data_hf[10])\n","# print(\"Datasets prepared. Sample from train_data_hf:\\n\", val_data_hf[10])\n","# print(\"Datasets prepared. Sample from train_data_hf:\\n\", test_data_hf[10])\n","##########################################\n","custom_config = BertConfig.from_pretrained(\"bert-base-cased\")\n","custom_config.hidden_act = \"gelu\"  # alts: \"relu\" \"silu\"\n","custom_config.attention_probs_dropout_prob = 0.1\n","custom_config.hidden_dropout_prob = 0.1\n","custom_config.gradient_checkpointing = False\n","##########################################\n","model, tokenizer = get_model_and_tokenizer(\n","    remote_model_name=\"bert-base-cased\",\n","    local_model_path=None,\n","    config=custom_config)\n","############\n","# model, tokenizer = get_model_and_tokenizer(\n","#     remote_model_name=None\n","#     local_model_path=\"...CONFIGURE_PATH...\",\n","#     config=custom_config)\n","print(\"=============\")\n","print(named_model, \":\")\n","print(\"=============\")\n","print(\"num_parameters:\", model.num_parameters())\n","print(\"num_trainable_parameters at load:\", model.num_parameters(only_trainable=True))\n","print(\"=============\")\n","print(\"model lineage:\", MODEL_LINEAGE)\n","print(\"=============\")\n","##########################################\n","layers_to_unfreeze = [\n","    \"bert.embeddings.\",\n","    \"bert.encoder.layer.0.\",\n","    # \"bert.encoder.layer.1.\",\n","    \"bert.encoder.layer.8.\",\n","    \"bert.encoder.layer.9.\",\n","    \"bert.encoder.layer.10.\",\n","    \"bert.encoder.layer.11.\",\n","    \"bert.pooler.\",\n","    \"classifier.\",\n","]\n","freeze_unfreeze_layers(model, layers_to_unfreeze=layers_to_unfreeze)\n","print(model.config)\n","print(\"=============\")\n","print(\"num_parameters:\", model.num_parameters())\n","print(\"num_trainable_parameters:\", model.num_parameters(only_trainable=True))\n","print(\"=============\")\n","##########################################\n","print(\"Experiment configuration used with this experiment:\")\n","print(\"model used:\", named_model)\n","print(\"learning rate used:\", learning_rate)\n","print(\"number of epochs:\", num_epochs)\n","print(\"maximum sequence length:\", length_max)\n","print(\"batch size used:\", size_batch)\n","print(\"regularization value:\", regularization_weight_decay)\n","print(\"outcome variable:\", y_col)\n","print(\"task:\", x_task)\n","print(\"input column:\", x_col)"],"metadata":{"id":"7sOcIW86jZ1Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train & Evaluate\n","trained_model, trainer_obj = train_transformer_model(\n","    model = model,\n","    tokenizer = tokenizer,\n","    train_dataset = train_data_hf,\n","    val_dataset = val_data_hf,\n","    output_dir = dir_results,\n","    num_epochs = num_epochs,\n","    batch_size = size_batch,\n","    lr = learning_rate,\n","    weight_decay = regularization_weight_decay)\n","metrics = trainer_obj.evaluate()\n","print(\"Validation metrics:\", metrics)\n","test_metrics = trainer_obj.evaluate(test_data_hf) if test_data_hf else None\n","print(\"Test metrics:\", test_metrics)"],"metadata":{"id":"ehDyRpQfjZye"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# save model checkpoint\n","timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","model_save_path = os.path.join(dir_models, f\"{x_task}_{named_model}_{y_col}_{timestamp}\")\n","trainer_obj.save_model(model_save_path)\n","print(f\"Model checkpoint saved to: {model_save_path}\")\n","# log experiment results\n","experiment_info = {\n","    \"model_name\": named_model,\n","    \"learning_rate\": learning_rate,\n","    \"epochs\": num_epochs,\n","    \"batch_size\": size_batch,\n","    \"weight_decay\": regularization_weight_decay,\n","    \"x_task\": x_task,\n","    \"x_col\": x_col,\n","    \"y_col\": y_col,\n","    \"layers_to_unfreeze\": layers_to_unfreeze}\n","model_info = gather_model_details(trained_model)\n","all_run_metrics = gather_all_run_metrics(\n","    trainer=trainer_obj,\n","    train_dataset=train_data_hf,\n","    val_dataset=val_data_hf,\n","    test_dataset=test_data_hf)\n","log_experiment_results_json(\n","    experiment_meta=experiment_info,\n","    model_details=model_info,\n","    run_metrics=all_run_metrics,\n","    log_file=log_filepath)\n","print(f\"EXPERIMENT LOGGED TO: {log_filepath}\")"],"metadata":{"id":"l7TiyMpAjZvm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3.1.6 from pretrained bert-base-cased Y: multi  task 2 & X: morph_sequence"],"metadata":{"id":"FWptxne9jM3u"}},{"cell_type":"code","source":["# Define Experiment Parameters\n","named_model = \"bert-base-cased\"\n","# named_model = \"roberta-base\"\n","# named_model = \"bert-large\"\n","# named_model = \"roberta-large\"\n","# named_model = \"\" # modern bert\n","############\n","regularization_weight_decay = 0.1\n","learning_rate = 1e-5\n","size_batch = 16\n","length_max = 256\n","num_epochs = 25\n","##########################################\n","# x_col = \"sentence\"\n","# x_col = \"sentence_no_contractions\"\n","# x_col = \"pos_sequence\"\n","# x_col = \"dep_sequence\"\n","x_col = \"morph_sequence\"\n","############\n","y_col = \"binary_complexity\"\n","# y_col = \"complexity\"\n","############\n","# x_task = \"single\"\n","x_task = \"multi\"\n","if x_task == \"single\":\n","    df_train = train_single_df\n","    df_val   = trial_val_single_df\n","    df_test  = test_single_df\n","else:\n","    df_train = train_multi_df\n","    df_val   = trial_val_multi_df\n","    df_test  = test_multi_df\n","##########################################\n","# Tokenize & Prepare Datasets\n","train_data_hf = prepare_dataset(\n","    df_train,\n","    tokenizer,\n","    text_col=x_col,\n","    label_col=y_col,\n","    max_length=length_max)\n","val_data_hf = prepare_dataset(\n","    df_val,\n","    tokenizer,\n","    text_col=x_col,\n","    label_col=y_col,\n","    max_length=length_max)\n","test_data_hf = prepare_dataset(\n","    df_test,\n","    tokenizer,\n","    text_col=x_col,\n","    label_col=y_col,\n","    max_length=length_max)\n","print(\"Datasets prepared. Sample from train_data_hf:\\n\", train_data_hf[10])\n","# print(\"Datasets prepared. Sample from train_data_hf:\\n\", val_data_hf[10])\n","# print(\"Datasets prepared. Sample from train_data_hf:\\n\", test_data_hf[10])\n","##########################################\n","custom_config = BertConfig.from_pretrained(\"bert-base-cased\")\n","custom_config.hidden_act = \"gelu\"  # alts: \"relu\" \"silu\"\n","custom_config.attention_probs_dropout_prob = 0.1\n","custom_config.hidden_dropout_prob = 0.1\n","custom_config.gradient_checkpointing = False\n","##########################################\n","model, tokenizer = get_model_and_tokenizer(\n","    remote_model_name=\"bert-base-cased\",\n","    local_model_path=None,\n","    config=custom_config)\n","############\n","# model, tokenizer = get_model_and_tokenizer(\n","#     remote_model_name=None\n","#     local_model_path=\"...CONFIGURE_PATH...\",\n","#     config=custom_config)\n","print(\"=============\")\n","print(named_model, \":\")\n","print(\"=============\")\n","print(\"num_parameters:\", model.num_parameters())\n","print(\"num_trainable_parameters at load:\", model.num_parameters(only_trainable=True))\n","print(\"=============\")\n","print(\"model lineage:\", MODEL_LINEAGE)\n","print(\"=============\")\n","##########################################\n","layers_to_unfreeze = [\n","    \"bert.embeddings.\",\n","    \"bert.encoder.layer.0.\",\n","    # \"bert.encoder.layer.1.\",\n","    \"bert.encoder.layer.8.\",\n","    \"bert.encoder.layer.9.\",\n","    \"bert.encoder.layer.10.\",\n","    \"bert.encoder.layer.11.\",\n","    \"bert.pooler.\",\n","    \"classifier.\",\n","]\n","freeze_unfreeze_layers(model, layers_to_unfreeze=layers_to_unfreeze)\n","print(model.config)\n","print(\"=============\")\n","print(\"num_parameters:\", model.num_parameters())\n","print(\"num_trainable_parameters:\", model.num_parameters(only_trainable=True))\n","print(\"=============\")\n","##########################################\n","print(\"Experiment configuration used with this experiment:\")\n","print(\"model used:\", named_model)\n","print(\"learning rate used:\", learning_rate)\n","print(\"number of epochs:\", num_epochs)\n","print(\"maximum sequence length:\", length_max)\n","print(\"batch size used:\", size_batch)\n","print(\"regularization value:\", regularization_weight_decay)\n","print(\"outcome variable:\", y_col)\n","print(\"task:\", x_task)\n","print(\"input column:\", x_col)"],"metadata":{"id":"5fhU2QeujXbN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train & Evaluate\n","trained_model, trainer_obj = train_transformer_model(\n","    model = model,\n","    tokenizer = tokenizer,\n","    train_dataset = train_data_hf,\n","    val_dataset = val_data_hf,\n","    output_dir = dir_results,\n","    num_epochs = num_epochs,\n","    batch_size = size_batch,\n","    lr = learning_rate,\n","    weight_decay = regularization_weight_decay)\n","metrics = trainer_obj.evaluate()\n","print(\"Validation metrics:\", metrics)\n","test_metrics = trainer_obj.evaluate(test_data_hf) if test_data_hf else None\n","print(\"Test metrics:\", test_metrics)"],"metadata":{"id":"-9IBBJ3SjaPN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# save model checkpoint\n","timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","model_save_path = os.path.join(dir_models, f\"{x_task}_{named_model}_{y_col}_{timestamp}\")\n","trainer_obj.save_model(model_save_path)\n","print(f\"Model checkpoint saved to: {model_save_path}\")\n","# log experiment results\n","experiment_info = {\n","    \"model_name\": named_model,\n","    \"learning_rate\": learning_rate,\n","    \"epochs\": num_epochs,\n","    \"batch_size\": size_batch,\n","    \"weight_decay\": regularization_weight_decay,\n","    \"x_task\": x_task,\n","    \"x_col\": x_col,\n","    \"y_col\": y_col,\n","    \"layers_to_unfreeze\": layers_to_unfreeze}\n","model_info = gather_model_details(trained_model)\n","all_run_metrics = gather_all_run_metrics(\n","    trainer=trainer_obj,\n","    train_dataset=train_data_hf,\n","    val_dataset=val_data_hf,\n","    test_dataset=test_data_hf)\n","log_experiment_results_json(\n","    experiment_meta=experiment_info,\n","    model_details=model_info,\n","    run_metrics=all_run_metrics,\n","    log_file=log_filepath)\n","print(f\"EXPERIMENT LOGGED TO: {log_filepath}\")"],"metadata":{"id":"j-QyCJq0jaMm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3.1.0.1 from pretrained bert-base-cased Y: single task 1 & X: sentence —"],"metadata":{"id":"ZISgVUwvmuOu"}},{"cell_type":"code","source":["# Define Experiment Parameters\n","named_model = \"bert-base-cased\"\n","# named_model = \"roberta-base\"\n","# named_model = \"bert-large\"\n","# named_model = \"roberta-large\"\n","# named_model = \"\" # modern bert\n","############\n","regularization_weight_decay = 0.1\n","learning_rate = 1e-5\n","size_batch = 16\n","length_max = 256\n","num_epochs = 25\n","##########################################\n","x_col = \"sentence\"\n","# x_col = \"sentence_no_contractions\"\n","# x_col = \"pos_sequence\"\n","# x_col = \"dep_sequence\"\n","# x_col = \"morph_sequence\"\n","############\n","y_col = \"binary_complexity\"\n","# y_col = \"complexity\"\n","############\n","x_task = \"single\"\n","# x_task = \"multi\"\n","if x_task == \"single\":\n","    df_train = train_single_df\n","    df_val   = trial_val_single_df\n","    df_test  = test_single_df\n","else:\n","    df_train = train_multi_df\n","    df_val   = trial_val_multi_df\n","    df_test  = test_multi_df\n","##########################################\n","# Tokenize & Prepare Datasets\n","train_data_hf = prepare_dataset(\n","    df_train,\n","    tokenizer,\n","    text_col=x_col,\n","    label_col=y_col,\n","    max_length=length_max)\n","val_data_hf = prepare_dataset(\n","    df_val,\n","    tokenizer,\n","    text_col=x_col,\n","    label_col=y_col,\n","    max_length=length_max)\n","test_data_hf = prepare_dataset(\n","    df_test,\n","    tokenizer,\n","    text_col=x_col,\n","    label_col=y_col,\n","    max_length=length_max)\n","print(\"Datasets prepared. Sample from train_data_hf:\\n\", train_data_hf[10])\n","# print(\"Datasets prepared. Sample from train_data_hf:\\n\", val_data_hf[10])\n","# print(\"Datasets prepared. Sample from train_data_hf:\\n\", test_data_hf[10])\n","##########################################\n","custom_config = BertConfig.from_pretrained(\"bert-base-cased\")\n","custom_config.hidden_act = \"gelu\"  # alts: \"relu\" \"silu\"\n","custom_config.attention_probs_dropout_prob = 0.1\n","custom_config.hidden_dropout_prob = 0.1\n","custom_config.gradient_checkpointing = False\n","##########################################\n","model, tokenizer = get_model_and_tokenizer(\n","    remote_model_name=\"bert-base-cased\",\n","    local_model_path=None,\n","    config=custom_config)\n","############\n","# model, tokenizer = get_model_and_tokenizer(\n","#     remote_model_name=None\n","#     local_model_path=\"...CONFIGURE_PATH...\",\n","#     config=custom_config)\n","print(\"=============\")\n","print(named_model, \":\")\n","print(\"=============\")\n","print(\"num_parameters:\", model.num_parameters())\n","print(\"num_trainable_parameters at load:\", model.num_parameters(only_trainable=True))\n","print(\"=============\")\n","print(\"model lineage:\", MODEL_LINEAGE)\n","print(\"=============\")\n","##########################################\n","layers_to_unfreeze = [\n","    \"bert.embeddings.\",\n","    \"bert.encoder.layer.0.\",\n","    # \"bert.encoder.layer.1.\",\n","    \"bert.encoder.layer.8.\",\n","    \"bert.encoder.layer.9.\",\n","    \"bert.encoder.layer.10.\",\n","    \"bert.encoder.layer.11.\",\n","    \"bert.pooler.\",\n","    \"classifier.\",\n","]\n","freeze_unfreeze_layers(model, layers_to_unfreeze=layers_to_unfreeze)\n","print(model.config)\n","print(\"=============\")\n","print(\"num_parameters:\", model.num_parameters())\n","print(\"num_trainable_parameters:\", model.num_parameters(only_trainable=True))\n","print(\"=============\")\n","##########################################\n","print(\"Experiment configuration used with this experiment:\")\n","print(\"model used:\", named_model)\n","print(\"learning rate used:\", learning_rate)\n","print(\"number of epochs:\", num_epochs)\n","print(\"maximum sequence length:\", length_max)\n","print(\"batch size used:\", size_batch)\n","print(\"regularization value:\", regularization_weight_decay)\n","print(\"outcome variable:\", y_col)\n","print(\"task:\", x_task)\n","print(\"input column:\", x_col)"],"metadata":{"id":"bG0Ad-jdm0h1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train & Evaluate\n","trained_model, trainer_obj = train_transformer_model(\n","    model = model,\n","    tokenizer = tokenizer,\n","    train_dataset = train_data_hf,\n","    val_dataset = val_data_hf,\n","    output_dir = dir_results,\n","    num_epochs = num_epochs,\n","    batch_size = size_batch,\n","    lr = learning_rate,\n","    weight_decay = regularization_weight_decay)\n","metrics = trainer_obj.evaluate()\n","print(\"Validation metrics:\", metrics)\n","test_metrics = trainer_obj.evaluate(test_data_hf) if test_data_hf else None\n","print(\"Test metrics:\", test_metrics)"],"metadata":{"id":"wBML_iWGm5GK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# save model checkpoint\n","timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","model_save_path = os.path.join(dir_models, f\"{x_task}_{named_model}_{y_col}_{timestamp}\")\n","trainer_obj.save_model(model_save_path)\n","print(f\"Model checkpoint saved to: {model_save_path}\")\n","# log experiment results\n","experiment_info = {\n","    \"model_name\": named_model,\n","    \"learning_rate\": learning_rate,\n","    \"epochs\": num_epochs,\n","    \"batch_size\": size_batch,\n","    \"weight_decay\": regularization_weight_decay,\n","    \"x_task\": x_task,\n","    \"x_col\": x_col,\n","    \"y_col\": y_col,\n","    \"layers_to_unfreeze\": layers_to_unfreeze}\n","model_info = gather_model_details(trained_model)\n","all_run_metrics = gather_all_run_metrics(\n","    trainer=trainer_obj,\n","    train_dataset=train_data_hf,\n","    val_dataset=val_data_hf,\n","    test_dataset=test_data_hf)\n","log_experiment_results_json(\n","    experiment_meta=experiment_info,\n","    model_details=model_info,\n","    run_metrics=all_run_metrics,\n","    log_file=log_filepath)\n","print(f\"EXPERIMENT LOGGED TO: {log_filepath}\")"],"metadata":{"id":"YZ7nvDuem5DD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3.1.0.2 from pretrained bert-base-cased Y: multi task 2 & X: sentence —"],"metadata":{"id":"-rOCP_tcm5Zs"}},{"cell_type":"code","source":["# Define Experiment Parameters\n","named_model = \"bert-base-cased\"\n","# named_model = \"roberta-base\"\n","# named_model = \"bert-large\"\n","# named_model = \"roberta-large\"\n","# named_model = \"\" # modern bert\n","############\n","regularization_weight_decay = 0.1\n","learning_rate = 1e-5\n","size_batch = 16\n","length_max = 256\n","num_epochs = 25\n","##########################################\n","x_col = \"sentence\"\n","# x_col = \"sentence_no_contractions\"\n","# x_col = \"pos_sequence\"\n","# x_col = \"dep_sequence\"\n","# x_col = \"morph_sequence\"\n","############\n","y_col = \"binary_complexity\"\n","# y_col = \"complexity\"\n","############\n","# x_task = \"single\"\n","x_task = \"multi\"\n","if x_task == \"single\":\n","    df_train = train_single_df\n","    df_val   = trial_val_single_df\n","    df_test  = test_single_df\n","else:\n","    df_train = train_multi_df\n","    df_val   = trial_val_multi_df\n","    df_test  = test_multi_df\n","##########################################\n","# Tokenize & Prepare Datasets\n","train_data_hf = prepare_dataset(\n","    df_train,\n","    tokenizer,\n","    text_col=x_col,\n","    label_col=y_col,\n","    max_length=length_max)\n","val_data_hf = prepare_dataset(\n","    df_val,\n","    tokenizer,\n","    text_col=x_col,\n","    label_col=y_col,\n","    max_length=length_max)\n","test_data_hf = prepare_dataset(\n","    df_test,\n","    tokenizer,\n","    text_col=x_col,\n","    label_col=y_col,\n","    max_length=length_max)\n","print(\"Datasets prepared. Sample from train_data_hf:\\n\", train_data_hf[10])\n","# print(\"Datasets prepared. Sample from train_data_hf:\\n\", val_data_hf[10])\n","# print(\"Datasets prepared. Sample from train_data_hf:\\n\", test_data_hf[10])\n","##########################################\n","custom_config = BertConfig.from_pretrained(\"bert-base-cased\")\n","custom_config.hidden_act = \"gelu\"  # alts: \"relu\" \"silu\"\n","custom_config.attention_probs_dropout_prob = 0.1\n","custom_config.hidden_dropout_prob = 0.1\n","custom_config.gradient_checkpointing = False\n","##########################################\n","model, tokenizer = get_model_and_tokenizer(\n","    remote_model_name=\"bert-base-cased\",\n","    local_model_path=None,\n","    config=custom_config)\n","############\n","# model, tokenizer = get_model_and_tokenizer(\n","#     remote_model_name=None\n","#     local_model_path=\"...CONFIGURE_PATH...\",\n","#     config=custom_config)\n","print(\"=============\")\n","print(named_model, \":\")\n","print(\"=============\")\n","print(\"num_parameters:\", model.num_parameters())\n","print(\"num_trainable_parameters at load:\", model.num_parameters(only_trainable=True))\n","print(\"=============\")\n","print(\"model lineage:\", MODEL_LINEAGE)\n","print(\"=============\")\n","##########################################\n","layers_to_unfreeze = [\n","    \"bert.embeddings.\",\n","    \"bert.encoder.layer.0.\",\n","    # \"bert.encoder.layer.1.\",\n","    \"bert.encoder.layer.8.\",\n","    \"bert.encoder.layer.9.\",\n","    \"bert.encoder.layer.10.\",\n","    \"bert.encoder.layer.11.\",\n","    \"bert.pooler.\",\n","    \"classifier.\",\n","]\n","freeze_unfreeze_layers(model, layers_to_unfreeze=layers_to_unfreeze)\n","print(model.config)\n","print(\"=============\")\n","print(\"num_parameters:\", model.num_parameters())\n","print(\"num_trainable_parameters:\", model.num_parameters(only_trainable=True))\n","print(\"=============\")\n","##########################################\n","print(\"Experiment configuration used with this experiment:\")\n","print(\"model used:\", named_model)\n","print(\"learning rate used:\", learning_rate)\n","print(\"number of epochs:\", num_epochs)\n","print(\"maximum sequence length:\", length_max)\n","print(\"batch size used:\", size_batch)\n","print(\"regularization value:\", regularization_weight_decay)\n","print(\"outcome variable:\", y_col)\n","print(\"task:\", x_task)\n","print(\"input column:\", x_col)"],"metadata":{"id":"G8o4kTdFm8z1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train & Evaluate\n","trained_model, trainer_obj = train_transformer_model(\n","    model = model,\n","    tokenizer = tokenizer,\n","    train_dataset = train_data_hf,\n","    val_dataset = val_data_hf,\n","    output_dir = dir_results,\n","    num_epochs = num_epochs,\n","    batch_size = size_batch,\n","    lr = learning_rate,\n","    weight_decay = regularization_weight_decay)\n","metrics = trainer_obj.evaluate()\n","print(\"Validation metrics:\", metrics)\n","test_metrics = trainer_obj.evaluate(test_data_hf) if test_data_hf else None\n","print(\"Test metrics:\", test_metrics)"],"metadata":{"id":"ILjRtr7hm8xE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# save model checkpoint\n","timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","model_save_path = os.path.join(dir_models, f\"{x_task}_{named_model}_{y_col}_{timestamp}\")\n","trainer_obj.save_model(model_save_path)\n","print(f\"Model checkpoint saved to: {model_save_path}\")\n","# log experiment results\n","experiment_info = {\n","    \"model_name\": named_model,\n","    \"learning_rate\": learning_rate,\n","    \"epochs\": num_epochs,\n","    \"batch_size\": size_batch,\n","    \"weight_decay\": regularization_weight_decay,\n","    \"x_task\": x_task,\n","    \"x_col\": x_col,\n","    \"y_col\": y_col,\n","    \"layers_to_unfreeze\": layers_to_unfreeze}\n","model_info = gather_model_details(trained_model)\n","all_run_metrics = gather_all_run_metrics(\n","    trainer=trainer_obj,\n","    train_dataset=train_data_hf,\n","    val_dataset=val_data_hf,\n","    test_dataset=test_data_hf)\n","log_experiment_results_json(\n","    experiment_meta=experiment_info,\n","    model_details=model_info,\n","    run_metrics=all_run_metrics,\n","    log_file=log_filepath)\n","print(f\"EXPERIMENT LOGGED TO: {log_filepath}\")"],"metadata":{"id":"e9zNl9fjm8ug"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["--------------------------------------------\n","********************************************"],"metadata":{"id":"BnP0cLGw80s9"}},{"cell_type":"markdown","source":["### 3.1.7 from pretrained roberta-base Y: single task 1 & X: sentence —"],"metadata":{"id":"wR5GI5ehoJHQ"}},{"cell_type":"code","source":[],"metadata":{"id":"CK8wgjodoQfX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"IcXOAH_koQYR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"bNa3ahnYoQFy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3.1.8 from pretrained roberta-base Y: multi task 2 & X: sentence —"],"metadata":{"id":"j4-CKI0NoQw2"}},{"cell_type":"code","source":[],"metadata":{"id":"_3qO7tPNoTil"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"z_bEjb_ioUBL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ismbqVt7oT56"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3.1.9 from pretrained roberta-base Y: single task 1 & X: sentence_no_contractions —"],"metadata":{"id":"ANL0UKwVoWwg"}},{"cell_type":"code","source":[],"metadata":{"id":"OJ1lR-GBoad1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"NWlbJ1qxoaXa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xdO-jS-6oaA8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3.1.10 from pretrained roberta-base Y: multi task 2 & X: sentence_no_contractions —"],"metadata":{"id":"AN_vPK2woatR"}},{"cell_type":"code","source":[],"metadata":{"id":"ph_p86vfofBO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"O-ihCyxcoflO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QIgJMtLjofei"},"execution_count":null,"outputs":[]}]}