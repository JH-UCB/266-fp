{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@title Install Packages"
      ],
      "metadata": {
        "id": "xYRurcbg2fuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWeMhKnlvi9F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11fb1075-ede6-4211-d5ff-f095a34f9800"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/491.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m460.8/491.2 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers\n",
        "!pip install -q torchinfo\n",
        "!pip install -q datasets\n",
        "!pip install -q evaluate\n",
        "!pip install -q nltk\n",
        "!pip install -q contractions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update\n",
        "! sudo apt-get install tree"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rX3VqZu11-s_",
        "outputId": "9be3f77f-55aa-40a7-96c8-8fc35cd26b4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "\r0% [Waiting for headers] [1 InRelease 12.7 kB/129 kB 10%] [Connected to cloud.r\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [1 InRelease 73.5 kB/129 kB 57%] [Connected to cloud.r\r                                                                               \rGet:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,241 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,978 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,775 kB]\n",
            "Get:14 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [70.9 kB]\n",
            "Get:15 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,381 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,148 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,092 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,540 kB]\n",
            "Get:19 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,688 kB]\n",
            "Get:20 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,808 kB]\n",
            "Fetched 30.1 MB in 8s (3,843 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tree\n",
            "0 upgraded, 1 newly installed, 0 to remove and 46 not upgraded.\n",
            "Need to get 47.9 kB of archives.\n",
            "After this operation, 116 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tree amd64 2.0.2-1 [47.9 kB]\n",
            "Fetched 47.9 kB in 0s (356 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tree.\n",
            "(Reading database ... 126210 files and directories currently installed.)\n",
            "Preparing to unpack .../tree_2.0.2-1_amd64.deb ...\n",
            "Unpacking tree (2.0.2-1) ...\n",
            "Setting up tree (2.0.2-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports\n",
        "\n",
        "import transformers\n",
        "import evaluate\n",
        "\n",
        "import nltk\n",
        "\n",
        "import contractions\n",
        "\n",
        "from datasets import load_dataset\n",
        "from torchinfo import summary\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import scikit-learn"
      ],
      "metadata": {
        "id": "3wEgNBR6zosA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Mount Google Drive"
      ],
      "metadata": {
        "id": "rSP7bIn12YU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWKPq7h01cXk",
        "outputId": "4c929ab7-84d8-42c2-f3e4-68f593196247"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir_root = '/content/drive/MyDrive/266-final/'\n",
        "# dir_data = '/content/drive/MyDrive/266-final/data/'\n",
        "# dir_data = '/content/drive/MyDrive/266-final/data/se21-t1-comp-lex-master/'\n",
        "dir_data = '/content/drive/MyDrive/266-final/data/266-comp-lex-master'\n",
        "dir_models = '/content/drive/MyDrive/266-final/models/'\n",
        "dir_results = '/content/drive/MyDrive/266-final/results/'"
      ],
      "metadata": {
        "id": "I3Tfro3Zzop5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tree /content/drive/MyDrive/266-final/data/266-comp-lex-master/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qw9f1Hol2UhL",
        "outputId": "d4cc6e3c-9a28-4114-a5c6-f314bbd9e0be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01;34m/content/drive/MyDrive/266-final/data/se21-t1-comp-lex-master/\u001b[0m\n",
            "├── \u001b[00mevaluate.py\u001b[0m\n",
            "├── \u001b[00mReadme.md\u001b[0m\n",
            "├── \u001b[01;34mtest\u001b[0m\n",
            "│   ├── \u001b[00mlcp_multi_test.tsv\u001b[0m\n",
            "│   └── \u001b[00mlcp_single_test.tsv\u001b[0m\n",
            "├── \u001b[01;34mtest-labels\u001b[0m\n",
            "│   ├── \u001b[00mlcp_multi_test.tsv\u001b[0m\n",
            "│   └── \u001b[00mlcp_single_test.tsv\u001b[0m\n",
            "├── \u001b[01;34mtrain\u001b[0m\n",
            "│   ├── \u001b[00mlcp_multi_train.tsv\u001b[0m\n",
            "│   └── \u001b[00mlcp_single_train.tsv\u001b[0m\n",
            "└── \u001b[01;34mtrial\u001b[0m\n",
            "    ├── \u001b[00mlcp_multi_trial.tsv\u001b[0m\n",
            "    └── \u001b[00mlcp_single_trial.tsv\u001b[0m\n",
            "\n",
            "4 directories, 10 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -R /content/drive/MyDrive/266-final/data/266-comp-lex-master/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zgul33NlKkbV",
        "outputId": "df457b35-d8b8-434e-cdc7-f1a4ca73e8bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/266-final/data/se21-t1-comp-lex-master/:\n",
            "evaluate.py  Readme.md\ttest  test-labels  train  trial\n",
            "\n",
            "/content/drive/MyDrive/266-final/data/se21-t1-comp-lex-master/test:\n",
            "lcp_multi_test.tsv  lcp_single_test.tsv\n",
            "\n",
            "/content/drive/MyDrive/266-final/data/se21-t1-comp-lex-master/test-labels:\n",
            "lcp_multi_test.tsv  lcp_single_test.tsv\n",
            "\n",
            "/content/drive/MyDrive/266-final/data/se21-t1-comp-lex-master/train:\n",
            "lcp_multi_train.tsv  lcp_single_train.tsv\n",
            "\n",
            "/content/drive/MyDrive/266-final/data/se21-t1-comp-lex-master/trial:\n",
            "lcp_multi_trial.tsv  lcp_single_trial.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import Data"
      ],
      "metadata": {
        "id": "oftTqvV8zojV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Set the base directory path\n",
        "# dir_data = \"/Users/home/VSCode/mids/266-fp/data/se21-t1-comp-lex-master\"\n",
        "\n",
        "# Load training datasets\n",
        "\n",
        "train_single_df = pd.read_csv(os.path.join(dir_data, \"train\", \"lcp_single_train.tsv\"), sep=\"\\t\")\n",
        "train_multi_df = pd.read_csv(os.path.join(dir_data, \"train\", \"lcp_multi_train.tsv\"), sep=\"\\t\")\n",
        "\n",
        "trail_val_single_df = pd.read_csv(os.path.join(dir_data, \"trial\", \"lcp_single_trial.tsv\"), sep=\"\\t\")\n",
        "trail_val_multi_df = pd.read_csv(os.path.join(dir_data, \"trial\", \"lcp_multi_trial.tsv\"), sep=\"\\t\")\n",
        "\n",
        "test_single_df = pd.read_csv(os.path.join(dir_data, \"test-labels\", \"lcp_single_test.tsv\"), sep=\"\\t\")\n",
        "test_multi_df = pd.read_csv(os.path.join(dir_data, \"test-labels\", \"lcp_multi_test.tsv\"), sep=\"\\t\")\n",
        "\n",
        "# single_train_df = pd.read_csv(os.path.join(dir_data, \"train\", \"lcp_single_train.tsv\"), sep=\"\\t\")\n",
        "# multi_train_df = pd.read_csv(os.path.join(dir_data, \"train\", \"lcp_multi_train.tsv\"), sep=\"\\t\")\n",
        "\n",
        "# single_test_df = pd.read_csv(os.path.join(dir_data, \"test\", \"lcp_single_test.tsv\"), sep=\"\\t\")\n",
        "\n",
        "# Try to load the problematic multi_test file with error handling\n",
        "try:\n",
        "    # Approach 1: Try with the C engine but with error handling\n",
        "    multi_test_df = pd.read_csv(\n",
        "        os.path.join(dir_data, \"test\", \"lcp_multi_test.tsv\"),\n",
        "        sep=\"\\t\",\n",
        "        on_bad_lines='skip'  # Skip bad lines\n",
        "    )\n",
        "    print(\"Loaded with skipping bad lines\")\n",
        "except Exception as e:\n",
        "    print(f\"First approach failed: {e}\")\n",
        "    try:\n",
        "        # Approach 2: Try with the Python engine which might be more forgiving\n",
        "        multi_test_df = pd.read_csv(\n",
        "            os.path.join(dir_data, \"test\", \"lcp_multi_test.tsv\"),\n",
        "            sep=\"\\t\",\n",
        "            engine=\"python\",\n",
        "            quoting=3  # QUOTE_NONE\n",
        "        )\n",
        "        print(\"Loaded with Python engine\")\n",
        "    # except Exception as e:\n",
        "    #     print(f\"Second approach failed: {e}\")\n",
        "    #     # Approach 3: Let's try to manually identify and fix the problematic line\n",
        "    #     with open(os.path.join(dir_data, \"test\", \"lcp_multi_test.tsv\"), 'r') as file:\n",
        "    #         lines = file.readlines()\n",
        "\n",
        "    #     print(f\"Total lines in file: {len(lines)}\")\n",
        "    #     if len(lines) >= 40:\n",
        "    #         print(f\"Problematic line might be: {lines[39]}\")  # Line 40 (0-indexed)\n",
        "\n",
        "    #     # Create a dataframe from the lines we can read\n",
        "    #     import io\n",
        "    #     good_lines = lines[:39] + lines[40:] if len(lines) >= 40 else lines\n",
        "    #     multi_test_df = pd.read_csv(io.StringIO(''.join(good_lines)), sep=\"\\t\")\n",
        "    #     print(\"Loaded by skipping problematic line manually\")\n",
        "\n",
        "# # Display information about the loaded dataframes\n",
        "# print(f\"\\nSingle word training data: {single_train_df.shape[0]} records with {single_train_df.shape[1]} columns\")\n",
        "# print(f\"Multi word training data: {multi_train_df.shape[0]} records with {multi_train_df.shape[1]} columns\")\n",
        "# print(f\"Single word test data: {single_test_df.shape[0]} records with {single_test_df.shape[1]} columns\")\n",
        "# print(f\"Multi word test data: {multi_test_df.shape[0]} records with {multi_test_df.shape[1]} columns\")\n",
        "\n",
        "# # Load test labels using the Python engine to avoid potential parsing issues\n",
        "# single_test_labels_df = pd.read_csv(\n",
        "#     os.path.join(dir_data, \"test-labels\", \"lcp_single_test.tsv\"),\n",
        "#     sep=\"\\t\",\n",
        "#     engine=\"python\",\n",
        "#     quoting=3  # QUOTE_NONE\n",
        "# )\n",
        "\n",
        "# multi_test_labels_df = pd.read_csv(\n",
        "#     os.path.join(dir_data, \"test-labels\", \"lcp_multi_test.tsv\"),\n",
        "#     sep=\"\\t\",\n",
        "#     engine=\"python\",\n",
        "#     quoting=3  # QUOTE_NONE\n",
        "# )\n",
        "\n",
        "# # Display information about the loaded test label dataframes\n",
        "# print(f\"Single word test labels: {single_test_labels_df.shape[0]} records with {single_test_labels_df.shape[1]} columns\")\n",
        "# print(f\"Multi word test labels: {multi_test_labels_df.shape[0]} records with {multi_test_labels_df.shape[1]} columns\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73lV0P87eV-P",
        "outputId": "075d590d-952b-4d47-8e74-ded304c9a2d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First approach failed: Error tokenizing data. C error: EOF inside string starting at row 40\n",
            "Loaded with Python engine\n",
            "\n",
            "Single word training data: 7232 records with 5 columns\n",
            "Multi word training data: 1464 records with 5 columns\n",
            "Single word test data: 808 records with 4 columns\n",
            "Multi word test data: 184 records with 4 columns\n",
            "Single word test labels: 917 records with 5 columns\n",
            "Multi word test labels: 184 records with 5 columns\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "THI7aT5zeV74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qs8JvkGbeV5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1SwpD2xceV2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u-aiYwNPEE5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q_-6n1S3buOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2_ETbD0YbuNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_tcACu7FbuMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wWgWq-y-bt8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jG3xMkzCbt6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ABo6W4Ibbt4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZDnoU_zNbt1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "27LtqsOBbtzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9GCUTqfKEE3G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}