{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a93c0f01508341b4a0245c826fe9499a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c999b8b94ef64ec89c9cf8c792001d7a",
              "IPY_MODEL_8f3347d1f5c94a17b7f87e35249d2047",
              "IPY_MODEL_2eb355a1ae03458ea436b5a5f25b1434"
            ],
            "layout": "IPY_MODEL_21f7277d629f44fabed866ad07abafb6"
          }
        },
        "c999b8b94ef64ec89c9cf8c792001d7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a60b4f890dd74c2486372d38a11303f1",
            "placeholder": "​",
            "style": "IPY_MODEL_474bdc8a359d443697571ce2636cd63d",
            "value": "Map: 100%"
          }
        },
        "8f3347d1f5c94a17b7f87e35249d2047": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f019ce704d5e49019d949a999f2823fb",
            "max": 7662,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76ce63e4d748469c94e891aea9fdf7df",
            "value": 7662
          }
        },
        "2eb355a1ae03458ea436b5a5f25b1434": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db8e8a4e34dc4fab8638deda4689b52c",
            "placeholder": "​",
            "style": "IPY_MODEL_275cfaccfee84232b2420aff5b241f71",
            "value": " 7662/7662 [00:00&lt;00:00, 9155.50 examples/s]"
          }
        },
        "21f7277d629f44fabed866ad07abafb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a60b4f890dd74c2486372d38a11303f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "474bdc8a359d443697571ce2636cd63d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f019ce704d5e49019d949a999f2823fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76ce63e4d748469c94e891aea9fdf7df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db8e8a4e34dc4fab8638deda4689b52c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "275cfaccfee84232b2420aff5b241f71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e51cc19c1b96496eb958646577011178": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d1214fc434e74c6e88454f907a8cbf07",
              "IPY_MODEL_7bcd765707c5446ba472ea2e75a464cd",
              "IPY_MODEL_c0925070d0a942b2972f1b80892d5878"
            ],
            "layout": "IPY_MODEL_d63572b2174243ba9ae1142514afa9a9"
          }
        },
        "d1214fc434e74c6e88454f907a8cbf07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e2183cbdf1f47c7ad1009569bfec12a",
            "placeholder": "​",
            "style": "IPY_MODEL_fb1632f9a0924cf4882cf09fefd4dc17",
            "value": "Map: 100%"
          }
        },
        "7bcd765707c5446ba472ea2e75a464cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_894839febf0e4f13bfc0c4d80802b033",
            "max": 421,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_764d46c7504d4cc2afac766818b15a4c",
            "value": 421
          }
        },
        "c0925070d0a942b2972f1b80892d5878": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d901d09335841e48c5b242c2ee69bf8",
            "placeholder": "​",
            "style": "IPY_MODEL_406545da2ce6467086d1a3f0b664fa92",
            "value": " 421/421 [00:00&lt;00:00, 7970.47 examples/s]"
          }
        },
        "d63572b2174243ba9ae1142514afa9a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e2183cbdf1f47c7ad1009569bfec12a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb1632f9a0924cf4882cf09fefd4dc17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "894839febf0e4f13bfc0c4d80802b033": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "764d46c7504d4cc2afac766818b15a4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d901d09335841e48c5b242c2ee69bf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "406545da2ce6467086d1a3f0b664fa92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ece3a9c4a884a9b974564d4514d4eb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_916abd9db2d64cc7898667389a6f14ea",
              "IPY_MODEL_db7491715190423185defe993048eef7",
              "IPY_MODEL_8e84c6c11cb54fe6b2114a230cbf2250"
            ],
            "layout": "IPY_MODEL_0e29a698896449caaa0d361269b2df58"
          }
        },
        "916abd9db2d64cc7898667389a6f14ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92f961742bce4b418f8eeccb7c871ebe",
            "placeholder": "​",
            "style": "IPY_MODEL_8cf66e513ea2414f9adf67a6a188aa10",
            "value": "Map: 100%"
          }
        },
        "db7491715190423185defe993048eef7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58f1b32db9e34ba98f5f02f5b43ed568",
            "max": 917,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f72f1056685543ecaa4e4031d7586301",
            "value": 917
          }
        },
        "8e84c6c11cb54fe6b2114a230cbf2250": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c5ea09902f9417a81e5f73c51012d3a",
            "placeholder": "​",
            "style": "IPY_MODEL_e318b4a09216473782af28cff35b6cf7",
            "value": " 917/917 [00:00&lt;00:00, 9999.89 examples/s]"
          }
        },
        "0e29a698896449caaa0d361269b2df58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92f961742bce4b418f8eeccb7c871ebe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cf66e513ea2414f9adf67a6a188aa10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58f1b32db9e34ba98f5f02f5b43ed568": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f72f1056685543ecaa4e4031d7586301": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c5ea09902f9417a81e5f73c51012d3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e318b4a09216473782af28cff35b6cf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@title Install Packages"
      ],
      "metadata": {
        "id": "xYRurcbg2fuq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XWeMhKnlvi9F"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers\n",
        "!pip install -q torchinfo\n",
        "!pip install -q datasets\n",
        "!pip install -q evaluate\n",
        "!pip install -q nltk\n",
        "!pip install -q contractions\n",
        "!pip install -q hf_xet\n",
        "!pip install -q sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update\n",
        "! sudo apt-get install tree"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rX3VqZu11-s_",
        "outputId": "46777a57-dba2-4a95-a64d-e4f5b49cfba1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,788 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,243 kB]\n",
            "Fetched 4,288 kB in 2s (1,883 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tree is already the newest version (2.0.2-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports\n",
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "import contractions\n",
        "\n",
        "import evaluate\n",
        "import transformers\n",
        "import torch\n",
        "\n",
        "from torchinfo import summary\n",
        "\n",
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification, TrainingArguments, Trainer, BertConfig, BertForSequenceClassification\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import sklearn\n",
        "\n",
        "import spacy\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, precision_recall_fscore_support, accuracy_score\n",
        "\n",
        "import sentencepiece\n",
        "\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "3wEgNBR6zosA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Mount Google Drive"
      ],
      "metadata": {
        "id": "rSP7bIn12YU7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWKPq7h01cXk",
        "outputId": "bf5056ad-d990-4e9b-f8c8-d663e83f09f1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir_root = '/content/drive/MyDrive/266-final/'\n",
        "# dir_data = '/content/drive/MyDrive/266-final/data/'\n",
        "# dir_data = '/content/drive/MyDrive/266-final/data/se21-t1-comp-lex-master/'\n",
        "dir_data = '/content/drive/MyDrive/266-final/data/266-comp-lex-master'\n",
        "dir_models = '/content/drive/MyDrive/266-final/models/'\n",
        "dir_results = '/content/drive/MyDrive/266-final/results/'"
      ],
      "metadata": {
        "id": "I3Tfro3Zzop5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandbai_api_key = \"5236444b7e96f5cf74038116d8c1efba161a4310\""
      ],
      "metadata": {
        "id": "HjZtvw5ScRDp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tree /content/drive/MyDrive/266-final/data/266-comp-lex-master/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qw9f1Hol2UhL",
        "outputId": "bbee7086-a911-45ed-c85c-5860ab1ee567"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01;34m/content/drive/MyDrive/266-final/data/266-comp-lex-master/\u001b[0m\n",
            "├── \u001b[01;34mfe-test-labels\u001b[0m\n",
            "│   ├── \u001b[00mtest_multi_df.csv\u001b[0m\n",
            "│   └── \u001b[00mtest_single_df.csv\u001b[0m\n",
            "├── \u001b[01;34mfe-train\u001b[0m\n",
            "│   ├── \u001b[00mtrain_multi_df.csv\u001b[0m\n",
            "│   └── \u001b[00mtrain_single_df.csv\u001b[0m\n",
            "├── \u001b[01;34mfe-trial-val\u001b[0m\n",
            "│   ├── \u001b[00mtrial_val_multi_df.csv\u001b[0m\n",
            "│   └── \u001b[00mtrial_val_single_df.csv\u001b[0m\n",
            "├── \u001b[01;34mtest-labels\u001b[0m\n",
            "│   ├── \u001b[00mlcp_multi_test.tsv\u001b[0m\n",
            "│   └── \u001b[00mlcp_single_test.tsv\u001b[0m\n",
            "├── \u001b[01;34mtrain\u001b[0m\n",
            "│   ├── \u001b[00mlcp_multi_train.tsv\u001b[0m\n",
            "│   └── \u001b[00mlcp_single_train.tsv\u001b[0m\n",
            "└── \u001b[01;34mtrial\u001b[0m\n",
            "    ├── \u001b[00mlcp_multi_trial.tsv\u001b[0m\n",
            "    └── \u001b[00mlcp_single_trial.tsv\u001b[0m\n",
            "\n",
            "6 directories, 12 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -R /content/drive/MyDrive/266-final/data/266-comp-lex-master/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zgul33NlKkbV",
        "outputId": "d79abebc-8629-404b-82e1-6cdff49a2fb2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/266-final/data/266-comp-lex-master/:\n",
            "fe-test-labels\tfe-train  fe-trial-val\ttest-labels  train  trial\n",
            "\n",
            "/content/drive/MyDrive/266-final/data/266-comp-lex-master/fe-test-labels:\n",
            "test_multi_df.csv  test_single_df.csv\n",
            "\n",
            "/content/drive/MyDrive/266-final/data/266-comp-lex-master/fe-train:\n",
            "train_multi_df.csv  train_single_df.csv\n",
            "\n",
            "/content/drive/MyDrive/266-final/data/266-comp-lex-master/fe-trial-val:\n",
            "trial_val_multi_df.csv\ttrial_val_single_df.csv\n",
            "\n",
            "/content/drive/MyDrive/266-final/data/266-comp-lex-master/test-labels:\n",
            "lcp_multi_test.tsv  lcp_single_test.tsv\n",
            "\n",
            "/content/drive/MyDrive/266-final/data/266-comp-lex-master/train:\n",
            "lcp_multi_train.tsv  lcp_single_train.tsv\n",
            "\n",
            "/content/drive/MyDrive/266-final/data/266-comp-lex-master/trial:\n",
            "lcp_multi_trial.tsv  lcp_single_trial.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tree /content/drive/MyDrive/266-final/data/266-comp-lex-master/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9f8sPUBdbVr",
        "outputId": "68c37857-f1c3-4005-8e54-859c5a995d8e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01;34m/content/drive/MyDrive/266-final/data/266-comp-lex-master/\u001b[0m\n",
            "├── \u001b[01;34mfe-test-labels\u001b[0m\n",
            "│   ├── \u001b[00mtest_multi_df.csv\u001b[0m\n",
            "│   └── \u001b[00mtest_single_df.csv\u001b[0m\n",
            "├── \u001b[01;34mfe-train\u001b[0m\n",
            "│   ├── \u001b[00mtrain_multi_df.csv\u001b[0m\n",
            "│   └── \u001b[00mtrain_single_df.csv\u001b[0m\n",
            "├── \u001b[01;34mfe-trial-val\u001b[0m\n",
            "│   ├── \u001b[00mtrial_val_multi_df.csv\u001b[0m\n",
            "│   └── \u001b[00mtrial_val_single_df.csv\u001b[0m\n",
            "├── \u001b[01;34mtest-labels\u001b[0m\n",
            "│   ├── \u001b[00mlcp_multi_test.tsv\u001b[0m\n",
            "│   └── \u001b[00mlcp_single_test.tsv\u001b[0m\n",
            "├── \u001b[01;34mtrain\u001b[0m\n",
            "│   ├── \u001b[00mlcp_multi_train.tsv\u001b[0m\n",
            "│   └── \u001b[00mlcp_single_train.tsv\u001b[0m\n",
            "└── \u001b[01;34mtrial\u001b[0m\n",
            "    ├── \u001b[00mlcp_multi_trial.tsv\u001b[0m\n",
            "    └── \u001b[00mlcp_single_trial.tsv\u001b[0m\n",
            "\n",
            "6 directories, 12 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import Data"
      ],
      "metadata": {
        "id": "oftTqvV8zojV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_names = [\n",
        "    \"train_single_df\",\n",
        "    \"train_multi_df\",\n",
        "    \"trial_val_single_df\",\n",
        "    \"trial_val_multi_df\",\n",
        "    \"test_single_df\",\n",
        "    \"test_multi_df\"\n",
        "]\n",
        "\n",
        "loaded_dataframes = {}\n",
        "\n",
        "for df_name in df_names:\n",
        "    if \"train\" in df_name:\n",
        "        subdir = \"fe-train\"\n",
        "    elif \"trial_val\" in df_name:\n",
        "        subdir = \"fe-trial-val\"\n",
        "    elif \"test\" in df_name:\n",
        "        subdir = \"fe-test-labels\"\n",
        "    else:\n",
        "        subdir = None\n",
        "\n",
        "    if subdir:\n",
        "        read_path = os.path.join(dir_data, subdir, f\"{df_name}.csv\")\n",
        "        loaded_df = pd.read_csv(read_path)\n",
        "        loaded_dataframes[df_name] = loaded_df\n",
        "        print(f\"Loaded {df_name} from {read_path}\")\n",
        "\n",
        "# for df_name, df in loaded_dataframes.items():\n",
        "#     print(f\"\\n>>> {df_name} shape: {df.shape}\")\n",
        "#     if 'binary_complexity' in df.columns:\n",
        "#         print(df['binary_complexity'].value_counts())\n",
        "#         print(df.info())\n",
        "#         print(df.head())\n",
        "\n",
        "for df_name, df in loaded_dataframes.items():\n",
        "    globals()[df_name] = df\n",
        "    print(f\"{df_name} loaded into global namespace.\")"
      ],
      "metadata": {
        "id": "73lV0P87eV-P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc83b425-a29c-470a-d6fd-07d9e46ac0c6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded train_single_df from /content/drive/MyDrive/266-final/data/266-comp-lex-master/fe-train/train_single_df.csv\n",
            "Loaded train_multi_df from /content/drive/MyDrive/266-final/data/266-comp-lex-master/fe-train/train_multi_df.csv\n",
            "Loaded trial_val_single_df from /content/drive/MyDrive/266-final/data/266-comp-lex-master/fe-trial-val/trial_val_single_df.csv\n",
            "Loaded trial_val_multi_df from /content/drive/MyDrive/266-final/data/266-comp-lex-master/fe-trial-val/trial_val_multi_df.csv\n",
            "Loaded test_single_df from /content/drive/MyDrive/266-final/data/266-comp-lex-master/fe-test-labels/test_single_df.csv\n",
            "Loaded test_multi_df from /content/drive/MyDrive/266-final/data/266-comp-lex-master/fe-test-labels/test_multi_df.csv\n",
            "train_single_df loaded into global namespace.\n",
            "train_multi_df loaded into global namespace.\n",
            "trial_val_single_df loaded into global namespace.\n",
            "trial_val_multi_df loaded into global namespace.\n",
            "test_single_df loaded into global namespace.\n",
            "test_multi_df loaded into global namespace.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Functional tests pass, we can proceed with Baseline Modeling"
      ],
      "metadata": {
        "id": "8VsgfL5ZhO4z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiments with Transformers Models"
      ],
      "metadata": {
        "id": "kxZvACQZQu61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def get_model_and_tokenizer(model_name: str):\n",
        "#     \"\"\"\n",
        "#     Loads the specified pretrained model & tokenizer for classification.\n",
        "#     \"\"\"\n",
        "#     tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "#     model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "#     return model, tokenizer\n",
        "\n",
        "# new prod version to support local model checkpoints, to be used after experiment 1.0\n",
        "def get_model_and_tokenizer(\n",
        "    remote_model_name: str = None,\n",
        "    local_model_path: str = None\n",
        "):\n",
        "    \"\"\"\n",
        "    Loads the model & tokenizer for classification.\n",
        "    If 'local_model_path' is specified, load from that path.\n",
        "    Otherwise, fall back to 'remote_model_name'.\n",
        "    \"\"\"\n",
        "    from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "    if local_model_path:\n",
        "        # Local load\n",
        "        print(f\"Loading from local path: {local_model_path}\")\n",
        "        tokenizer = AutoTokenizer.from_pretrained(local_model_path)\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(local_model_path)\n",
        "    elif remote_model_name:\n",
        "        # Load from HF Hub\n",
        "        print(f\"Loading from Hugging Face model: {remote_model_name}\")\n",
        "        tokenizer = AutoTokenizer.from_pretrained(remote_model_name)\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(remote_model_name)\n",
        "    else:\n",
        "        raise ValueError(\"You must provide either a remote_model_name or a local_model_path!\")\n",
        "\n",
        "    return model, tokenizer"
      ],
      "metadata": {
        "id": "-rpwRVNF_e56"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def freeze_unfreeze_layers(model, layers_to_unfreeze=None):\n",
        "    \"\"\"\n",
        "    Toggles requires_grad = False for all parameters\n",
        "    except for those whose names contain any string in layers_to_unfreeze.\n",
        "    By default, always unfreeze classifier/heads.\n",
        "    \"\"\"\n",
        "    if layers_to_unfreeze is None:\n",
        "        layers_to_unfreeze = [\"classifier.\", \"pooler.\"]\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        # If any layer substring matches, we unfreeze\n",
        "        if any(substring in name for substring in layers_to_unfreeze):\n",
        "            param.requires_grad = True\n",
        "        else:\n",
        "            param.requires_grad = False"
      ],
      "metadata": {
        "id": "a7OVfxB__e3S"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def encode_examples(examples, tokenizer, text_col, max_length=256):\n",
        "    \"\"\"\n",
        "    Tokenizes a batch of texts from 'examples[text_col]' using the given tokenizer.\n",
        "    Returns a dict with 'input_ids', 'attention_mask', etc.\n",
        "    \"\"\"\n",
        "    texts = examples[text_col]\n",
        "    encoded = tokenizer(\n",
        "        texts,\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=max_length\n",
        "    )\n",
        "    return encoded"
      ],
      "metadata": {
        "id": "BtVWXxqb_e0r"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset(df, tokenizer, text_col, label_col, max_length=256):\n",
        "    \"\"\"\n",
        "    Converts a Pandas DataFrame to a Hugging Face Dataset,\n",
        "    then applies 'encode_examples' to tokenize.\n",
        "    \"\"\"\n",
        "    # Convert to HF Dataset\n",
        "    dataset = Dataset.from_pandas(df)\n",
        "\n",
        "    # Map the encode function\n",
        "    dataset = dataset.map(\n",
        "        lambda batch: encode_examples(batch, tokenizer, text_col, max_length),\n",
        "        batched=True\n",
        "    )\n",
        "\n",
        "    # Rename the label column to 'labels' for HF Trainer\n",
        "    dataset = dataset.rename_column(label_col, \"labels\")\n",
        "    # HF often requires removing any columns that cannot be converted or are not needed\n",
        "    dataset.set_format(type='torch',\n",
        "                       columns=['input_ids', 'attention_mask', 'labels'])\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "YmynPX-5i5HL"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"\n",
        "    Computes classification metrics, including accuracy, precision, recall, and F1.\n",
        "    \"\"\"\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=1)\n",
        "\n",
        "    metric_accuracy  = evaluate.load(\"accuracy\")\n",
        "    metric_precision = evaluate.load(\"precision\")\n",
        "    metric_recall    = evaluate.load(\"recall\")\n",
        "    metric_f1        = evaluate.load(\"f1\")\n",
        "\n",
        "    accuracy_result  = metric_accuracy.compute(predictions=preds, references=labels)\n",
        "    precision_result = metric_precision.compute(predictions=preds, references=labels, average=\"binary\")\n",
        "    recall_result    = metric_recall.compute(predictions=preds, references=labels, average=\"binary\")\n",
        "    f1_result        = metric_f1.compute(predictions=preds, references=labels, average=\"binary\")\n",
        "\n",
        "    return {\n",
        "        \"accuracy\"       : accuracy_result[\"accuracy\"],\n",
        "        \"precision\": precision_result[\"precision\"],\n",
        "        \"recall\"   : recall_result[\"recall\"],\n",
        "        \"f1\"       : f1_result[\"f1\"]\n",
        "    }"
      ],
      "metadata": {
        "id": "ze7GiYRP_ewQ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiment Design"
      ],
      "metadata": {
        "id": "5w231tlmrh_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Experiment Parameters\n",
        "\n",
        "named_model = \"bert-base-cased\"\n",
        "# named_model = \"roberta-base\"\n",
        "# named_model = \"bert-large\"\n",
        "# named_model = \"roberta-large\"\n",
        "# named_model = \"\" # modern bert\n",
        "\n",
        "# learning_rate = 1e-3\n",
        "# learning_rate = 1e-4\n",
        "# learning_rate = 1e-5\n",
        "# learning_rate = 5e-6\n",
        "learning_rate = 5e-7\n",
        "# learning_rate = 5e-8\n",
        "\n",
        "# num_epochs = 3\n",
        "num_epochs = 5\n",
        "# num_epochs = 10\n",
        "# num_epochs = 15\n",
        "# num_epochs = 20\n",
        "\n",
        "length_max = 128\n",
        "# length_max = 256\n",
        "# length_max = 348\n",
        "# length_max = 512\n",
        "\n",
        "# size_batch = 1\n",
        "# size_batch = 4\n",
        "size_batch = 8\n",
        "# size_batch = 16\n",
        "# size_batch = 24\n",
        "# size_batch = 32\n",
        "\n",
        "regularization_weight_decay = 0\n",
        "# regularization_weight_decay = 0.1\n",
        "# regularization_weight_decay = 0.5\n",
        "\n",
        "# dropout???\n",
        "\n",
        "# layers to freeze and unfreeze?\n",
        "\n",
        "y_col = \"binary_complexity\"\n",
        "# y_col = \"complexity\"\n",
        "\n",
        "x_task = \"single\"\n",
        "# x_task = \"multi\"\n",
        "\n",
        "# x_col = \"sentence\"\n",
        "x_col = \"sentence_no_contractions\"\n",
        "# x_col = \"pos_sequence\"\n",
        "# x_col = \"dep_sequence\"\n",
        "# x_col = \"morph_sequence\"\n",
        "\n",
        "if x_task == \"single\":\n",
        "    df_train = train_single_df\n",
        "    df_val   = trial_val_single_df\n",
        "    df_test  = test_single_df\n",
        "else:\n",
        "    df_train = train_multi_df\n",
        "    df_val   = trial_val_multi_df\n",
        "    df_test  = test_multi_df\n"
      ],
      "metadata": {
        "id": "PjPcND4vrgOm"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_transformer_model(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    train_dataset,\n",
        "    val_dataset,\n",
        "    output_dir=dir_results,\n",
        "    num_epochs=num_epochs,\n",
        "    batch_size=size_batch,\n",
        "    lr=learning_rate,\n",
        "    weight_decay=regularization_weight_decay\n",
        "):\n",
        "    \"\"\"\n",
        "    Sets up a Trainer and trains the model for 'num_epochs' using the given dataset.\n",
        "    Returns the trained model and the Trainer object for possible re-use or analysis.\n",
        "    \"\"\"\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        num_train_epochs=num_epochs,\n",
        "        per_device_train_batch_size=batch_size,\n",
        "        per_device_eval_batch_size=batch_size,\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        save_strategy=\"no\",\n",
        "        logging_strategy=\"epoch\",\n",
        "        learning_rate=lr,\n",
        "        weight_decay=weight_decay,\n",
        "        report_to=[\"none\"],  # or \"wandb\"\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        tokenizer=tokenizer,  # optional\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    return model, trainer"
      ],
      "metadata": {
        "id": "b-kyadzyrgHT"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiment 1: from pretrained bert-base-cased with single task"
      ],
      "metadata": {
        "id": "O_g9-bLdVBD_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model Inspection"
      ],
      "metadata": {
        "id": "UWNP_mfRZFJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"model checkpoints:\", dir_models)\n",
        "!ls /content/drive/MyDrive/266-final/models/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5raqYA8p8zQ",
        "outputId": "94abc0d4-d52e-4ed4-a1d3-599052b2cd4e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model checkpoints: /content/drive/MyDrive/266-final/models/\n",
            "bert-base-cased_20250407_232900  model_20250407_232826\tnltk_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Model & Tokenizer\n",
        "model, tokenizer = get_model_and_tokenizer(named_model) # deprecated argument structure\n",
        "# model, tokenizer = get_model_and_tokenizer(\"/content/drive/MyDrive/266-final/models/bert-base-cased_20250407_232900\") # proposed argument usage for checkpointed models\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    print(name)\n",
        "\n",
        "print(\"=============\")\n",
        "print(named_model, \":\")\n",
        "print(\"=============\")\n",
        "print(model)\n",
        "print(\"=============\")\n",
        "print(model.config)\n",
        "print(\"=============\")\n",
        "print(\"num_parameters:\", model.num_parameters())\n",
        "print(\"=============\")\n",
        "print(\"num_trainable_parameters:\", model.num_parameters(only_trainable=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVZ8rPGOVT5X",
        "outputId": "8d061241-dd41-4084-86e9-1b19407fb6ae"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading from Hugging Face model: bert-base-cased\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert.embeddings.word_embeddings.weight\n",
            "bert.embeddings.position_embeddings.weight\n",
            "bert.embeddings.token_type_embeddings.weight\n",
            "bert.embeddings.LayerNorm.weight\n",
            "bert.embeddings.LayerNorm.bias\n",
            "bert.encoder.layer.0.attention.self.query.weight\n",
            "bert.encoder.layer.0.attention.self.query.bias\n",
            "bert.encoder.layer.0.attention.self.key.weight\n",
            "bert.encoder.layer.0.attention.self.key.bias\n",
            "bert.encoder.layer.0.attention.self.value.weight\n",
            "bert.encoder.layer.0.attention.self.value.bias\n",
            "bert.encoder.layer.0.attention.output.dense.weight\n",
            "bert.encoder.layer.0.attention.output.dense.bias\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.0.intermediate.dense.weight\n",
            "bert.encoder.layer.0.intermediate.dense.bias\n",
            "bert.encoder.layer.0.output.dense.weight\n",
            "bert.encoder.layer.0.output.dense.bias\n",
            "bert.encoder.layer.0.output.LayerNorm.weight\n",
            "bert.encoder.layer.0.output.LayerNorm.bias\n",
            "bert.encoder.layer.1.attention.self.query.weight\n",
            "bert.encoder.layer.1.attention.self.query.bias\n",
            "bert.encoder.layer.1.attention.self.key.weight\n",
            "bert.encoder.layer.1.attention.self.key.bias\n",
            "bert.encoder.layer.1.attention.self.value.weight\n",
            "bert.encoder.layer.1.attention.self.value.bias\n",
            "bert.encoder.layer.1.attention.output.dense.weight\n",
            "bert.encoder.layer.1.attention.output.dense.bias\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.1.intermediate.dense.weight\n",
            "bert.encoder.layer.1.intermediate.dense.bias\n",
            "bert.encoder.layer.1.output.dense.weight\n",
            "bert.encoder.layer.1.output.dense.bias\n",
            "bert.encoder.layer.1.output.LayerNorm.weight\n",
            "bert.encoder.layer.1.output.LayerNorm.bias\n",
            "bert.encoder.layer.2.attention.self.query.weight\n",
            "bert.encoder.layer.2.attention.self.query.bias\n",
            "bert.encoder.layer.2.attention.self.key.weight\n",
            "bert.encoder.layer.2.attention.self.key.bias\n",
            "bert.encoder.layer.2.attention.self.value.weight\n",
            "bert.encoder.layer.2.attention.self.value.bias\n",
            "bert.encoder.layer.2.attention.output.dense.weight\n",
            "bert.encoder.layer.2.attention.output.dense.bias\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.2.intermediate.dense.weight\n",
            "bert.encoder.layer.2.intermediate.dense.bias\n",
            "bert.encoder.layer.2.output.dense.weight\n",
            "bert.encoder.layer.2.output.dense.bias\n",
            "bert.encoder.layer.2.output.LayerNorm.weight\n",
            "bert.encoder.layer.2.output.LayerNorm.bias\n",
            "bert.encoder.layer.3.attention.self.query.weight\n",
            "bert.encoder.layer.3.attention.self.query.bias\n",
            "bert.encoder.layer.3.attention.self.key.weight\n",
            "bert.encoder.layer.3.attention.self.key.bias\n",
            "bert.encoder.layer.3.attention.self.value.weight\n",
            "bert.encoder.layer.3.attention.self.value.bias\n",
            "bert.encoder.layer.3.attention.output.dense.weight\n",
            "bert.encoder.layer.3.attention.output.dense.bias\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.3.intermediate.dense.weight\n",
            "bert.encoder.layer.3.intermediate.dense.bias\n",
            "bert.encoder.layer.3.output.dense.weight\n",
            "bert.encoder.layer.3.output.dense.bias\n",
            "bert.encoder.layer.3.output.LayerNorm.weight\n",
            "bert.encoder.layer.3.output.LayerNorm.bias\n",
            "bert.encoder.layer.4.attention.self.query.weight\n",
            "bert.encoder.layer.4.attention.self.query.bias\n",
            "bert.encoder.layer.4.attention.self.key.weight\n",
            "bert.encoder.layer.4.attention.self.key.bias\n",
            "bert.encoder.layer.4.attention.self.value.weight\n",
            "bert.encoder.layer.4.attention.self.value.bias\n",
            "bert.encoder.layer.4.attention.output.dense.weight\n",
            "bert.encoder.layer.4.attention.output.dense.bias\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.4.intermediate.dense.weight\n",
            "bert.encoder.layer.4.intermediate.dense.bias\n",
            "bert.encoder.layer.4.output.dense.weight\n",
            "bert.encoder.layer.4.output.dense.bias\n",
            "bert.encoder.layer.4.output.LayerNorm.weight\n",
            "bert.encoder.layer.4.output.LayerNorm.bias\n",
            "bert.encoder.layer.5.attention.self.query.weight\n",
            "bert.encoder.layer.5.attention.self.query.bias\n",
            "bert.encoder.layer.5.attention.self.key.weight\n",
            "bert.encoder.layer.5.attention.self.key.bias\n",
            "bert.encoder.layer.5.attention.self.value.weight\n",
            "bert.encoder.layer.5.attention.self.value.bias\n",
            "bert.encoder.layer.5.attention.output.dense.weight\n",
            "bert.encoder.layer.5.attention.output.dense.bias\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.5.intermediate.dense.weight\n",
            "bert.encoder.layer.5.intermediate.dense.bias\n",
            "bert.encoder.layer.5.output.dense.weight\n",
            "bert.encoder.layer.5.output.dense.bias\n",
            "bert.encoder.layer.5.output.LayerNorm.weight\n",
            "bert.encoder.layer.5.output.LayerNorm.bias\n",
            "bert.encoder.layer.6.attention.self.query.weight\n",
            "bert.encoder.layer.6.attention.self.query.bias\n",
            "bert.encoder.layer.6.attention.self.key.weight\n",
            "bert.encoder.layer.6.attention.self.key.bias\n",
            "bert.encoder.layer.6.attention.self.value.weight\n",
            "bert.encoder.layer.6.attention.self.value.bias\n",
            "bert.encoder.layer.6.attention.output.dense.weight\n",
            "bert.encoder.layer.6.attention.output.dense.bias\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.6.intermediate.dense.weight\n",
            "bert.encoder.layer.6.intermediate.dense.bias\n",
            "bert.encoder.layer.6.output.dense.weight\n",
            "bert.encoder.layer.6.output.dense.bias\n",
            "bert.encoder.layer.6.output.LayerNorm.weight\n",
            "bert.encoder.layer.6.output.LayerNorm.bias\n",
            "bert.encoder.layer.7.attention.self.query.weight\n",
            "bert.encoder.layer.7.attention.self.query.bias\n",
            "bert.encoder.layer.7.attention.self.key.weight\n",
            "bert.encoder.layer.7.attention.self.key.bias\n",
            "bert.encoder.layer.7.attention.self.value.weight\n",
            "bert.encoder.layer.7.attention.self.value.bias\n",
            "bert.encoder.layer.7.attention.output.dense.weight\n",
            "bert.encoder.layer.7.attention.output.dense.bias\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.7.intermediate.dense.weight\n",
            "bert.encoder.layer.7.intermediate.dense.bias\n",
            "bert.encoder.layer.7.output.dense.weight\n",
            "bert.encoder.layer.7.output.dense.bias\n",
            "bert.encoder.layer.7.output.LayerNorm.weight\n",
            "bert.encoder.layer.7.output.LayerNorm.bias\n",
            "bert.encoder.layer.8.attention.self.query.weight\n",
            "bert.encoder.layer.8.attention.self.query.bias\n",
            "bert.encoder.layer.8.attention.self.key.weight\n",
            "bert.encoder.layer.8.attention.self.key.bias\n",
            "bert.encoder.layer.8.attention.self.value.weight\n",
            "bert.encoder.layer.8.attention.self.value.bias\n",
            "bert.encoder.layer.8.attention.output.dense.weight\n",
            "bert.encoder.layer.8.attention.output.dense.bias\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.8.intermediate.dense.weight\n",
            "bert.encoder.layer.8.intermediate.dense.bias\n",
            "bert.encoder.layer.8.output.dense.weight\n",
            "bert.encoder.layer.8.output.dense.bias\n",
            "bert.encoder.layer.8.output.LayerNorm.weight\n",
            "bert.encoder.layer.8.output.LayerNorm.bias\n",
            "bert.encoder.layer.9.attention.self.query.weight\n",
            "bert.encoder.layer.9.attention.self.query.bias\n",
            "bert.encoder.layer.9.attention.self.key.weight\n",
            "bert.encoder.layer.9.attention.self.key.bias\n",
            "bert.encoder.layer.9.attention.self.value.weight\n",
            "bert.encoder.layer.9.attention.self.value.bias\n",
            "bert.encoder.layer.9.attention.output.dense.weight\n",
            "bert.encoder.layer.9.attention.output.dense.bias\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.9.intermediate.dense.weight\n",
            "bert.encoder.layer.9.intermediate.dense.bias\n",
            "bert.encoder.layer.9.output.dense.weight\n",
            "bert.encoder.layer.9.output.dense.bias\n",
            "bert.encoder.layer.9.output.LayerNorm.weight\n",
            "bert.encoder.layer.9.output.LayerNorm.bias\n",
            "bert.encoder.layer.10.attention.self.query.weight\n",
            "bert.encoder.layer.10.attention.self.query.bias\n",
            "bert.encoder.layer.10.attention.self.key.weight\n",
            "bert.encoder.layer.10.attention.self.key.bias\n",
            "bert.encoder.layer.10.attention.self.value.weight\n",
            "bert.encoder.layer.10.attention.self.value.bias\n",
            "bert.encoder.layer.10.attention.output.dense.weight\n",
            "bert.encoder.layer.10.attention.output.dense.bias\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.10.intermediate.dense.weight\n",
            "bert.encoder.layer.10.intermediate.dense.bias\n",
            "bert.encoder.layer.10.output.dense.weight\n",
            "bert.encoder.layer.10.output.dense.bias\n",
            "bert.encoder.layer.10.output.LayerNorm.weight\n",
            "bert.encoder.layer.10.output.LayerNorm.bias\n",
            "bert.encoder.layer.11.attention.self.query.weight\n",
            "bert.encoder.layer.11.attention.self.query.bias\n",
            "bert.encoder.layer.11.attention.self.key.weight\n",
            "bert.encoder.layer.11.attention.self.key.bias\n",
            "bert.encoder.layer.11.attention.self.value.weight\n",
            "bert.encoder.layer.11.attention.self.value.bias\n",
            "bert.encoder.layer.11.attention.output.dense.weight\n",
            "bert.encoder.layer.11.attention.output.dense.bias\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.11.intermediate.dense.weight\n",
            "bert.encoder.layer.11.intermediate.dense.bias\n",
            "bert.encoder.layer.11.output.dense.weight\n",
            "bert.encoder.layer.11.output.dense.bias\n",
            "bert.encoder.layer.11.output.LayerNorm.weight\n",
            "bert.encoder.layer.11.output.LayerNorm.bias\n",
            "bert.pooler.dense.weight\n",
            "bert.pooler.dense.bias\n",
            "classifier.weight\n",
            "classifier.bias\n",
            "=============\n",
            "bert-base-cased :\n",
            "=============\n",
            "BertForSequenceClassification(\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSdpaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
            ")\n",
            "=============\n",
            "BertConfig {\n",
            "  \"_attn_implementation_autoset\": true,\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.50.3\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "=============\n",
            "num_parameters: 108311810\n",
            "=============\n",
            "num_trainable_parameters: 108311810\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Layer Configuration"
      ],
      "metadata": {
        "id": "9xKfKrycZH8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze/Unfreeze Layers & Additional Configuration Parameters\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "layers_to_unfreeze = [\n",
        "    \"bert.encoder.layer.9.\",\n",
        "    \"bert.encoder.layer.10.\",\n",
        "    \"bert.encoder.layer.11.\",\n",
        "    \"pooler.\",\n",
        "    \"classifier.\",\n",
        "]\n",
        "\n",
        "freeze_unfreeze_layers(model, layers_to_unfreeze=layers_to_unfreeze)\n",
        "\n",
        "\n",
        "bert_config = BertConfig(\n",
        "    # vocab_size=28996,\n",
        "    hidden_size=768,\n",
        "    # num_hidden_layers=12,\n",
        "    # num_attention_heads=12,\n",
        "    intermediate_size=3072,\n",
        "    # max_position_embeddings=512,\n",
        "    type_vocab_size=2,\n",
        "\n",
        "    hidden_dropout_prob=0.3,\n",
        "    attention_probs_dropout_prob=0.2,\n",
        "    # classifier_dropout=None,\n",
        "    # initializer_range=0.02,\n",
        "    # layer_norm_eps=1e-12,\n",
        "\n",
        "    hidden_act=\"gelu\",\n",
        "    gradient_checkpointing=False,\n",
        "    position_embedding_type=\"absolute\",\n",
        "    use_cache=True,\n",
        "    pad_token_id=0\n",
        ")\n",
        "\n",
        "model.bert.pooler.activation = nn.ReLU() # Tanh() replaced as the pooler layer activation function\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    print(name, \"requires_grad=\", param.requires_grad)\n",
        "\n",
        "print(\"\\nLayers that are 'True' are trainable. 'False' are frozen.\")\n",
        "\n",
        "print(\"=============\")\n",
        "print(named_model, \":\")\n",
        "print(\"=============\")\n",
        "print(model)\n",
        "print(\"=============\")\n",
        "print(model.config)\n",
        "print(\"=============\")\n",
        "print(\"num_parameters:\", model.num_parameters())\n",
        "print(\"=============\")\n",
        "print(\"num_trainable_parameters:\", model.num_parameters(only_trainable=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTv7BTh5VXQv",
        "outputId": "b99be45b-697a-48f7-ff0a-3445a88b729b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert.embeddings.word_embeddings.weight requires_grad= False\n",
            "bert.embeddings.position_embeddings.weight requires_grad= False\n",
            "bert.embeddings.token_type_embeddings.weight requires_grad= False\n",
            "bert.embeddings.LayerNorm.weight requires_grad= False\n",
            "bert.embeddings.LayerNorm.bias requires_grad= False\n",
            "bert.encoder.layer.0.attention.self.query.weight requires_grad= False\n",
            "bert.encoder.layer.0.attention.self.query.bias requires_grad= False\n",
            "bert.encoder.layer.0.attention.self.key.weight requires_grad= False\n",
            "bert.encoder.layer.0.attention.self.key.bias requires_grad= False\n",
            "bert.encoder.layer.0.attention.self.value.weight requires_grad= False\n",
            "bert.encoder.layer.0.attention.self.value.bias requires_grad= False\n",
            "bert.encoder.layer.0.attention.output.dense.weight requires_grad= False\n",
            "bert.encoder.layer.0.attention.output.dense.bias requires_grad= False\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight requires_grad= False\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias requires_grad= False\n",
            "bert.encoder.layer.0.intermediate.dense.weight requires_grad= False\n",
            "bert.encoder.layer.0.intermediate.dense.bias requires_grad= False\n",
            "bert.encoder.layer.0.output.dense.weight requires_grad= False\n",
            "bert.encoder.layer.0.output.dense.bias requires_grad= False\n",
            "bert.encoder.layer.0.output.LayerNorm.weight requires_grad= False\n",
            "bert.encoder.layer.0.output.LayerNorm.bias requires_grad= False\n",
            "bert.encoder.layer.1.attention.self.query.weight requires_grad= False\n",
            "bert.encoder.layer.1.attention.self.query.bias requires_grad= False\n",
            "bert.encoder.layer.1.attention.self.key.weight requires_grad= False\n",
            "bert.encoder.layer.1.attention.self.key.bias requires_grad= False\n",
            "bert.encoder.layer.1.attention.self.value.weight requires_grad= False\n",
            "bert.encoder.layer.1.attention.self.value.bias requires_grad= False\n",
            "bert.encoder.layer.1.attention.output.dense.weight requires_grad= False\n",
            "bert.encoder.layer.1.attention.output.dense.bias requires_grad= False\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.weight requires_grad= False\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.bias requires_grad= False\n",
            "bert.encoder.layer.1.intermediate.dense.weight requires_grad= False\n",
            "bert.encoder.layer.1.intermediate.dense.bias requires_grad= False\n",
            "bert.encoder.layer.1.output.dense.weight requires_grad= False\n",
            "bert.encoder.layer.1.output.dense.bias requires_grad= False\n",
            "bert.encoder.layer.1.output.LayerNorm.weight requires_grad= False\n",
            "bert.encoder.layer.1.output.LayerNorm.bias requires_grad= False\n",
            "bert.encoder.layer.2.attention.self.query.weight requires_grad= False\n",
            "bert.encoder.layer.2.attention.self.query.bias requires_grad= False\n",
            "bert.encoder.layer.2.attention.self.key.weight requires_grad= False\n",
            "bert.encoder.layer.2.attention.self.key.bias requires_grad= False\n",
            "bert.encoder.layer.2.attention.self.value.weight requires_grad= False\n",
            "bert.encoder.layer.2.attention.self.value.bias requires_grad= False\n",
            "bert.encoder.layer.2.attention.output.dense.weight requires_grad= False\n",
            "bert.encoder.layer.2.attention.output.dense.bias requires_grad= False\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.weight requires_grad= False\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.bias requires_grad= False\n",
            "bert.encoder.layer.2.intermediate.dense.weight requires_grad= False\n",
            "bert.encoder.layer.2.intermediate.dense.bias requires_grad= False\n",
            "bert.encoder.layer.2.output.dense.weight requires_grad= False\n",
            "bert.encoder.layer.2.output.dense.bias requires_grad= False\n",
            "bert.encoder.layer.2.output.LayerNorm.weight requires_grad= False\n",
            "bert.encoder.layer.2.output.LayerNorm.bias requires_grad= False\n",
            "bert.encoder.layer.3.attention.self.query.weight requires_grad= False\n",
            "bert.encoder.layer.3.attention.self.query.bias requires_grad= False\n",
            "bert.encoder.layer.3.attention.self.key.weight requires_grad= False\n",
            "bert.encoder.layer.3.attention.self.key.bias requires_grad= False\n",
            "bert.encoder.layer.3.attention.self.value.weight requires_grad= False\n",
            "bert.encoder.layer.3.attention.self.value.bias requires_grad= False\n",
            "bert.encoder.layer.3.attention.output.dense.weight requires_grad= False\n",
            "bert.encoder.layer.3.attention.output.dense.bias requires_grad= False\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.weight requires_grad= False\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.bias requires_grad= False\n",
            "bert.encoder.layer.3.intermediate.dense.weight requires_grad= False\n",
            "bert.encoder.layer.3.intermediate.dense.bias requires_grad= False\n",
            "bert.encoder.layer.3.output.dense.weight requires_grad= False\n",
            "bert.encoder.layer.3.output.dense.bias requires_grad= False\n",
            "bert.encoder.layer.3.output.LayerNorm.weight requires_grad= False\n",
            "bert.encoder.layer.3.output.LayerNorm.bias requires_grad= False\n",
            "bert.encoder.layer.4.attention.self.query.weight requires_grad= False\n",
            "bert.encoder.layer.4.attention.self.query.bias requires_grad= False\n",
            "bert.encoder.layer.4.attention.self.key.weight requires_grad= False\n",
            "bert.encoder.layer.4.attention.self.key.bias requires_grad= False\n",
            "bert.encoder.layer.4.attention.self.value.weight requires_grad= False\n",
            "bert.encoder.layer.4.attention.self.value.bias requires_grad= False\n",
            "bert.encoder.layer.4.attention.output.dense.weight requires_grad= False\n",
            "bert.encoder.layer.4.attention.output.dense.bias requires_grad= False\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.weight requires_grad= False\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.bias requires_grad= False\n",
            "bert.encoder.layer.4.intermediate.dense.weight requires_grad= False\n",
            "bert.encoder.layer.4.intermediate.dense.bias requires_grad= False\n",
            "bert.encoder.layer.4.output.dense.weight requires_grad= False\n",
            "bert.encoder.layer.4.output.dense.bias requires_grad= False\n",
            "bert.encoder.layer.4.output.LayerNorm.weight requires_grad= False\n",
            "bert.encoder.layer.4.output.LayerNorm.bias requires_grad= False\n",
            "bert.encoder.layer.5.attention.self.query.weight requires_grad= False\n",
            "bert.encoder.layer.5.attention.self.query.bias requires_grad= False\n",
            "bert.encoder.layer.5.attention.self.key.weight requires_grad= False\n",
            "bert.encoder.layer.5.attention.self.key.bias requires_grad= False\n",
            "bert.encoder.layer.5.attention.self.value.weight requires_grad= False\n",
            "bert.encoder.layer.5.attention.self.value.bias requires_grad= False\n",
            "bert.encoder.layer.5.attention.output.dense.weight requires_grad= False\n",
            "bert.encoder.layer.5.attention.output.dense.bias requires_grad= False\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.weight requires_grad= False\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.bias requires_grad= False\n",
            "bert.encoder.layer.5.intermediate.dense.weight requires_grad= False\n",
            "bert.encoder.layer.5.intermediate.dense.bias requires_grad= False\n",
            "bert.encoder.layer.5.output.dense.weight requires_grad= False\n",
            "bert.encoder.layer.5.output.dense.bias requires_grad= False\n",
            "bert.encoder.layer.5.output.LayerNorm.weight requires_grad= False\n",
            "bert.encoder.layer.5.output.LayerNorm.bias requires_grad= False\n",
            "bert.encoder.layer.6.attention.self.query.weight requires_grad= False\n",
            "bert.encoder.layer.6.attention.self.query.bias requires_grad= False\n",
            "bert.encoder.layer.6.attention.self.key.weight requires_grad= False\n",
            "bert.encoder.layer.6.attention.self.key.bias requires_grad= False\n",
            "bert.encoder.layer.6.attention.self.value.weight requires_grad= False\n",
            "bert.encoder.layer.6.attention.self.value.bias requires_grad= False\n",
            "bert.encoder.layer.6.attention.output.dense.weight requires_grad= False\n",
            "bert.encoder.layer.6.attention.output.dense.bias requires_grad= False\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.weight requires_grad= False\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.bias requires_grad= False\n",
            "bert.encoder.layer.6.intermediate.dense.weight requires_grad= False\n",
            "bert.encoder.layer.6.intermediate.dense.bias requires_grad= False\n",
            "bert.encoder.layer.6.output.dense.weight requires_grad= False\n",
            "bert.encoder.layer.6.output.dense.bias requires_grad= False\n",
            "bert.encoder.layer.6.output.LayerNorm.weight requires_grad= False\n",
            "bert.encoder.layer.6.output.LayerNorm.bias requires_grad= False\n",
            "bert.encoder.layer.7.attention.self.query.weight requires_grad= False\n",
            "bert.encoder.layer.7.attention.self.query.bias requires_grad= False\n",
            "bert.encoder.layer.7.attention.self.key.weight requires_grad= False\n",
            "bert.encoder.layer.7.attention.self.key.bias requires_grad= False\n",
            "bert.encoder.layer.7.attention.self.value.weight requires_grad= False\n",
            "bert.encoder.layer.7.attention.self.value.bias requires_grad= False\n",
            "bert.encoder.layer.7.attention.output.dense.weight requires_grad= False\n",
            "bert.encoder.layer.7.attention.output.dense.bias requires_grad= False\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.weight requires_grad= False\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.bias requires_grad= False\n",
            "bert.encoder.layer.7.intermediate.dense.weight requires_grad= False\n",
            "bert.encoder.layer.7.intermediate.dense.bias requires_grad= False\n",
            "bert.encoder.layer.7.output.dense.weight requires_grad= False\n",
            "bert.encoder.layer.7.output.dense.bias requires_grad= False\n",
            "bert.encoder.layer.7.output.LayerNorm.weight requires_grad= False\n",
            "bert.encoder.layer.7.output.LayerNorm.bias requires_grad= False\n",
            "bert.encoder.layer.8.attention.self.query.weight requires_grad= False\n",
            "bert.encoder.layer.8.attention.self.query.bias requires_grad= False\n",
            "bert.encoder.layer.8.attention.self.key.weight requires_grad= False\n",
            "bert.encoder.layer.8.attention.self.key.bias requires_grad= False\n",
            "bert.encoder.layer.8.attention.self.value.weight requires_grad= False\n",
            "bert.encoder.layer.8.attention.self.value.bias requires_grad= False\n",
            "bert.encoder.layer.8.attention.output.dense.weight requires_grad= False\n",
            "bert.encoder.layer.8.attention.output.dense.bias requires_grad= False\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.weight requires_grad= False\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.bias requires_grad= False\n",
            "bert.encoder.layer.8.intermediate.dense.weight requires_grad= False\n",
            "bert.encoder.layer.8.intermediate.dense.bias requires_grad= False\n",
            "bert.encoder.layer.8.output.dense.weight requires_grad= False\n",
            "bert.encoder.layer.8.output.dense.bias requires_grad= False\n",
            "bert.encoder.layer.8.output.LayerNorm.weight requires_grad= False\n",
            "bert.encoder.layer.8.output.LayerNorm.bias requires_grad= False\n",
            "bert.encoder.layer.9.attention.self.query.weight requires_grad= True\n",
            "bert.encoder.layer.9.attention.self.query.bias requires_grad= True\n",
            "bert.encoder.layer.9.attention.self.key.weight requires_grad= True\n",
            "bert.encoder.layer.9.attention.self.key.bias requires_grad= True\n",
            "bert.encoder.layer.9.attention.self.value.weight requires_grad= True\n",
            "bert.encoder.layer.9.attention.self.value.bias requires_grad= True\n",
            "bert.encoder.layer.9.attention.output.dense.weight requires_grad= True\n",
            "bert.encoder.layer.9.attention.output.dense.bias requires_grad= True\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.weight requires_grad= True\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.bias requires_grad= True\n",
            "bert.encoder.layer.9.intermediate.dense.weight requires_grad= True\n",
            "bert.encoder.layer.9.intermediate.dense.bias requires_grad= True\n",
            "bert.encoder.layer.9.output.dense.weight requires_grad= True\n",
            "bert.encoder.layer.9.output.dense.bias requires_grad= True\n",
            "bert.encoder.layer.9.output.LayerNorm.weight requires_grad= True\n",
            "bert.encoder.layer.9.output.LayerNorm.bias requires_grad= True\n",
            "bert.encoder.layer.10.attention.self.query.weight requires_grad= True\n",
            "bert.encoder.layer.10.attention.self.query.bias requires_grad= True\n",
            "bert.encoder.layer.10.attention.self.key.weight requires_grad= True\n",
            "bert.encoder.layer.10.attention.self.key.bias requires_grad= True\n",
            "bert.encoder.layer.10.attention.self.value.weight requires_grad= True\n",
            "bert.encoder.layer.10.attention.self.value.bias requires_grad= True\n",
            "bert.encoder.layer.10.attention.output.dense.weight requires_grad= True\n",
            "bert.encoder.layer.10.attention.output.dense.bias requires_grad= True\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.weight requires_grad= True\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.bias requires_grad= True\n",
            "bert.encoder.layer.10.intermediate.dense.weight requires_grad= True\n",
            "bert.encoder.layer.10.intermediate.dense.bias requires_grad= True\n",
            "bert.encoder.layer.10.output.dense.weight requires_grad= True\n",
            "bert.encoder.layer.10.output.dense.bias requires_grad= True\n",
            "bert.encoder.layer.10.output.LayerNorm.weight requires_grad= True\n",
            "bert.encoder.layer.10.output.LayerNorm.bias requires_grad= True\n",
            "bert.encoder.layer.11.attention.self.query.weight requires_grad= True\n",
            "bert.encoder.layer.11.attention.self.query.bias requires_grad= True\n",
            "bert.encoder.layer.11.attention.self.key.weight requires_grad= True\n",
            "bert.encoder.layer.11.attention.self.key.bias requires_grad= True\n",
            "bert.encoder.layer.11.attention.self.value.weight requires_grad= True\n",
            "bert.encoder.layer.11.attention.self.value.bias requires_grad= True\n",
            "bert.encoder.layer.11.attention.output.dense.weight requires_grad= True\n",
            "bert.encoder.layer.11.attention.output.dense.bias requires_grad= True\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.weight requires_grad= True\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.bias requires_grad= True\n",
            "bert.encoder.layer.11.intermediate.dense.weight requires_grad= True\n",
            "bert.encoder.layer.11.intermediate.dense.bias requires_grad= True\n",
            "bert.encoder.layer.11.output.dense.weight requires_grad= True\n",
            "bert.encoder.layer.11.output.dense.bias requires_grad= True\n",
            "bert.encoder.layer.11.output.LayerNorm.weight requires_grad= True\n",
            "bert.encoder.layer.11.output.LayerNorm.bias requires_grad= True\n",
            "bert.pooler.dense.weight requires_grad= True\n",
            "bert.pooler.dense.bias requires_grad= True\n",
            "classifier.weight requires_grad= True\n",
            "classifier.bias requires_grad= True\n",
            "\n",
            "Layers that are 'True' are trainable. 'False' are frozen.\n",
            "=============\n",
            "bert-base-cased :\n",
            "=============\n",
            "BertForSequenceClassification(\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSdpaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
            ")\n",
            "=============\n",
            "BertConfig {\n",
            "  \"_attn_implementation_autoset\": true,\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.50.3\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "=============\n",
            "num_parameters: 108311810\n",
            "=============\n",
            "num_trainable_parameters: 21855746\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dataset Preparation"
      ],
      "metadata": {
        "id": "s0vgf-iJZQzv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize & Prepare Datasets\n",
        "\n",
        "train_data_hf = prepare_dataset(\n",
        "    df_train,\n",
        "    tokenizer,\n",
        "    text_col=x_col,\n",
        "    label_col=y_col,\n",
        "    max_length=length_max\n",
        ")\n",
        "\n",
        "val_data_hf = prepare_dataset(\n",
        "    df_val,\n",
        "    tokenizer,\n",
        "    text_col=x_col,\n",
        "    label_col=y_col,\n",
        "    max_length=length_max\n",
        ")\n",
        "\n",
        "test_data_hf = prepare_dataset(\n",
        "    df_test,\n",
        "    tokenizer,\n",
        "    text_col=x_col,\n",
        "    label_col=y_col,\n",
        "    max_length=length_max\n",
        "\n",
        ")\n",
        "\n",
        "print(\"Datasets prepared. Sample from train_data_hf:\\n\", train_data_hf[10])\n",
        "print(\"Datasets prepared. Sample from train_data_hf:\\n\", val_data_hf[10])\n",
        "print(\"Datasets prepared. Sample from train_data_hf:\\n\", test_data_hf[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a93c0f01508341b4a0245c826fe9499a",
            "c999b8b94ef64ec89c9cf8c792001d7a",
            "8f3347d1f5c94a17b7f87e35249d2047",
            "2eb355a1ae03458ea436b5a5f25b1434",
            "21f7277d629f44fabed866ad07abafb6",
            "a60b4f890dd74c2486372d38a11303f1",
            "474bdc8a359d443697571ce2636cd63d",
            "f019ce704d5e49019d949a999f2823fb",
            "76ce63e4d748469c94e891aea9fdf7df",
            "db8e8a4e34dc4fab8638deda4689b52c",
            "275cfaccfee84232b2420aff5b241f71",
            "e51cc19c1b96496eb958646577011178",
            "d1214fc434e74c6e88454f907a8cbf07",
            "7bcd765707c5446ba472ea2e75a464cd",
            "c0925070d0a942b2972f1b80892d5878",
            "d63572b2174243ba9ae1142514afa9a9",
            "0e2183cbdf1f47c7ad1009569bfec12a",
            "fb1632f9a0924cf4882cf09fefd4dc17",
            "894839febf0e4f13bfc0c4d80802b033",
            "764d46c7504d4cc2afac766818b15a4c",
            "7d901d09335841e48c5b242c2ee69bf8",
            "406545da2ce6467086d1a3f0b664fa92",
            "5ece3a9c4a884a9b974564d4514d4eb4",
            "916abd9db2d64cc7898667389a6f14ea",
            "db7491715190423185defe993048eef7",
            "8e84c6c11cb54fe6b2114a230cbf2250",
            "0e29a698896449caaa0d361269b2df58",
            "92f961742bce4b418f8eeccb7c871ebe",
            "8cf66e513ea2414f9adf67a6a188aa10",
            "58f1b32db9e34ba98f5f02f5b43ed568",
            "f72f1056685543ecaa4e4031d7586301",
            "2c5ea09902f9417a81e5f73c51012d3a",
            "e318b4a09216473782af28cff35b6cf7"
          ]
        },
        "id": "bMQMoy5rcdLv",
        "outputId": "e66c3980-ebfd-43f7-e356-a8a8ea84e712"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/7662 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a93c0f01508341b4a0245c826fe9499a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/421 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e51cc19c1b96496eb958646577011178"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/917 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ece3a9c4a884a9b974564d4514d4eb4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datasets prepared. Sample from train_data_hf:\n",
            " {'labels': tensor(0), 'input_ids': tensor([  101,  1252,  1106,  1103,  3824,  1104, 19892, 11220,  1324,  1119,\n",
            "         1522,  3839,   117,  1272,  1103,  1555,  1104,  1103, 11563,  5609,\n",
            "         1106,  1172,   132,  1152,  2446,  1122,  1113,  1147,  3221,   119,\n",
            "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])}\n",
            "Datasets prepared. Sample from train_data_hf:\n",
            " {'labels': tensor(0), 'input_ids': tensor([ 101, 6589, 1103, 2226, 1108, 1304, 4259,  117, 1105, 1117, 4470, 4562,\n",
            "        1107, 1140,  119,  102,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])}\n",
            "Datasets prepared. Sample from train_data_hf:\n",
            " {'labels': tensor(1), 'input_ids': tensor([  101,  1220,  1508,  1117,  8526,  1107,  1103,  1402,  1104,  1147,\n",
            "         6807,   117,  1105, 27052,  1117,  1246,  1107,  1103,  1402,  1104,\n",
            "        10136,  7528,   119,   102,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train & Evaluate\n",
        "\n",
        "trained_model, trainer_obj = train_transformer_model(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=train_data_hf,\n",
        "    val_dataset=val_data_hf,\n",
        "    output_dir=dir_results,\n",
        "    num_epochs=num_epochs,\n",
        "    batch_size=size_batch,\n",
        "    lr=learning_rate,\n",
        "    weight_decay=regularization_weight_decay\n",
        ")\n",
        "\n",
        "metrics = trainer_obj.evaluate()\n",
        "print(\"Validation metrics:\", metrics)\n",
        "\n",
        "test_metrics = trainer_obj.evaluate(test_data_hf) if test_data_hf else None\n",
        "print(\"Test metrics:\", test_metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "-entrH9lieD0",
        "outputId": "b839a1b4-1f29-44a1-ae5d-bd9499f266e8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "<ipython-input-21-295bdbf803a2>:30: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4790' max='4790' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4790/4790 02:56, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.731300</td>\n",
              "      <td>0.706221</td>\n",
              "      <td>0.465558</td>\n",
              "      <td>0.429185</td>\n",
              "      <td>0.520833</td>\n",
              "      <td>0.470588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.704600</td>\n",
              "      <td>0.696122</td>\n",
              "      <td>0.510689</td>\n",
              "      <td>0.469828</td>\n",
              "      <td>0.567708</td>\n",
              "      <td>0.514151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.699400</td>\n",
              "      <td>0.692158</td>\n",
              "      <td>0.546318</td>\n",
              "      <td>0.502439</td>\n",
              "      <td>0.536458</td>\n",
              "      <td>0.518892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.697200</td>\n",
              "      <td>0.690662</td>\n",
              "      <td>0.558195</td>\n",
              "      <td>0.515625</td>\n",
              "      <td>0.515625</td>\n",
              "      <td>0.515625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.695400</td>\n",
              "      <td>0.689904</td>\n",
              "      <td>0.553444</td>\n",
              "      <td>0.510638</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.505263</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='168' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [53/53 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation metrics: {'eval_loss': 0.6899044513702393, 'eval_accuracy': 0.5534441805225653, 'eval_precision': 0.5106382978723404, 'eval_recall': 0.5, 'eval_f1': 0.5052631578947369, 'eval_runtime': 5.6434, 'eval_samples_per_second': 74.601, 'eval_steps_per_second': 9.392, 'epoch': 5.0}\n",
            "Test metrics: {'eval_loss': 0.6933835744857788, 'eval_accuracy': 0.5310796074154853, 'eval_precision': 0.5136476426799007, 'eval_recall': 0.46938775510204084, 'eval_f1': 0.490521327014218, 'eval_runtime': 7.662, 'eval_samples_per_second': 119.681, 'eval_steps_per_second': 15.009, 'epoch': 5.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Experiment configuration used with this experiment:\")\n",
        "print(\"model used:\", named_model)\n",
        "print(\"learning rate used:\", learning_rate)\n",
        "print(\"number of epochs:\", num_epochs)\n",
        "print(\"maximum sequence length:\", length_max)\n",
        "print(\"batch size used:\", size_batch)\n",
        "print(\"regularization value:\", regularization_weight_decay)\n",
        "print(\"outcome variable:\", y_col)\n",
        "print(\"task:\", x_task)\n",
        "print(\"input column:\", x_col)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8hht2anjdDJ",
        "outputId": "ef5c045c-2d83-45e2-bdaf-f1d3dd35e402"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment configuration used with this experiment:\n",
            "model used: bert-base-cased\n",
            "learning rate used: 5e-07\n",
            "number of epochs: 5\n",
            "maximum sequence length: 128\n",
            "batch size used: 8\n",
            "regularization value: 0\n",
            "outcome variable: binary_complexity\n",
            "task: single\n",
            "input column: sentence_no_contractions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save model checkpoint\n",
        "\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "model_save_path = os.path.join(dir_models, f\"{named_model}_{timestamp}\")\n",
        "\n",
        "trainer_obj.save_model(model_save_path)\n",
        "print(f\"Model checkpoint saved to: {model_save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSTfG1W6lM9Q",
        "outputId": "271ef99f-cfe1-44f4-f44a-eff7cd85236a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model checkpoint saved to: /content/drive/MyDrive/266-final/models/bert-base-cased_20250407_235945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiment 1.1: bert-base-cased single with additional epochs"
      ],
      "metadata": {
        "id": "iwW4R6lWk5Th"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Experiment Parameters\n",
        "\n",
        "named_model = \"bert-base-cased\"\n",
        "# named_model = \"roberta-base\"\n",
        "# named_model = \"bert-large\"\n",
        "# named_model = \"roberta-large\"\n",
        "# named_model = \"\" # modern bert\n",
        "\n",
        "# learning_rate = 1e-3\n",
        "# learning_rate = 1e-4\n",
        "# learning_rate = 1e-5\n",
        "# learning_rate = 5e-6\n",
        "learning_rate = 5e-7\n",
        "# learning_rate = 5e-8\n",
        "\n",
        "# num_epochs = 3\n",
        "num_epochs = 5\n",
        "# num_epochs = 10\n",
        "# num_epochs = 15\n",
        "# num_epochs = 20\n",
        "\n",
        "length_max = 128\n",
        "# length_max = 256\n",
        "# length_max = 348\n",
        "# length_max = 512\n",
        "\n",
        "# size_batch = 1\n",
        "# size_batch = 4\n",
        "size_batch = 8\n",
        "# size_batch = 16\n",
        "# size_batch = 24\n",
        "# size_batch = 32\n",
        "\n",
        "regularization_weight_decay = 0\n",
        "# regularization_weight_decay = 0.1\n",
        "# regularization_weight_decay = 0.5\n",
        "\n",
        "# dropout???\n",
        "\n",
        "# layers to freeze and unfreeze?\n",
        "\n",
        "y_col = \"binary_complexity\"\n",
        "# y_col = \"complexity\"\n",
        "\n",
        "x_task = \"single\"\n",
        "# x_task = \"multi\"\n",
        "\n",
        "# x_col = \"sentence\"\n",
        "x_col = \"sentence_no_contractions\"\n",
        "# x_col = \"pos_sequence\"\n",
        "# x_col = \"dep_sequence\"\n",
        "# x_col = \"morph_sequence\"\n",
        "\n",
        "if x_task == \"single\":\n",
        "    df_train = train_single_df\n",
        "    df_val   = trial_val_single_df\n",
        "    df_test  = test_single_df\n",
        "else:\n",
        "    df_train = train_multi_df\n",
        "    df_val   = trial_val_multi_df\n",
        "    df_test  = test_multi_df"
      ],
      "metadata": {
        "id": "Ew3YUukFlGUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-ETCjJYpsJqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nFVChQwSsJp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h3pwvxuesJo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aysFT4tAsJoF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}