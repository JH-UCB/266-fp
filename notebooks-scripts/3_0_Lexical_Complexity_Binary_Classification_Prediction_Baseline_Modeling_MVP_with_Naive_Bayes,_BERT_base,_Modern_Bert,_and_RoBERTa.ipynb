{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1",
      "machine_shape": "hm",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@title Install Packages"
      ],
      "metadata": {
        "id": "xYRurcbg2fuq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XWeMhKnlvi9F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e507fac-8136-429b-d6d0-054b2cacc832"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.3/118.3 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers\n",
        "!pip install -q torchinfo\n",
        "!pip install -q datasets\n",
        "!pip install -q evaluate\n",
        "!pip install -q nltk\n",
        "!pip install -q contractions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update\n",
        "! sudo apt-get install tree"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rX3VqZu11-s_",
        "outputId": "b4817a48-b800-430e-9a0a-795a1f4e81b9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "\r0% [Waiting for headers] [1 InRelease 14.2 kB/129 kB 11%] [Connecting to cloud.\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [1 InRelease 30.1 kB/129 kB 23%] [Connecting to cloud.\r                                                                               \rGet:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "\r0% [3 InRelease 15.6 kB/128 kB 12%] [1 InRelease 30.1 kB/129 kB 23%] [Connected\r0% [3 InRelease 73.5 kB/128 kB 57%] [Waiting for headers] [Waiting for headers]\r0% [Waiting for headers] [Waiting for headers] [Connected to ppa.launchpadconte\r                                                                               \rGet:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "\r0% [Waiting for headers] [Waiting for headers] [4 InRelease 6,555 B/6,555 B 100\r0% [Waiting for headers] [Waiting for headers] [Connected to ppa.launchpadconte\r                                                                               \rGet:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,775 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,148 kB]\n",
            "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,683 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,978 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,540 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,092 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,241 kB]\n",
            "Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,804 kB]\n",
            "Fetched 28.7 MB in 2s (12.5 MB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tree\n",
            "0 upgraded, 1 newly installed, 0 to remove and 21 not upgraded.\n",
            "Need to get 47.9 kB of archives.\n",
            "After this operation, 116 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tree amd64 2.0.2-1 [47.9 kB]\n",
            "Fetched 47.9 kB in 0s (355 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tree.\n",
            "(Reading database ... 122056 files and directories currently installed.)\n",
            "Preparing to unpack .../tree_2.0.2-1_amd64.deb ...\n",
            "Unpacking tree (2.0.2-1) ...\n",
            "Setting up tree (2.0.2-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports\n",
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "import evaluate\n",
        "import transformers\n",
        "\n",
        "import contractions\n",
        "\n",
        "from torchinfo import summary\n",
        "from datasets import load_dataset\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import sklearn\n",
        "\n",
        "import spacy\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "3wEgNBR6zosA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Mount Google Drive"
      ],
      "metadata": {
        "id": "rSP7bIn12YU7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWKPq7h01cXk",
        "outputId": "c9a1105b-f425-4f21-9bf4-2858fd529a57"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir_root = '/content/drive/MyDrive/266-final/'\n",
        "# dir_data = '/content/drive/MyDrive/266-final/data/'\n",
        "# dir_data = '/content/drive/MyDrive/266-final/data/se21-t1-comp-lex-master/'\n",
        "dir_data = '/content/drive/MyDrive/266-final/data/266-comp-lex-master'\n",
        "dir_models = '/content/drive/MyDrive/266-final/models/'\n",
        "dir_results = '/content/drive/MyDrive/266-final/results/'"
      ],
      "metadata": {
        "id": "I3Tfro3Zzop5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tree /content/drive/MyDrive/266-final/data/266-comp-lex-master/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qw9f1Hol2UhL",
        "outputId": "470ce834-7459-4891-b7db-6de9f9823ad7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01;34m/content/drive/MyDrive/266-final/data/266-comp-lex-master/\u001b[0m\n",
            "├── \u001b[01;34mfe-test-labels\u001b[0m\n",
            "│   ├── \u001b[00mtest_multi_df.csv\u001b[0m\n",
            "│   └── \u001b[00mtest_single_df.csv\u001b[0m\n",
            "├── \u001b[01;34mfe-train\u001b[0m\n",
            "│   ├── \u001b[00mtrain_multi_df.csv\u001b[0m\n",
            "│   └── \u001b[00mtrain_single_df.csv\u001b[0m\n",
            "├── \u001b[01;34mfe-trial-val\u001b[0m\n",
            "│   ├── \u001b[00mtrial_val_multi_df.csv\u001b[0m\n",
            "│   └── \u001b[00mtrial_val_single_df.csv\u001b[0m\n",
            "├── \u001b[01;34mtest-labels\u001b[0m\n",
            "│   ├── \u001b[00mlcp_multi_test.tsv\u001b[0m\n",
            "│   └── \u001b[00mlcp_single_test.tsv\u001b[0m\n",
            "├── \u001b[01;34mtrain\u001b[0m\n",
            "│   ├── \u001b[00mlcp_multi_train.tsv\u001b[0m\n",
            "│   └── \u001b[00mlcp_single_train.tsv\u001b[0m\n",
            "└── \u001b[01;34mtrial\u001b[0m\n",
            "    ├── \u001b[00mlcp_multi_trial.tsv\u001b[0m\n",
            "    └── \u001b[00mlcp_single_trial.tsv\u001b[0m\n",
            "\n",
            "6 directories, 12 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -R /content/drive/MyDrive/266-final/data/266-comp-lex-master/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zgul33NlKkbV",
        "outputId": "196690f4-b3e4-4233-f4eb-d20b161b4b48"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/266-final/data/266-comp-lex-master/:\n",
            "fe-test-labels\tfe-train  fe-trial-val\ttest-labels  train  trial\n",
            "\n",
            "/content/drive/MyDrive/266-final/data/266-comp-lex-master/fe-test-labels:\n",
            "test_multi_df.csv  test_single_df.csv\n",
            "\n",
            "/content/drive/MyDrive/266-final/data/266-comp-lex-master/fe-train:\n",
            "train_multi_df.csv  train_single_df.csv\n",
            "\n",
            "/content/drive/MyDrive/266-final/data/266-comp-lex-master/fe-trial-val:\n",
            "trial_val_multi_df.csv\ttrial_val_single_df.csv\n",
            "\n",
            "/content/drive/MyDrive/266-final/data/266-comp-lex-master/test-labels:\n",
            "lcp_multi_test.tsv  lcp_single_test.tsv\n",
            "\n",
            "/content/drive/MyDrive/266-final/data/266-comp-lex-master/train:\n",
            "lcp_multi_train.tsv  lcp_single_train.tsv\n",
            "\n",
            "/content/drive/MyDrive/266-final/data/266-comp-lex-master/trial:\n",
            "lcp_multi_trial.tsv  lcp_single_trial.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tree /content/drive/MyDrive/266-final/data/266-comp-lex-master/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9f8sPUBdbVr",
        "outputId": "497db26d-d8fe-42d8-ad5b-bd524c0bedbe"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01;34m/content/drive/MyDrive/266-final/data/266-comp-lex-master/\u001b[0m\n",
            "├── \u001b[01;34mfe-test-labels\u001b[0m\n",
            "│   ├── \u001b[00mtest_multi_df.csv\u001b[0m\n",
            "│   └── \u001b[00mtest_single_df.csv\u001b[0m\n",
            "├── \u001b[01;34mfe-train\u001b[0m\n",
            "│   ├── \u001b[00mtrain_multi_df.csv\u001b[0m\n",
            "│   └── \u001b[00mtrain_single_df.csv\u001b[0m\n",
            "├── \u001b[01;34mfe-trial-val\u001b[0m\n",
            "│   ├── \u001b[00mtrial_val_multi_df.csv\u001b[0m\n",
            "│   └── \u001b[00mtrial_val_single_df.csv\u001b[0m\n",
            "├── \u001b[01;34mtest-labels\u001b[0m\n",
            "│   ├── \u001b[00mlcp_multi_test.tsv\u001b[0m\n",
            "│   └── \u001b[00mlcp_single_test.tsv\u001b[0m\n",
            "├── \u001b[01;34mtrain\u001b[0m\n",
            "│   ├── \u001b[00mlcp_multi_train.tsv\u001b[0m\n",
            "│   └── \u001b[00mlcp_single_train.tsv\u001b[0m\n",
            "└── \u001b[01;34mtrial\u001b[0m\n",
            "    ├── \u001b[00mlcp_multi_trial.tsv\u001b[0m\n",
            "    └── \u001b[00mlcp_single_trial.tsv\u001b[0m\n",
            "\n",
            "6 directories, 12 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import Data"
      ],
      "metadata": {
        "id": "oftTqvV8zojV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_names = [\n",
        "    \"train_single_df\",\n",
        "    \"train_multi_df\",\n",
        "    \"trial_val_single_df\",\n",
        "    \"trial_val_multi_df\",\n",
        "    \"test_single_df\",\n",
        "    \"test_multi_df\"\n",
        "]\n",
        "\n",
        "loaded_dataframes = {}\n",
        "\n",
        "for df_name in df_names:\n",
        "    if \"train\" in df_name:\n",
        "        subdir = \"fe-train\"\n",
        "    elif \"trial_val\" in df_name:\n",
        "        subdir = \"fe-trial-val\"\n",
        "    elif \"test\" in df_name:\n",
        "        subdir = \"fe-test-labels\"\n",
        "    else:\n",
        "        subdir = None\n",
        "\n",
        "    if subdir:\n",
        "        read_path = os.path.join(dir_data, subdir, f\"{df_name}.csv\")\n",
        "        loaded_df = pd.read_csv(read_path)\n",
        "        loaded_dataframes[df_name] = loaded_df\n",
        "        print(f\"Loaded {df_name} from {read_path}\")\n",
        "\n",
        "for df_name, df in loaded_dataframes.items():\n",
        "    print(f\"\\n>>> {df_name} shape: {df.shape}\")\n",
        "    if 'binary_complexity' in df.columns:\n",
        "        print(df['binary_complexity'].value_counts())\n",
        "        print(df.info())\n",
        "        print(df.head())\n",
        "\n",
        "for df_name, df in loaded_dataframes.items():\n",
        "    globals()[df_name] = df\n",
        "    print(f\"{df_name} loaded into global namespace.\")"
      ],
      "metadata": {
        "id": "73lV0P87eV-P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "203dadff-3a3f-40ac-e19c-11aa6be09c7e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded train_single_df from /content/drive/MyDrive/266-final/data/266-comp-lex-master/fe-train/train_single_df.csv\n",
            "Loaded train_multi_df from /content/drive/MyDrive/266-final/data/266-comp-lex-master/fe-train/train_multi_df.csv\n",
            "Loaded trial_val_single_df from /content/drive/MyDrive/266-final/data/266-comp-lex-master/fe-trial-val/trial_val_single_df.csv\n",
            "Loaded trial_val_multi_df from /content/drive/MyDrive/266-final/data/266-comp-lex-master/fe-trial-val/trial_val_multi_df.csv\n",
            "Loaded test_single_df from /content/drive/MyDrive/266-final/data/266-comp-lex-master/fe-test-labels/test_single_df.csv\n",
            "Loaded test_multi_df from /content/drive/MyDrive/266-final/data/266-comp-lex-master/fe-test-labels/test_multi_df.csv\n",
            "\n",
            ">>> train_single_df shape: (7662, 12)\n",
            "binary_complexity\n",
            "0    3865\n",
            "1    3797\n",
            "Name: count, dtype: int64\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7662 entries, 0 to 7661\n",
            "Data columns (total 12 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   id                        7662 non-null   object \n",
            " 1   corpus                    7662 non-null   object \n",
            " 2   sentence                  7662 non-null   object \n",
            " 3   token                     7655 non-null   object \n",
            " 4   complexity                7662 non-null   float64\n",
            " 5   sentence_no_contractions  7662 non-null   object \n",
            " 6   contraction_expanded      7662 non-null   bool   \n",
            " 7   pos_sequence              7662 non-null   object \n",
            " 8   dep_sequence              7662 non-null   object \n",
            " 9   morph_sequence            7662 non-null   object \n",
            " 10  morph_complexity          7662 non-null   float64\n",
            " 11  binary_complexity         7662 non-null   int64  \n",
            "dtypes: bool(1), float64(2), int64(1), object(8)\n",
            "memory usage: 666.1+ KB\n",
            "None\n",
            "                               id corpus  \\\n",
            "0  3ZLW647WALVGE8EBR50EGUBPU4P32A  bible   \n",
            "1  34R0BODSP1ZBN3DVY8J8XSIY551E5C  bible   \n",
            "2  3S1WOPCJFGTJU2SGNAN2Y213N6WJE3  bible   \n",
            "3  3BFNCI9LYKQN09BHXHH9CLSX5KP738  bible   \n",
            "4  3G5RUKN2EC3YIWSKUXZ8ZVH95R49N2  bible   \n",
            "\n",
            "                                            sentence     token  complexity  \\\n",
            "0  Behold, there came up out of the river seven c...     river    0.000000   \n",
            "1  I am a fellow bondservant with you and with yo...  brothers    0.000000   \n",
            "2  The man, the lord of the land, said to us, 'By...  brothers    0.050000   \n",
            "3  Shimei had sixteen sons and six daughters; but...  brothers    0.150000   \n",
            "4               \"He has put my brothers far from me.  brothers    0.263889   \n",
            "\n",
            "                            sentence_no_contractions  contraction_expanded  \\\n",
            "0  Behold, there came up out of the river seven c...                 False   \n",
            "1  I am a fellow bondservant with you and with yo...                 False   \n",
            "2  The man, the lord of the land, said to us, 'By...                 False   \n",
            "3  Shimei had sixteen sons and six daughters; but...                  True   \n",
            "4               \"He has put my brothers far from me.                 False   \n",
            "\n",
            "                                        pos_sequence  \\\n",
            "0  ['ADV', 'PUNCT', 'PRON', 'VERB', 'ADP', 'ADP',...   \n",
            "1  ['PRON', 'AUX', 'DET', 'ADJ', 'NOUN', 'ADP', '...   \n",
            "2  ['DET', 'NOUN', 'PUNCT', 'DET', 'PROPN', 'ADP'...   \n",
            "3  ['PROPN', 'VERB', 'NUM', 'NOUN', 'CCONJ', 'NUM...   \n",
            "4  ['PUNCT', 'PRON', 'AUX', 'VERB', 'PRON', 'NOUN...   \n",
            "\n",
            "                                        dep_sequence  \\\n",
            "0  ['advmod', 'punct', 'expl', 'ROOT', 'prt', 'pr...   \n",
            "1  ['nsubj', 'ROOT', 'det', 'amod', 'attr', 'prep...   \n",
            "2  ['det', 'nsubj', 'punct', 'det', 'appos', 'pre...   \n",
            "3  ['nsubj', 'ROOT', 'nummod', 'dobj', 'cc', 'num...   \n",
            "4  ['punct', 'nsubj', 'aux', 'ROOT', 'poss', 'dob...   \n",
            "\n",
            "                                      morph_sequence  morph_complexity  \\\n",
            "0  [, PunctType=Comm, , Tense=Past|VerbForm=Fin, ...          1.041667   \n",
            "1  [Case=Nom|Number=Sing|Person=1|PronType=Prs, M...          1.461538   \n",
            "2  [Definite=Def|PronType=Art, Number=Sing, Punct...          1.354167   \n",
            "3  [Number=Sing, Tense=Past|VerbForm=Fin, NumType...          1.275862   \n",
            "4  [PunctSide=Ini|PunctType=Quot, Case=Nom|Gender...          2.500000   \n",
            "\n",
            "   binary_complexity  \n",
            "0                  0  \n",
            "1                  0  \n",
            "2                  0  \n",
            "3                  0  \n",
            "4                  0  \n",
            "\n",
            ">>> train_multi_df shape: (1517, 12)\n",
            "binary_complexity\n",
            "0    759\n",
            "1    758\n",
            "Name: count, dtype: int64\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1517 entries, 0 to 1516\n",
            "Data columns (total 12 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   id                        1517 non-null   object \n",
            " 1   corpus                    1517 non-null   object \n",
            " 2   sentence                  1517 non-null   object \n",
            " 3   token                     1517 non-null   object \n",
            " 4   complexity                1517 non-null   float64\n",
            " 5   sentence_no_contractions  1517 non-null   object \n",
            " 6   contraction_expanded      1517 non-null   bool   \n",
            " 7   pos_sequence              1517 non-null   object \n",
            " 8   dep_sequence              1517 non-null   object \n",
            " 9   morph_sequence            1517 non-null   object \n",
            " 10  morph_complexity          1517 non-null   float64\n",
            " 11  binary_complexity         1517 non-null   int64  \n",
            "dtypes: bool(1), float64(2), int64(1), object(8)\n",
            "memory usage: 132.0+ KB\n",
            "None\n",
            "                               id corpus  \\\n",
            "0  3S37Y8CWI80N8KVM53U4E6JKCDC4WE  bible   \n",
            "1  3WGCNLZJKF877FYC1Q6COKNWTDWD11  bible   \n",
            "2  3UOMW19E6D6WQ5TH2HDD74IVKTP5CB  bible   \n",
            "3  36JW4WBR06KF9AXMUL4N476OMF8FHD  bible   \n",
            "4  3HRWUH63QU2FH9Q8R7MRNFC7JX2N5A  bible   \n",
            "\n",
            "                                            sentence            token  \\\n",
            "0  but the seventh day is a Sabbath to Yahweh you...      seventh day   \n",
            "1  But let each man test his own work, and then h...         own work   \n",
            "2  To him who by understanding made the heavens; ...  loving kindness   \n",
            "3  Remember to me, my God, this also, and spare m...  loving kindness   \n",
            "4  Because your loving kindness is better than li...  loving kindness   \n",
            "\n",
            "   complexity                           sentence_no_contractions  \\\n",
            "0    0.027778  but the seventh day is a Sabbath to Yahweh you...   \n",
            "1    0.050000  But let each man test his own work, and then h...   \n",
            "2    0.050000  To him who by understanding made the heavens; ...   \n",
            "3    0.050000  Remember to me, my God, this also, and spare m...   \n",
            "4    0.075000  Because your loving kindness is better than li...   \n",
            "\n",
            "   contraction_expanded                                       pos_sequence  \\\n",
            "0                 False  ['CCONJ', 'DET', 'ADJ', 'NOUN', 'AUX', 'DET', ...   \n",
            "1                 False  ['CCONJ', 'VERB', 'DET', 'NOUN', 'VERB', 'PRON...   \n",
            "2                 False  ['ADP', 'PRON', 'PRON', 'ADP', 'VERB', 'VERB',...   \n",
            "3                 False  ['VERB', 'ADP', 'PRON', 'PUNCT', 'PRON', 'PROP...   \n",
            "4                 False  ['SCONJ', 'PRON', 'ADJ', 'NOUN', 'AUX', 'ADJ',...   \n",
            "\n",
            "                                        dep_sequence  \\\n",
            "0  ['cc', 'det', 'amod', 'nsubj', 'ccomp', 'det',...   \n",
            "1  ['cc', 'ROOT', 'det', 'nsubj', 'ccomp', 'poss'...   \n",
            "2  ['prep', 'pobj', 'nsubj', 'prep', 'pcomp', 'ad...   \n",
            "3  ['ROOT', 'prep', 'pobj', 'punct', 'poss', 'npa...   \n",
            "4  ['mark', 'poss', 'amod', 'nsubj', 'advcl', 'ac...   \n",
            "\n",
            "                                      morph_sequence  morph_complexity  \\\n",
            "0  [ConjType=Cmp, Definite=Def|PronType=Art, Degr...          1.341772   \n",
            "1  [ConjType=Cmp, VerbForm=Inf, , Number=Sing, Ve...          1.608696   \n",
            "2  [, Case=Acc|Gender=Masc|Number=Sing|Person=3|P...          1.562500   \n",
            "3  [VerbForm=Inf, , Case=Acc|Number=Sing|Person=1...          1.590909   \n",
            "4  [, Person=2|Poss=Yes|PronType=Prs, Degree=Pos,...          1.600000   \n",
            "\n",
            "   binary_complexity  \n",
            "0                  0  \n",
            "1                  0  \n",
            "2                  0  \n",
            "3                  0  \n",
            "4                  0  \n",
            "\n",
            ">>> trial_val_single_df shape: (421, 12)\n",
            "binary_complexity\n",
            "0    229\n",
            "1    192\n",
            "Name: count, dtype: int64\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 421 entries, 0 to 420\n",
            "Data columns (total 12 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   id                        421 non-null    object \n",
            " 1   corpus                    421 non-null    object \n",
            " 2   sentence                  421 non-null    object \n",
            " 3   token                     421 non-null    object \n",
            " 4   complexity                421 non-null    float64\n",
            " 5   sentence_no_contractions  421 non-null    object \n",
            " 6   contraction_expanded      421 non-null    bool   \n",
            " 7   pos_sequence              421 non-null    object \n",
            " 8   dep_sequence              421 non-null    object \n",
            " 9   morph_sequence            421 non-null    object \n",
            " 10  morph_complexity          421 non-null    float64\n",
            " 11  binary_complexity         421 non-null    int64  \n",
            "dtypes: bool(1), float64(2), int64(1), object(8)\n",
            "memory usage: 36.7+ KB\n",
            "None\n",
            "                               id corpus  \\\n",
            "0  3QI9WAYOGQB8GQIR4MDIEF0D2RLS67  bible   \n",
            "1  3T8DUCXY0N6WD9X4RTLK8UN1U929TF  bible   \n",
            "2  3I7KR83SNADXAQ7HXK7S7305BYB9KD  bible   \n",
            "3  3BO3NEOQM0HK9ERYPN0GQIWCPC4IAQ  bible   \n",
            "4  3Y3CZJSZ9KT0W7I0KE38WZHHKSW5RH  bible   \n",
            "\n",
            "                                            sentence token  complexity  \\\n",
            "0  They will not hurt nor destroy in all my holy ...   sea    0.000000   \n",
            "1  that sends ambassadors by the sea, even in ves...   sea    0.102941   \n",
            "2  and they entered into the boat, and were going...   sea    0.109375   \n",
            "3  Joseph laid up grain as the sand of the sea, v...   sea    0.160714   \n",
            "4  There will be a highway for the remnant that i...  land    0.000000   \n",
            "\n",
            "                            sentence_no_contractions  contraction_expanded  \\\n",
            "0  They will not hurt nor destroy in all my holy ...                 False   \n",
            "1  that sends ambassadors by the sea, even in ves...                 False   \n",
            "2  and they entered into the boat, and were going...                 False   \n",
            "3  Joseph laid up grain as the sand of the sea, v...                 False   \n",
            "4  There will be a highway for the remnant that i...                 False   \n",
            "\n",
            "                                        pos_sequence  \\\n",
            "0  ['PRON', 'AUX', 'PART', 'VERB', 'CCONJ', 'VERB...   \n",
            "1  ['PRON', 'VERB', 'NOUN', 'ADP', 'DET', 'NOUN',...   \n",
            "2  ['CCONJ', 'PRON', 'VERB', 'ADP', 'DET', 'NOUN'...   \n",
            "3  ['PROPN', 'VERB', 'ADP', 'NOUN', 'ADP', 'DET',...   \n",
            "4  ['PRON', 'AUX', 'AUX', 'DET', 'NOUN', 'ADP', '...   \n",
            "\n",
            "                                        dep_sequence  \\\n",
            "0  ['nsubj', 'aux', 'neg', 'ccomp', 'cc', 'conj',...   \n",
            "1  ['nsubj', 'ROOT', 'dobj', 'prep', 'det', 'pobj...   \n",
            "2  ['cc', 'nsubj', 'ROOT', 'prep', 'det', 'pobj',...   \n",
            "3  ['nsubj', 'ROOT', 'prt', 'dobj', 'prep', 'det'...   \n",
            "4  ['expl', 'aux', 'ROOT', 'det', 'attr', 'prep',...   \n",
            "\n",
            "                                      morph_sequence  morph_complexity  \\\n",
            "0  [Case=Nom|Number=Plur|Person=3|PronType=Prs, V...          1.129032   \n",
            "1  [PronType=Rel, Number=Sing|Person=3|Tense=Pres...          1.263158   \n",
            "2  [ConjType=Cmp, Case=Nom|Number=Plur|Person=3|P...          1.437500   \n",
            "3  [Number=Sing, Tense=Past|VerbForm=Fin, , Numbe...          1.400000   \n",
            "4  [, VerbForm=Fin, VerbForm=Inf, Definite=Ind|Pr...          1.277778   \n",
            "\n",
            "   binary_complexity  \n",
            "0                  0  \n",
            "1                  0  \n",
            "2                  0  \n",
            "3                  0  \n",
            "4                  0  \n",
            "\n",
            ">>> trial_val_multi_df shape: (99, 12)\n",
            "binary_complexity\n",
            "1    51\n",
            "0    48\n",
            "Name: count, dtype: int64\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 99 entries, 0 to 98\n",
            "Data columns (total 12 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   id                        99 non-null     object \n",
            " 1   corpus                    99 non-null     object \n",
            " 2   sentence                  99 non-null     object \n",
            " 3   token                     99 non-null     object \n",
            " 4   complexity                99 non-null     float64\n",
            " 5   sentence_no_contractions  99 non-null     object \n",
            " 6   contraction_expanded      99 non-null     bool   \n",
            " 7   pos_sequence              99 non-null     object \n",
            " 8   dep_sequence              99 non-null     object \n",
            " 9   morph_sequence            99 non-null     object \n",
            " 10  morph_complexity          99 non-null     float64\n",
            " 11  binary_complexity         99 non-null     int64  \n",
            "dtypes: bool(1), float64(2), int64(1), object(8)\n",
            "memory usage: 8.7+ KB\n",
            "None\n",
            "                               id corpus  \\\n",
            "0  31HLTCK4BLVQ5BO1AUR91TX9V9IVGH  bible   \n",
            "1  389A2A304OIXVY7G5B71Q9M43LE0CL  bible   \n",
            "2  31N9JPQXIPIRX2A3S9N0CCFXO6TNHR  bible   \n",
            "3  3JVP4ZJHDPSO81TGXL3N1CKZGQY0IN  bible   \n",
            "4  3JAOYN9IHL25ZQAUV5EJZ4GH0KL33L  bible   \n",
            "\n",
            "                                            sentence          token  \\\n",
            "0  The name of one son was Gershom, for Moses sai...   foreign land   \n",
            "1  unleavened bread, unleavened cakes mixed with ...    wheat flour   \n",
            "2  However the high places were not taken away; t...  burnt incense   \n",
            "3  and he burnt incense of sweet spices on it, as...  burnt incense   \n",
            "4  The same day the king made the middle of the c...   bronze altar   \n",
            "\n",
            "   complexity                           sentence_no_contractions  \\\n",
            "0    0.000000  The name of one son was Gershom, for Moses sai...   \n",
            "1    0.157895  unleavened bread, unleavened cakes mixed with ...   \n",
            "2    0.200000  However the high places were not taken away; t...   \n",
            "3    0.250000  and he burnt incense of sweet spices on it, as...   \n",
            "4    0.214286  The same day the king made the middle of the c...   \n",
            "\n",
            "   contraction_expanded                                       pos_sequence  \\\n",
            "0                 False  ['DET', 'NOUN', 'ADP', 'NUM', 'NOUN', 'AUX', '...   \n",
            "1                 False  ['ADJ', 'NOUN', 'PUNCT', 'ADJ', 'NOUN', 'VERB'...   \n",
            "2                 False  ['ADV', 'DET', 'ADJ', 'NOUN', 'AUX', 'PART', '...   \n",
            "3                 False  ['CCONJ', 'PRON', 'VERB', 'NOUN', 'ADP', 'ADJ'...   \n",
            "4                 False  ['DET', 'ADJ', 'NOUN', 'DET', 'NOUN', 'VERB', ...   \n",
            "\n",
            "                                        dep_sequence  \\\n",
            "0  ['det', 'nsubj', 'prep', 'nummod', 'pobj', 'RO...   \n",
            "1  ['amod', 'dep', 'punct', 'amod', 'appos', 'acl...   \n",
            "2  ['advmod', 'det', 'amod', 'nsubjpass', 'auxpas...   \n",
            "3  ['cc', 'nsubj', 'ROOT', 'dobj', 'prep', 'amod'...   \n",
            "4  ['det', 'amod', 'npadvmod', 'det', 'nsubj', 'c...   \n",
            "\n",
            "                                      morph_sequence  morph_complexity  \\\n",
            "0  [Definite=Def|PronType=Art, Number=Sing, , Num...          1.520000   \n",
            "1  [Degree=Pos, Number=Sing, PunctType=Comm, Degr...          1.200000   \n",
            "2  [, Definite=Def|PronType=Art, Degree=Pos, Numb...          1.190476   \n",
            "3  [ConjType=Cmp, Case=Nom|Gender=Masc|Number=Sin...          1.466667   \n",
            "4  [Definite=Def|PronType=Art, Degree=Pos, Number...          1.352113   \n",
            "\n",
            "   binary_complexity  \n",
            "0                  0  \n",
            "1                  0  \n",
            "2                  0  \n",
            "3                  0  \n",
            "4                  0  \n",
            "\n",
            ">>> test_single_df shape: (917, 12)\n",
            "binary_complexity\n",
            "0    476\n",
            "1    441\n",
            "Name: count, dtype: int64\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 917 entries, 0 to 916\n",
            "Data columns (total 12 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   id                        917 non-null    object \n",
            " 1   corpus                    917 non-null    object \n",
            " 2   sentence                  917 non-null    object \n",
            " 3   token                     917 non-null    object \n",
            " 4   complexity                917 non-null    float64\n",
            " 5   sentence_no_contractions  917 non-null    object \n",
            " 6   contraction_expanded      917 non-null    bool   \n",
            " 7   pos_sequence              917 non-null    object \n",
            " 8   dep_sequence              917 non-null    object \n",
            " 9   morph_sequence            917 non-null    object \n",
            " 10  morph_complexity          917 non-null    float64\n",
            " 11  binary_complexity         917 non-null    int64  \n",
            "dtypes: bool(1), float64(2), int64(1), object(8)\n",
            "memory usage: 79.8+ KB\n",
            "None\n",
            "                               id corpus  \\\n",
            "0  3K8CQCU3KE19US5SN890DFPK3SANWR  bible   \n",
            "1  3Q2T3FD0ON86LCI41NJYV3PN0BW3MV  bible   \n",
            "2  3ULIZ0H1VA5C32JJMKOTQ8Z4GUS51B  bible   \n",
            "3  3BFF0DJK8XCEIOT30ZLBPPSRMZQTSD  bible   \n",
            "4  3QREJ3J433XSBS8QMHAICCR0BQ1LKR  bible   \n",
            "\n",
            "                                            sentence     token  complexity  \\\n",
            "0  But he, beckoning to them with his hand to be ...      hand    0.000000   \n",
            "1  If I forget you, Jerusalem, let my right hand ...      hand    0.197368   \n",
            "2  the ten sons of Haman the son of Hammedatha, t...      hand    0.200000   \n",
            "3  Let your hand be lifted up above your adversar...      hand    0.267857   \n",
            "4  Abimelech chased him, and he fled before him, ...  entrance    0.000000   \n",
            "\n",
            "                            sentence_no_contractions  contraction_expanded  \\\n",
            "0  But he, beckoning to them with his hand to be ...                 False   \n",
            "1  If I forget you, Jerusalem, let my right hand ...                 False   \n",
            "2  the ten sons of Haman the son of Hammedatha, t...                  True   \n",
            "3  Let your hand be lifted up above your adversar...                 False   \n",
            "4  Abimelech chased him, and he fled before him, ...                 False   \n",
            "\n",
            "                                        pos_sequence  \\\n",
            "0  ['CCONJ', 'PRON', 'PUNCT', 'VERB', 'ADP', 'PRO...   \n",
            "1  ['SCONJ', 'PRON', 'VERB', 'PRON', 'PUNCT', 'PR...   \n",
            "2  ['DET', 'NUM', 'NOUN', 'ADP', 'PROPN', 'DET', ...   \n",
            "3  ['VERB', 'PRON', 'NOUN', 'AUX', 'VERB', 'ADP',...   \n",
            "4  ['PROPN', 'VERB', 'PRON', 'PUNCT', 'CCONJ', 'P...   \n",
            "\n",
            "                                        dep_sequence  \\\n",
            "0  ['cc', 'nsubj', 'punct', 'advcl', 'prep', 'pob...   \n",
            "1  ['mark', 'nsubj', 'advcl', 'dobj', 'punct', 'n...   \n",
            "2  ['det', 'nummod', 'ROOT', 'prep', 'pobj', 'det...   \n",
            "3  ['ROOT', 'poss', 'nsubjpass', 'auxpass', 'ccom...   \n",
            "4  ['nsubj', 'ROOT', 'dobj', 'punct', 'cc', 'nsub...   \n",
            "\n",
            "                                      morph_sequence  morph_complexity  \\\n",
            "0  [ConjType=Cmp, Case=Nom|Gender=Masc|Number=Sin...          1.703704   \n",
            "1  [, Case=Nom|Number=Sing|Person=1|PronType=Prs,...          1.800000   \n",
            "2  [Definite=Def|PronType=Art, NumType=Card, Numb...          1.269231   \n",
            "3  [VerbForm=Inf, Person=2|Poss=Yes|PronType=Prs,...          1.250000   \n",
            "4  [Number=Sing, Tense=Past|VerbForm=Fin, Case=Ac...          1.652174   \n",
            "\n",
            "   binary_complexity  \n",
            "0                  0  \n",
            "1                  0  \n",
            "2                  0  \n",
            "3                  0  \n",
            "4                  0  \n",
            "\n",
            ">>> test_multi_df shape: (184, 12)\n",
            "binary_complexity\n",
            "1    99\n",
            "0    85\n",
            "Name: count, dtype: int64\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 184 entries, 0 to 183\n",
            "Data columns (total 12 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   id                        184 non-null    object \n",
            " 1   corpus                    184 non-null    object \n",
            " 2   sentence                  184 non-null    object \n",
            " 3   token                     184 non-null    object \n",
            " 4   complexity                184 non-null    float64\n",
            " 5   sentence_no_contractions  184 non-null    object \n",
            " 6   contraction_expanded      184 non-null    bool   \n",
            " 7   pos_sequence              184 non-null    object \n",
            " 8   dep_sequence              184 non-null    object \n",
            " 9   morph_sequence            184 non-null    object \n",
            " 10  morph_complexity          184 non-null    float64\n",
            " 11  binary_complexity         184 non-null    int64  \n",
            "dtypes: bool(1), float64(2), int64(1), object(8)\n",
            "memory usage: 16.1+ KB\n",
            "None\n",
            "                               id corpus  \\\n",
            "0  3UXQ63NLAAMRIP4WG4XPD98AOYOBLX  bible   \n",
            "1  3FJ2RVH25Z62TA3R8E1O77EBUYU92W  bible   \n",
            "2  3YO4AH2FPDK1PZHZAT8WAEBL70EQ0F  bible   \n",
            "3  3X52SWXE0X5Q3O81YI0MX4V84QTCWZ  bible   \n",
            "4  32K26U12DNONTREA84Q1V8UCIH2VD7  bible   \n",
            "\n",
            "                                            sentence           token  \\\n",
            "0  for he had an only daughter, about twelve year...   only daughter   \n",
            "1  All these were cities fortified with high wall...      high walls   \n",
            "2  In the morning, 'It will be foul weather today...   weather today   \n",
            "3  Her young children also were dashed in pieces ...  young children   \n",
            "4  All king Solomon's drinking vessels were of go...       pure gold   \n",
            "\n",
            "   complexity                           sentence_no_contractions  \\\n",
            "0    0.025000  for he had an only daughter, about twelve year...   \n",
            "1    0.100000  All these were cities fortified with high wall...   \n",
            "2    0.125000  In the morning, 'It will be foul weather today...   \n",
            "3    0.160714  Her young children also were dashed in pieces ...   \n",
            "4    0.178571  All king Solomon's drinking vessels were of go...   \n",
            "\n",
            "   contraction_expanded                                       pos_sequence  \\\n",
            "0                 False  ['SCONJ', 'PRON', 'VERB', 'DET', 'ADJ', 'NOUN'...   \n",
            "1                 False  ['DET', 'PRON', 'AUX', 'NOUN', 'VERB', 'ADP', ...   \n",
            "2                 False  ['ADP', 'DET', 'NOUN', 'PUNCT', 'PUNCT', 'PRON...   \n",
            "3                 False  ['PRON', 'ADJ', 'NOUN', 'ADV', 'AUX', 'VERB', ...   \n",
            "4                 False  ['DET', 'NOUN', 'PROPN', 'PART', 'NOUN', 'NOUN...   \n",
            "\n",
            "                                        dep_sequence  \\\n",
            "0  ['mark', 'nsubj', 'ROOT', 'det', 'amod', 'dobj...   \n",
            "1  ['predet', 'nsubj', 'ROOT', 'attr', 'acl', 'pr...   \n",
            "2  ['prep', 'det', 'pobj', 'punct', 'punct', 'nsu...   \n",
            "3  ['poss', 'amod', 'nsubjpass', 'advmod', 'auxpa...   \n",
            "4  ['det', 'compound', 'poss', 'case', 'compound'...   \n",
            "\n",
            "                                      morph_sequence  morph_complexity  \\\n",
            "0  [, Case=Nom|Gender=Masc|Number=Sing|Person=3|P...          1.722222   \n",
            "1  [, Number=Plur|PronType=Dem, Mood=Ind|Tense=Pa...          1.136364   \n",
            "2  [, Definite=Def|PronType=Art, Number=Sing, Pun...          1.476190   \n",
            "3  [Gender=Fem|Number=Sing|Person=3|Poss=Yes|Pron...          1.514286   \n",
            "4  [, Number=Sing, Number=Sing, , Number=Sing, Nu...          1.162791   \n",
            "\n",
            "   binary_complexity  \n",
            "0                  0  \n",
            "1                  0  \n",
            "2                  0  \n",
            "3                  0  \n",
            "4                  0  \n",
            "train_single_df loaded into global namespace.\n",
            "train_multi_df loaded into global namespace.\n",
            "trial_val_single_df loaded into global namespace.\n",
            "trial_val_multi_df loaded into global namespace.\n",
            "test_single_df loaded into global namespace.\n",
            "test_multi_df loaded into global namespace.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Functional tests pass, we can proceed with Baseline Modeling"
      ],
      "metadata": {
        "id": "8VsgfL5ZhO4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Experiment 1: Baseline Modeling"
      ],
      "metadata": {
        "id": "AryofObMaySF"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reminders:\n",
        "\n",
        "- Precision\n",
        "$$\n",
        "\\text{Precision} = \\frac{TP}{TP + FP}\n",
        "$$\n",
        "- Recall\n",
        "$$\n",
        "\\text{Recall} = \\frac{TP}{TP + FN}\n",
        "$$\n",
        "\n",
        "- Accuracy\n",
        "$$\n",
        "\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}\n",
        "$$\n",
        "\n",
        "- F1 Score\n",
        "$$\n",
        "\\text{F1} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
        "$$\n",
        "\n",
        "- Cosine Similarity\n",
        "$$\n",
        "\\text{Cosine Similarity} = \\frac{\\mathbf{A} \\cdot \\mathbf{B}}{\\|\\mathbf{A}\\| \\, \\|\\mathbf{B}\\|}\n",
        "$$\n",
        "\n",
        "- Jaccard Similarity\n",
        "$$\n",
        "\\text{Jaccard Similarity} = \\frac{|A \\cap B|}{|A \\cup B|}\n",
        "$$\n",
        "\n",
        "- Overlap Similarity (Overlap Coefficient)\n",
        "$$\n",
        "\\text{Overlap Similarity} = \\frac{|A \\cap B|}{\\min(|A|, |B|)}\n",
        "$$\n",
        "\n",
        "- Dice Coefficient\n",
        "$$\n",
        "\\text{Dice Coefficient} = \\frac{2 \\, |A \\cap B|}{|A| + |B|}\n",
        "$$\n",
        "\n"
      ],
      "metadata": {
        "id": "zcq7Fwy9jazt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Naive Bayes"
      ],
      "metadata": {
        "id": "kXGkjXQGqeH8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### X = Sentence: contractions and no contractions"
      ],
      "metadata": {
        "id": "25Ph58CZtFJJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- sentence no contractions"
      ],
      "metadata": {
        "id": "MMDGr-ELvBZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_single_df\n",
        "val_df = trial_val_single_df\n",
        "\n",
        "vectorizer = TfidfVectorizer()  # just on 'sentence_no_contractions'\n",
        "X_train = vectorizer.fit_transform(train_df['sentence_no_contractions'])\n",
        "y_train = train_df['binary_complexity']\n",
        "\n",
        "X_val = vectorizer.transform(val_df['sentence_no_contractions'])\n",
        "y_val = val_df['binary_complexity']\n",
        "\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "preds = clf.predict(X_val)\n",
        "print(classification_report(y_val, preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd8mW5gfhV8j",
        "outputId": "7424566b-63da-401f-a9fe-8429a9488792"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.74      0.65       229\n",
            "           1       0.55      0.38      0.44       192\n",
            "\n",
            "    accuracy                           0.57       421\n",
            "   macro avg       0.57      0.56      0.55       421\n",
            "weighted avg       0.57      0.57      0.56       421\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- sentence with contractions"
      ],
      "metadata": {
        "id": "00DmH5T-vDp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_single_df\n",
        "val_df = trial_val_single_df\n",
        "\n",
        "vectorizer = TfidfVectorizer()  # just on 'sentence'\n",
        "X_train = vectorizer.fit_transform(train_df['sentence'])\n",
        "y_train = train_df['binary_complexity']\n",
        "\n",
        "X_val = vectorizer.transform(val_df['sentence'])\n",
        "y_val = val_df['binary_complexity']\n",
        "\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "preds = clf.predict(X_val)\n",
        "print(classification_report(y_val, preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0rDGC_Ur7Tc",
        "outputId": "106b9007-e9b1-43d2-9cc5-b413f934a3f8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.74      0.65       229\n",
            "           1       0.55      0.38      0.44       192\n",
            "\n",
            "    accuracy                           0.57       421\n",
            "   macro avg       0.57      0.56      0.55       421\n",
            "weighted avg       0.57      0.57      0.56       421\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- sentence no contractions"
      ],
      "metadata": {
        "id": "s90SKXECvFdU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_multi_df\n",
        "val_df = trial_val_multi_df\n",
        "\n",
        "vectorizer = TfidfVectorizer()  # just on 'sentence_no_contractions'\n",
        "X_train = vectorizer.fit_transform(train_df['sentence_no_contractions'])\n",
        "y_train = train_df['binary_complexity']\n",
        "\n",
        "X_val = vectorizer.transform(val_df['sentence_no_contractions'])\n",
        "y_val = val_df['binary_complexity']\n",
        "\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "preds = clf.predict(X_val)\n",
        "print(classification_report(y_val, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5krsiE6ohV6F",
        "outputId": "19c2b769-1aab-4540-ed18-2bd499c8c8e9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.67      0.58        48\n",
            "           1       0.57      0.41      0.48        51\n",
            "\n",
            "    accuracy                           0.54        99\n",
            "   macro avg       0.54      0.54      0.53        99\n",
            "weighted avg       0.54      0.54      0.53        99\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- sentence with contractions"
      ],
      "metadata": {
        "id": "gSARiKJUvJlO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_multi_df\n",
        "val_df = trial_val_multi_df\n",
        "\n",
        "vectorizer = TfidfVectorizer()  # just on 'sentence'\n",
        "X_train = vectorizer.fit_transform(train_df['sentence'])\n",
        "y_train = train_df['binary_complexity']\n",
        "\n",
        "X_val = vectorizer.transform(val_df['sentence'])\n",
        "y_val = val_df['binary_complexity']\n",
        "\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "preds = clf.predict(X_val)\n",
        "print(classification_report(y_val, preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDhdExbrhV3n",
        "outputId": "3a4bcff7-c3b7-4827-d36e-7162f122e79f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.67      0.58        48\n",
            "           1       0.57      0.41      0.48        51\n",
            "\n",
            "    accuracy                           0.54        99\n",
            "   macro avg       0.54      0.54      0.53        99\n",
            "weighted avg       0.54      0.54      0.53        99\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Score is higher than expected for a Naive Bayes model\n",
        "- There is no difference in performance when using the input sequence of the sentence with and without contractions"
      ],
      "metadata": {
        "id": "8ZGQHDtwsMwa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### X = pos_sequence: Part-of-Speech Tags"
      ],
      "metadata": {
        "id": "kmm6vDVPsm6a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- POS Tags: Extracts the part-of-speech (POS) tags for each token (e.g., \"DET\", \"NOUN\", \"VERB\")."
      ],
      "metadata": {
        "id": "UAkALOTjuG36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_single_df\n",
        "val_df = trial_val_single_df\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train = vectorizer.fit_transform(train_df['pos_sequence'])\n",
        "y_train = train_df['binary_complexity']\n",
        "\n",
        "X_val = vectorizer.transform(val_df['pos_sequence'])\n",
        "y_val = val_df['binary_complexity']\n",
        "\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "preds = clf.predict(X_val)\n",
        "print(classification_report(y_val, preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_j5rivRdsbaQ",
        "outputId": "7709baeb-5897-46c4-be73-d5b2939b58f5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.67      0.63       229\n",
            "           1       0.54      0.46      0.50       192\n",
            "\n",
            "    accuracy                           0.57       421\n",
            "   macro avg       0.57      0.57      0.56       421\n",
            "weighted avg       0.57      0.57      0.57       421\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_multi_df\n",
        "val_df = trial_val_multi_df\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train = vectorizer.fit_transform(train_df['pos_sequence'])\n",
        "y_train = train_df['binary_complexity']\n",
        "\n",
        "X_val = vectorizer.transform(val_df['pos_sequence'])\n",
        "y_val = val_df['binary_complexity']\n",
        "\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "preds = clf.predict(X_val)\n",
        "print(classification_report(y_val, preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJUA-jU3tBKj",
        "outputId": "d9240072-4a82-417b-d1b1-e70750a37610"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.54      0.56        48\n",
            "           1       0.59      0.63      0.61        51\n",
            "\n",
            "    accuracy                           0.59        99\n",
            "   macro avg       0.59      0.58      0.58        99\n",
            "weighted avg       0.59      0.59      0.59        99\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Part of Speech tags outperform raw input sequence"
      ],
      "metadata": {
        "id": "y9fD5Js7t8Ez"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### X = dep_sequence: Dependency Tags\n",
        "\n",
        "- Dependency Tags: Extracts the syntactic dependency labels for each token (e.g., \"det\", \"nsubj\", \"ROOT\")."
      ],
      "metadata": {
        "id": "N9puBjbrtktC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_single_df\n",
        "val_df = trial_val_single_df\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train = vectorizer.fit_transform(train_df['dep_sequence'])\n",
        "y_train = train_df['binary_complexity']\n",
        "\n",
        "X_val = vectorizer.transform(val_df['dep_sequence'])\n",
        "y_val = val_df['binary_complexity']\n",
        "\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "preds = clf.predict(X_val)\n",
        "print(classification_report(y_val, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0uXfJPLsbX0",
        "outputId": "ab145cfa-09a8-4975-d28d-9f8c6ac5425f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.60      0.60       229\n",
            "           1       0.53      0.54      0.54       192\n",
            "\n",
            "    accuracy                           0.57       421\n",
            "   macro avg       0.57      0.57      0.57       421\n",
            "weighted avg       0.57      0.57      0.57       421\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_multi_df\n",
        "val_df = trial_val_multi_df\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train = vectorizer.fit_transform(train_df['dep_sequence'])\n",
        "y_train = train_df['binary_complexity']\n",
        "\n",
        "X_val = vectorizer.transform(val_df['dep_sequence'])\n",
        "y_val = val_df['binary_complexity']\n",
        "\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "preds = clf.predict(X_val)\n",
        "print(classification_report(y_val, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmVkGchCuuj2",
        "outputId": "c64fb7cd-905c-4060-c673-5068ea664218"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.46      0.48        48\n",
            "           1       0.54      0.59      0.56        51\n",
            "\n",
            "    accuracy                           0.53        99\n",
            "   macro avg       0.52      0.52      0.52        99\n",
            "weighted avg       0.52      0.53      0.52        99\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### X = morph_sequence: Morphological Features\n",
        "- For each token, the morphological attributes have been retrieved for each token"
      ],
      "metadata": {
        "id": "hlE9BbXuuYQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_single_df\n",
        "val_df = trial_val_single_df\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train = vectorizer.fit_transform(train_df['morph_sequence'])\n",
        "y_train = train_df['binary_complexity']\n",
        "\n",
        "X_val = vectorizer.transform(val_df['morph_sequence'])\n",
        "y_val = val_df['binary_complexity']\n",
        "\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "preds = clf.predict(X_val)\n",
        "print(classification_report(y_val, preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpy5Kh8SsbTR",
        "outputId": "c35d319f-f62f-45a7-c97a-a0afc58d4976"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.59      0.60       229\n",
            "           1       0.53      0.57      0.55       192\n",
            "\n",
            "    accuracy                           0.58       421\n",
            "   macro avg       0.58      0.58      0.58       421\n",
            "weighted avg       0.58      0.58      0.58       421\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_multi_df\n",
        "val_df = trial_val_multi_df\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train = vectorizer.fit_transform(train_df['morph_sequence'])\n",
        "y_train = train_df['binary_complexity']\n",
        "\n",
        "X_val = vectorizer.transform(val_df['morph_sequence'])\n",
        "y_val = val_df['binary_complexity']\n",
        "\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "preds = clf.predict(X_val)\n",
        "print(classification_report(y_val, preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SS92gFd1sbQe",
        "outputId": "ad6363be-8480-403f-90a9-d23ed9ad49c0"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.52      0.57        48\n",
            "           1       0.61      0.71      0.65        51\n",
            "\n",
            "    accuracy                           0.62        99\n",
            "   macro avg       0.62      0.61      0.61        99\n",
            "weighted avg       0.62      0.62      0.61        99\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformers Models"
      ],
      "metadata": {
        "id": "kxZvACQZQu61"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT"
      ],
      "metadata": {
        "id": "dN0RXkp0uj5E"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bbVwzSTbQxFe"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}